{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337) \n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, BatchNormalization, MaxPooling1D, LeakyReLU, Flatten, Dropout\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from keras.utils import custom_object_scope\n",
    "from keras.callbacks import History, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras import metrics, regularizers\n",
    "from keras.optimizers import Adam, Adagrad, Adadelta, RMSprop\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import keras.regularizers\n",
    "import keras\n",
    "import glob\n",
    "import os\n",
    "import itertools\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/dimitrygrebenyuk/Yandex.Disk.localized/Working/PDF/Refinements/PDF-Cluster-Prediction/all_data')\n",
    "files_calc = glob.glob('*.dat')\n",
    "files_exp = glob.glob('*processed.gr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_points = []\n",
    "\n",
    "with open('labels.txt', 'w') as labels:\n",
    "    for f in files_calc:\n",
    "        df = pd.read_csv(f, usecols=[1], skiprows=201, header=None, delim_whitespace=True, skipfooter=0, engine='python')\n",
    "        raw_data_points.append(df.values.ravel())\n",
    "        labels.write(f[0])\n",
    "        labels.write('\\n')\n",
    "    for f in files_exp:\n",
    "        df = pd.read_csv(f, usecols=[1], skiprows=1, header=None, delim_whitespace=True, skipfooter=1, engine='python')\n",
    "        raw_data_points.append(df.values.ravel())\n",
    "        labels.write(f[0])\n",
    "        labels.write('\\n')\n",
    "        \n",
    "raw_data_points = np.array(raw_data_points)\n",
    "\n",
    "# Load the labels\n",
    "labels = pd.read_csv(\"labels.txt\", header=None)\n",
    "one_hot_labels = pd.get_dummies(labels[0])\n",
    "labels = one_hot_labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x159a8a9a0>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# Preprocessing\n",
    "#scaler = MinMaxScaler()\n",
    "#scaler = StandardScaler()\n",
    "#scaler =MaxAbsScaler()\n",
    "#data_points = scaler.fit_transform(data_points)\n",
    "normalize = Normalizer()\n",
    "data_points = normalize.fit_transform(raw_data_points)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(len(data_points[43,:]))/100+2, data_points[43,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_points, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 745, 32)           8224      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 745, 32)          128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 372, 32)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 372, 32)           0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 357, 32)           16416     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 357, 32)           0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 178, 32)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 178, 32)           0         \n",
      "                                                                 \n",
      " seq_self_attention (SeqSelf  (None, 178, 32)          1025      \n",
      " Attention)                                                      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 5696)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               729216    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 1032      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 756,041\n",
      "Trainable params: 755,977\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Tuning of the model\n",
    "\n",
    "model = Sequential()\n",
    "# Add the convolutional layers\n",
    "model.add(Conv1D(filters=32, kernel_size=256, activation='relu', input_shape=(1000,1))) # 256, 32\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2)) # 2\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters=32, kernel_size=16, activation='relu')) # 64, 32\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling1D(pool_size=2)) # 2\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(SeqSelfAttention(attention_width=16, attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL)) # 16\n",
    "\n",
    "# Flatten the output of the convolutional layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add the fully connected layers\n",
    "model.add(Dense(units=128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01))) # 128 0.01\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=8, activation='softmax', kernel_regularizer=keras.regularizers.l2(0.01))) # 10 0.01\n",
    "\n",
    "# Compile the model\n",
    "optimizer = RMSprop(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-09 10:18:12.621599: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/4 [=====================>........] - ETA: 0s - loss: 4.6511 - accuracy: 0.2500\n",
      "Epoch 1: val_accuracy improved from -inf to 0.32000, saving model to onehot.hdf5\n",
      "4/4 [==============================] - 1s 83ms/step - loss: 4.6522 - accuracy: 0.2551 - val_loss: 4.6713 - val_accuracy: 0.3200\n",
      "Epoch 2/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 4.5000 - accuracy: 0.3646\n",
      "Epoch 2: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 4.4782 - accuracy: 0.3776 - val_loss: 4.6353 - val_accuracy: 0.3200\n",
      "Epoch 3/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 4.3920 - accuracy: 0.4167\n",
      "Epoch 3: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 4.3984 - accuracy: 0.4184 - val_loss: 4.6082 - val_accuracy: 0.3200\n",
      "Epoch 4/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 4.3151 - accuracy: 0.4271\n",
      "Epoch 4: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 4.3023 - accuracy: 0.4286 - val_loss: 4.5833 - val_accuracy: 0.3200\n",
      "Epoch 5/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 4.1886 - accuracy: 0.4479\n",
      "Epoch 5: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 4.1865 - accuracy: 0.4490 - val_loss: 4.5614 - val_accuracy: 0.3200\n",
      "Epoch 6/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 4.1838 - accuracy: 0.4388\n",
      "Epoch 6: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 4.1838 - accuracy: 0.4388 - val_loss: 4.5379 - val_accuracy: 0.3200\n",
      "Epoch 7/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 4.1339 - accuracy: 0.4583\n",
      "Epoch 7: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 4.1132 - accuracy: 0.4694 - val_loss: 4.5147 - val_accuracy: 0.3200\n",
      "Epoch 8/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 4.1026 - accuracy: 0.4583\n",
      "Epoch 8: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 4.1177 - accuracy: 0.4490 - val_loss: 4.4956 - val_accuracy: 0.3200\n",
      "Epoch 9/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 4.0441 - accuracy: 0.4184\n",
      "Epoch 9: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 4.0441 - accuracy: 0.4184 - val_loss: 4.4731 - val_accuracy: 0.3200\n",
      "Epoch 10/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.9856 - accuracy: 0.4479\n",
      "Epoch 10: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 3.9707 - accuracy: 0.4592 - val_loss: 4.4509 - val_accuracy: 0.3200\n",
      "Epoch 11/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.8515 - accuracy: 0.4792\n",
      "Epoch 11: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 3.8536 - accuracy: 0.4694 - val_loss: 4.4335 - val_accuracy: 0.3200\n",
      "Epoch 12/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.9436 - accuracy: 0.4688\n",
      "Epoch 12: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 3.9584 - accuracy: 0.4592 - val_loss: 4.4144 - val_accuracy: 0.3200\n",
      "Epoch 13/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.7809 - accuracy: 0.5104\n",
      "Epoch 13: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 3.7982 - accuracy: 0.5000 - val_loss: 4.3958 - val_accuracy: 0.3200\n",
      "Epoch 14/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.8875 - accuracy: 0.4896\n",
      "Epoch 14: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 3.8967 - accuracy: 0.4898 - val_loss: 4.3782 - val_accuracy: 0.3200\n",
      "Epoch 15/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.7532 - accuracy: 0.4688\n",
      "Epoch 15: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 3.7442 - accuracy: 0.4796 - val_loss: 4.3591 - val_accuracy: 0.3200\n",
      "Epoch 16/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.8078 - accuracy: 0.4479\n",
      "Epoch 16: val_accuracy improved from 0.32000 to 0.36000, saving model to onehot.hdf5\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 3.8015 - accuracy: 0.4490 - val_loss: 4.3400 - val_accuracy: 0.3600\n",
      "Epoch 17/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.7359 - accuracy: 0.4796\n",
      "Epoch 17: val_accuracy did not improve from 0.36000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 3.7359 - accuracy: 0.4796 - val_loss: 4.3217 - val_accuracy: 0.3200\n",
      "Epoch 18/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.6812 - accuracy: 0.5104\n",
      "Epoch 18: val_accuracy did not improve from 0.36000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 3.6722 - accuracy: 0.5204 - val_loss: 4.2991 - val_accuracy: 0.3200\n",
      "Epoch 19/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.6786 - accuracy: 0.5102\n",
      "Epoch 19: val_accuracy did not improve from 0.36000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 3.6786 - accuracy: 0.5102 - val_loss: 4.2802 - val_accuracy: 0.3200\n",
      "Epoch 20/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.5360 - accuracy: 0.5521\n",
      "Epoch 20: val_accuracy did not improve from 0.36000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 3.5511 - accuracy: 0.5510 - val_loss: 4.2607 - val_accuracy: 0.3600\n",
      "Epoch 21/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.5951 - accuracy: 0.5521\n",
      "Epoch 21: val_accuracy did not improve from 0.36000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 3.6008 - accuracy: 0.5408 - val_loss: 4.2434 - val_accuracy: 0.3200\n",
      "Epoch 22/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.4937 - accuracy: 0.5938\n",
      "Epoch 22: val_accuracy did not improve from 0.36000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 3.4902 - accuracy: 0.5918 - val_loss: 4.2247 - val_accuracy: 0.3200\n",
      "Epoch 23/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.5072 - accuracy: 0.5000\n",
      "Epoch 23: val_accuracy did not improve from 0.36000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 3.5072 - accuracy: 0.5000 - val_loss: 4.2079 - val_accuracy: 0.2000\n",
      "Epoch 24/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.5088 - accuracy: 0.4792\n",
      "Epoch 24: val_accuracy did not improve from 0.36000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 3.4904 - accuracy: 0.4898 - val_loss: 4.1830 - val_accuracy: 0.3600\n",
      "Epoch 25/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.3565 - accuracy: 0.5729\n",
      "Epoch 25: val_accuracy did not improve from 0.36000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 3.3706 - accuracy: 0.5612 - val_loss: 4.1674 - val_accuracy: 0.3600\n",
      "Epoch 26/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.3412 - accuracy: 0.5729\n",
      "Epoch 26: val_accuracy did not improve from 0.36000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 3.3672 - accuracy: 0.5612 - val_loss: 4.1517 - val_accuracy: 0.2800\n",
      "Epoch 27/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.3333 - accuracy: 0.6250\n",
      "Epoch 27: val_accuracy did not improve from 0.36000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 3.3245 - accuracy: 0.6327 - val_loss: 4.1302 - val_accuracy: 0.3200\n",
      "Epoch 28/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.2527 - accuracy: 0.6122\n",
      "Epoch 28: val_accuracy did not improve from 0.36000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 3.2527 - accuracy: 0.6122 - val_loss: 4.1084 - val_accuracy: 0.3200\n",
      "Epoch 29/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.2708 - accuracy: 0.6354\n",
      "Epoch 29: val_accuracy improved from 0.36000 to 0.44000, saving model to onehot.hdf5\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 3.2693 - accuracy: 0.6327 - val_loss: 4.0912 - val_accuracy: 0.4400\n",
      "Epoch 30/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.2637 - accuracy: 0.5417\n",
      "Epoch 30: val_accuracy did not improve from 0.44000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 3.2588 - accuracy: 0.5408 - val_loss: 4.0729 - val_accuracy: 0.3200\n",
      "Epoch 31/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.1122 - accuracy: 0.6146\n",
      "Epoch 31: val_accuracy did not improve from 0.44000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 3.1118 - accuracy: 0.6122 - val_loss: 4.0583 - val_accuracy: 0.2000\n",
      "Epoch 32/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.2451 - accuracy: 0.5417\n",
      "Epoch 32: val_accuracy did not improve from 0.44000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 3.2383 - accuracy: 0.5408 - val_loss: 4.0401 - val_accuracy: 0.3200\n",
      "Epoch 33/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.1540 - accuracy: 0.5938\n",
      "Epoch 33: val_accuracy did not improve from 0.44000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 3.1369 - accuracy: 0.6020 - val_loss: 4.0259 - val_accuracy: 0.2000\n",
      "Epoch 34/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.2225 - accuracy: 0.5625\n",
      "Epoch 34: val_accuracy did not improve from 0.44000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 3.2248 - accuracy: 0.5612 - val_loss: 4.0067 - val_accuracy: 0.3200\n",
      "Epoch 35/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.1880 - accuracy: 0.5312\n",
      "Epoch 35: val_accuracy did not improve from 0.44000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 3.1712 - accuracy: 0.5408 - val_loss: 3.9913 - val_accuracy: 0.2800\n",
      "Epoch 36/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.1264 - accuracy: 0.6042\n",
      "Epoch 36: val_accuracy did not improve from 0.44000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 3.1053 - accuracy: 0.6122 - val_loss: 3.9739 - val_accuracy: 0.3600\n",
      "Epoch 37/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.0667 - accuracy: 0.6354\n",
      "Epoch 37: val_accuracy did not improve from 0.44000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 3.0724 - accuracy: 0.6327 - val_loss: 3.9510 - val_accuracy: 0.3600\n",
      "Epoch 38/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.1142 - accuracy: 0.5625\n",
      "Epoch 38: val_accuracy did not improve from 0.44000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 3.1076 - accuracy: 0.5714 - val_loss: 3.9380 - val_accuracy: 0.4000\n",
      "Epoch 39/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.0453 - accuracy: 0.6224\n",
      "Epoch 39: val_accuracy did not improve from 0.44000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 3.0453 - accuracy: 0.6224 - val_loss: 3.9234 - val_accuracy: 0.4000\n",
      "Epoch 40/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.0022 - accuracy: 0.6562\n",
      "Epoch 40: val_accuracy did not improve from 0.44000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 3.0224 - accuracy: 0.6429 - val_loss: 3.9113 - val_accuracy: 0.4000\n",
      "Epoch 41/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.0678 - accuracy: 0.6042\n",
      "Epoch 41: val_accuracy improved from 0.44000 to 0.48000, saving model to onehot.hdf5\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 3.0728 - accuracy: 0.6020 - val_loss: 3.8964 - val_accuracy: 0.4800\n",
      "Epoch 42/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.9445 - accuracy: 0.6146\n",
      "Epoch 42: val_accuracy did not improve from 0.48000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.9318 - accuracy: 0.6224 - val_loss: 3.8788 - val_accuracy: 0.4000\n",
      "Epoch 43/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.9163 - accuracy: 0.6458\n",
      "Epoch 43: val_accuracy did not improve from 0.48000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.9087 - accuracy: 0.6531 - val_loss: 3.8653 - val_accuracy: 0.4000\n",
      "Epoch 44/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.8083 - accuracy: 0.6735\n",
      "Epoch 44: val_accuracy did not improve from 0.48000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 2.8083 - accuracy: 0.6735 - val_loss: 3.8493 - val_accuracy: 0.4400\n",
      "Epoch 45/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.9012 - accuracy: 0.7143\n",
      "Epoch 45: val_accuracy did not improve from 0.48000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 2.9012 - accuracy: 0.7143 - val_loss: 3.8426 - val_accuracy: 0.4400\n",
      "Epoch 46/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.8247 - accuracy: 0.7083\n",
      "Epoch 46: val_accuracy did not improve from 0.48000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.8236 - accuracy: 0.7041 - val_loss: 3.8321 - val_accuracy: 0.4000\n",
      "Epoch 47/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.9021 - accuracy: 0.6667\n",
      "Epoch 47: val_accuracy did not improve from 0.48000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.8806 - accuracy: 0.6735 - val_loss: 3.8178 - val_accuracy: 0.4000\n",
      "Epoch 48/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.7184 - accuracy: 0.6771\n",
      "Epoch 48: val_accuracy did not improve from 0.48000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.7107 - accuracy: 0.6837 - val_loss: 3.8023 - val_accuracy: 0.3600\n",
      "Epoch 49/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.6608 - accuracy: 0.7396\n",
      "Epoch 49: val_accuracy did not improve from 0.48000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.6641 - accuracy: 0.7347 - val_loss: 3.7869 - val_accuracy: 0.4800\n",
      "Epoch 50/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.8393 - accuracy: 0.5938\n",
      "Epoch 50: val_accuracy did not improve from 0.48000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.8476 - accuracy: 0.5918 - val_loss: 3.7719 - val_accuracy: 0.4800\n",
      "Epoch 51/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.7544 - accuracy: 0.6667\n",
      "Epoch 51: val_accuracy did not improve from 0.48000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 2.7474 - accuracy: 0.6735 - val_loss: 3.7587 - val_accuracy: 0.3600\n",
      "Epoch 52/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.7375 - accuracy: 0.6458\n",
      "Epoch 52: val_accuracy did not improve from 0.48000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.7339 - accuracy: 0.6429 - val_loss: 3.7433 - val_accuracy: 0.4800\n",
      "Epoch 53/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.7511 - accuracy: 0.6327\n",
      "Epoch 53: val_accuracy improved from 0.48000 to 0.60000, saving model to onehot.hdf5\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 2.7511 - accuracy: 0.6327 - val_loss: 3.7342 - val_accuracy: 0.6000\n",
      "Epoch 54/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.7173 - accuracy: 0.6667\n",
      "Epoch 54: val_accuracy did not improve from 0.60000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 2.7281 - accuracy: 0.6633 - val_loss: 3.7269 - val_accuracy: 0.5200\n",
      "Epoch 55/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.6478 - accuracy: 0.6667\n",
      "Epoch 55: val_accuracy did not improve from 0.60000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.6309 - accuracy: 0.6735 - val_loss: 3.7120 - val_accuracy: 0.4800\n",
      "Epoch 56/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.6540 - accuracy: 0.6771\n",
      "Epoch 56: val_accuracy did not improve from 0.60000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.6476 - accuracy: 0.6735 - val_loss: 3.7003 - val_accuracy: 0.4400\n",
      "Epoch 57/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.6551 - accuracy: 0.6633\n",
      "Epoch 57: val_accuracy did not improve from 0.60000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 2.6551 - accuracy: 0.6633 - val_loss: 3.6806 - val_accuracy: 0.5200\n",
      "Epoch 58/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.6539 - accuracy: 0.5833\n",
      "Epoch 58: val_accuracy did not improve from 0.60000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.6355 - accuracy: 0.5918 - val_loss: 3.6720 - val_accuracy: 0.4800\n",
      "Epoch 59/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.6524 - accuracy: 0.6771\n",
      "Epoch 59: val_accuracy did not improve from 0.60000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 2.6530 - accuracy: 0.6837 - val_loss: 3.6691 - val_accuracy: 0.4800\n",
      "Epoch 60/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.5427 - accuracy: 0.6875\n",
      "Epoch 60: val_accuracy did not improve from 0.60000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 2.5385 - accuracy: 0.6939 - val_loss: 3.6474 - val_accuracy: 0.5200\n",
      "Epoch 61/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.5798 - accuracy: 0.6633\n",
      "Epoch 61: val_accuracy improved from 0.60000 to 0.68000, saving model to onehot.hdf5\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 2.5798 - accuracy: 0.6633 - val_loss: 3.6379 - val_accuracy: 0.6800\n",
      "Epoch 62/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.5304 - accuracy: 0.7292\n",
      "Epoch 62: val_accuracy did not improve from 0.68000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 2.5425 - accuracy: 0.7245 - val_loss: 3.6339 - val_accuracy: 0.5200\n",
      "Epoch 63/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.5973 - accuracy: 0.6979\n",
      "Epoch 63: val_accuracy did not improve from 0.68000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 2.6009 - accuracy: 0.6939 - val_loss: 3.6207 - val_accuracy: 0.4800\n",
      "Epoch 64/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.4524 - accuracy: 0.7500\n",
      "Epoch 64: val_accuracy did not improve from 0.68000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.5088 - accuracy: 0.7347 - val_loss: 3.6117 - val_accuracy: 0.4000\n",
      "Epoch 65/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.4774 - accuracy: 0.7396\n",
      "Epoch 65: val_accuracy did not improve from 0.68000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.4862 - accuracy: 0.7245 - val_loss: 3.5990 - val_accuracy: 0.5200\n",
      "Epoch 66/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.5315 - accuracy: 0.7083\n",
      "Epoch 66: val_accuracy did not improve from 0.68000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.5419 - accuracy: 0.6939 - val_loss: 3.5863 - val_accuracy: 0.6800\n",
      "Epoch 67/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.4296 - accuracy: 0.7708\n",
      "Epoch 67: val_accuracy did not improve from 0.68000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.4196 - accuracy: 0.7755 - val_loss: 3.5703 - val_accuracy: 0.5200\n",
      "Epoch 68/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.4784 - accuracy: 0.6771\n",
      "Epoch 68: val_accuracy did not improve from 0.68000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.4726 - accuracy: 0.6837 - val_loss: 3.5584 - val_accuracy: 0.5200\n",
      "Epoch 69/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.3533 - accuracy: 0.7188\n",
      "Epoch 69: val_accuracy did not improve from 0.68000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 2.3394 - accuracy: 0.7245 - val_loss: 3.5451 - val_accuracy: 0.5200\n",
      "Epoch 70/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.4428 - accuracy: 0.6771\n",
      "Epoch 70: val_accuracy did not improve from 0.68000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.4455 - accuracy: 0.6735 - val_loss: 3.5371 - val_accuracy: 0.6400\n",
      "Epoch 71/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.4331 - accuracy: 0.7083\n",
      "Epoch 71: val_accuracy did not improve from 0.68000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.4173 - accuracy: 0.7143 - val_loss: 3.5201 - val_accuracy: 0.6000\n",
      "Epoch 72/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.3985 - accuracy: 0.7500\n",
      "Epoch 72: val_accuracy did not improve from 0.68000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.4148 - accuracy: 0.7449 - val_loss: 3.5046 - val_accuracy: 0.6800\n",
      "Epoch 73/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.3437 - accuracy: 0.7500\n",
      "Epoch 73: val_accuracy improved from 0.68000 to 0.72000, saving model to onehot.hdf5\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 2.3496 - accuracy: 0.7449 - val_loss: 3.4924 - val_accuracy: 0.7200\n",
      "Epoch 74/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.4687 - accuracy: 0.7500\n",
      "Epoch 74: val_accuracy did not improve from 0.72000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 2.4532 - accuracy: 0.7551 - val_loss: 3.4839 - val_accuracy: 0.6800\n",
      "Epoch 75/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.3284 - accuracy: 0.7292\n",
      "Epoch 75: val_accuracy improved from 0.72000 to 0.76000, saving model to onehot.hdf5\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 2.3584 - accuracy: 0.7143 - val_loss: 3.4752 - val_accuracy: 0.7600\n",
      "Epoch 76/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.3030 - accuracy: 0.7083\n",
      "Epoch 76: val_accuracy did not improve from 0.76000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 2.3018 - accuracy: 0.7143 - val_loss: 3.4493 - val_accuracy: 0.5600\n",
      "Epoch 77/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.4210 - accuracy: 0.6875\n",
      "Epoch 77: val_accuracy did not improve from 0.76000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 2.4338 - accuracy: 0.6837 - val_loss: 3.4393 - val_accuracy: 0.5200\n",
      "Epoch 78/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.3823 - accuracy: 0.7604\n",
      "Epoch 78: val_accuracy did not improve from 0.76000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.3901 - accuracy: 0.7551 - val_loss: 3.4400 - val_accuracy: 0.6400\n",
      "Epoch 79/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.2893 - accuracy: 0.7500\n",
      "Epoch 79: val_accuracy improved from 0.76000 to 0.80000, saving model to onehot.hdf5\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 2.3195 - accuracy: 0.7347 - val_loss: 3.4289 - val_accuracy: 0.8000\n",
      "Epoch 80/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.4625 - accuracy: 0.7083\n",
      "Epoch 80: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.4539 - accuracy: 0.7143 - val_loss: 3.4224 - val_accuracy: 0.6400\n",
      "Epoch 81/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.2821 - accuracy: 0.7292\n",
      "Epoch 81: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.2739 - accuracy: 0.7347 - val_loss: 3.4045 - val_accuracy: 0.6800\n",
      "Epoch 82/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.2424 - accuracy: 0.7708\n",
      "Epoch 82: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.2348 - accuracy: 0.7755 - val_loss: 3.3829 - val_accuracy: 0.7200\n",
      "Epoch 83/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.2927 - accuracy: 0.7604\n",
      "Epoch 83: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.2780 - accuracy: 0.7653 - val_loss: 3.3702 - val_accuracy: 0.7200\n",
      "Epoch 84/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.3312 - accuracy: 0.7083\n",
      "Epoch 84: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.3190 - accuracy: 0.7143 - val_loss: 3.3506 - val_accuracy: 0.6400\n",
      "Epoch 85/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.2651 - accuracy: 0.7188\n",
      "Epoch 85: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.2550 - accuracy: 0.7245 - val_loss: 3.3317 - val_accuracy: 0.6400\n",
      "Epoch 86/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.2396 - accuracy: 0.7500\n",
      "Epoch 86: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 2.2465 - accuracy: 0.7449 - val_loss: 3.3401 - val_accuracy: 0.6800\n",
      "Epoch 87/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.2199 - accuracy: 0.7292\n",
      "Epoch 87: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.2066 - accuracy: 0.7347 - val_loss: 3.3199 - val_accuracy: 0.7200\n",
      "Epoch 88/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.2630 - accuracy: 0.7396\n",
      "Epoch 88: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 2.2598 - accuracy: 0.7449 - val_loss: 3.3010 - val_accuracy: 0.4400\n",
      "Epoch 89/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.2248 - accuracy: 0.7292\n",
      "Epoch 89: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 2.2188 - accuracy: 0.7347 - val_loss: 3.2901 - val_accuracy: 0.6000\n",
      "Epoch 90/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.1845 - accuracy: 0.7812\n",
      "Epoch 90: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 2.1736 - accuracy: 0.7857 - val_loss: 3.2775 - val_accuracy: 0.6400\n",
      "Epoch 91/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.1668 - accuracy: 0.7604\n",
      "Epoch 91: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 2.1629 - accuracy: 0.7653 - val_loss: 3.2619 - val_accuracy: 0.6800\n",
      "Epoch 92/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.1986 - accuracy: 0.7396\n",
      "Epoch 92: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 2.2100 - accuracy: 0.7347 - val_loss: 3.2772 - val_accuracy: 0.7200\n",
      "Epoch 93/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.1418 - accuracy: 0.7917\n",
      "Epoch 93: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 2.1348 - accuracy: 0.7959 - val_loss: 3.2543 - val_accuracy: 0.6800\n",
      "Epoch 94/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.1870 - accuracy: 0.7604\n",
      "Epoch 94: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.2031 - accuracy: 0.7551 - val_loss: 3.2325 - val_accuracy: 0.6400\n",
      "Epoch 95/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.2280 - accuracy: 0.6875\n",
      "Epoch 95: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 2.2337 - accuracy: 0.6837 - val_loss: 3.2217 - val_accuracy: 0.7600\n",
      "Epoch 96/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.2318 - accuracy: 0.7708\n",
      "Epoch 96: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.2401 - accuracy: 0.7653 - val_loss: 3.2112 - val_accuracy: 0.7200\n",
      "Epoch 97/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.0632 - accuracy: 0.8125\n",
      "Epoch 97: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.0722 - accuracy: 0.8061 - val_loss: 3.2011 - val_accuracy: 0.6800\n",
      "Epoch 98/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.1398 - accuracy: 0.7292\n",
      "Epoch 98: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.1415 - accuracy: 0.7245 - val_loss: 3.1984 - val_accuracy: 0.8000\n",
      "Epoch 99/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.0499 - accuracy: 0.8021\n",
      "Epoch 99: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 2.0486 - accuracy: 0.8061 - val_loss: 3.1628 - val_accuracy: 0.8000\n",
      "Epoch 100/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.0530 - accuracy: 0.7917\n",
      "Epoch 100: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 1s 190ms/step - loss: 2.0635 - accuracy: 0.7755 - val_loss: 3.1582 - val_accuracy: 0.7600\n",
      "Epoch 101/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.2233 - accuracy: 0.7396\n",
      "Epoch 101: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 113ms/step - loss: 2.2353 - accuracy: 0.7347 - val_loss: 3.1386 - val_accuracy: 0.6400\n",
      "Epoch 102/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.1161 - accuracy: 0.7083\n",
      "Epoch 102: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 2.1328 - accuracy: 0.7041 - val_loss: 3.1387 - val_accuracy: 0.7200\n",
      "Epoch 103/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.0192 - accuracy: 0.7653\n",
      "Epoch 103: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 2.0192 - accuracy: 0.7653 - val_loss: 3.1237 - val_accuracy: 0.7600\n",
      "Epoch 104/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.0401 - accuracy: 0.7500\n",
      "Epoch 104: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 2.0344 - accuracy: 0.7551 - val_loss: 3.1060 - val_accuracy: 0.7200\n",
      "Epoch 105/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.0809 - accuracy: 0.7812\n",
      "Epoch 105: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 2.0702 - accuracy: 0.7857 - val_loss: 3.0861 - val_accuracy: 0.7600\n",
      "Epoch 106/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.1223 - accuracy: 0.7396\n",
      "Epoch 106: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 2.1259 - accuracy: 0.7347 - val_loss: 3.0782 - val_accuracy: 0.7200\n",
      "Epoch 107/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.9753 - accuracy: 0.8021\n",
      "Epoch 107: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.9749 - accuracy: 0.8061 - val_loss: 3.0535 - val_accuracy: 0.6000\n",
      "Epoch 108/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.0891 - accuracy: 0.7500\n",
      "Epoch 108: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 2.0794 - accuracy: 0.7551 - val_loss: 3.0432 - val_accuracy: 0.7600\n",
      "Epoch 109/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.0040 - accuracy: 0.8021\n",
      "Epoch 109: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.9942 - accuracy: 0.8061 - val_loss: 3.0238 - val_accuracy: 0.6800\n",
      "Epoch 110/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.1115 - accuracy: 0.7812\n",
      "Epoch 110: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 2.1005 - accuracy: 0.7857 - val_loss: 3.0269 - val_accuracy: 0.7200\n",
      "Epoch 111/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.0560 - accuracy: 0.7500\n",
      "Epoch 111: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.0424 - accuracy: 0.7551 - val_loss: 3.0050 - val_accuracy: 0.7200\n",
      "Epoch 112/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.9166 - accuracy: 0.8229\n",
      "Epoch 112: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.9334 - accuracy: 0.8163 - val_loss: 2.9690 - val_accuracy: 0.7200\n",
      "Epoch 113/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.9093 - accuracy: 0.7812\n",
      "Epoch 113: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.9031 - accuracy: 0.7857 - val_loss: 2.9673 - val_accuracy: 0.7200\n",
      "Epoch 114/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.0026 - accuracy: 0.7812\n",
      "Epoch 114: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 1.9896 - accuracy: 0.7857 - val_loss: 2.9545 - val_accuracy: 0.7600\n",
      "Epoch 115/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.9854 - accuracy: 0.7812\n",
      "Epoch 115: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.9812 - accuracy: 0.7857 - val_loss: 2.9443 - val_accuracy: 0.7200\n",
      "Epoch 116/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.9585 - accuracy: 0.7917\n",
      "Epoch 116: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.9511 - accuracy: 0.7959 - val_loss: 2.9367 - val_accuracy: 0.7200\n",
      "Epoch 117/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.9315 - accuracy: 0.7708\n",
      "Epoch 117: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.9228 - accuracy: 0.7755 - val_loss: 2.9292 - val_accuracy: 0.7600\n",
      "Epoch 118/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.9596 - accuracy: 0.7653\n",
      "Epoch 118: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 1.9596 - accuracy: 0.7653 - val_loss: 2.9067 - val_accuracy: 0.7600\n",
      "Epoch 119/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.9086 - accuracy: 0.7604\n",
      "Epoch 119: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.9011 - accuracy: 0.7653 - val_loss: 2.8817 - val_accuracy: 0.7200\n",
      "Epoch 120/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.8344 - accuracy: 0.8646\n",
      "Epoch 120: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 1.8360 - accuracy: 0.8571 - val_loss: 2.8589 - val_accuracy: 0.7600\n",
      "Epoch 121/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.8568 - accuracy: 0.7917\n",
      "Epoch 121: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.8475 - accuracy: 0.7959 - val_loss: 2.8399 - val_accuracy: 0.8000\n",
      "Epoch 122/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.8855 - accuracy: 0.7812\n",
      "Epoch 122: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.9003 - accuracy: 0.7755 - val_loss: 2.8270 - val_accuracy: 0.7200\n",
      "Epoch 123/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.9429 - accuracy: 0.7812\n",
      "Epoch 123: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.9562 - accuracy: 0.7653 - val_loss: 2.8527 - val_accuracy: 0.6800\n",
      "Epoch 124/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.8907 - accuracy: 0.7708\n",
      "Epoch 124: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.8791 - accuracy: 0.7755 - val_loss: 2.8154 - val_accuracy: 0.7200\n",
      "Epoch 125/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.8767 - accuracy: 0.8163\n",
      "Epoch 125: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.8767 - accuracy: 0.8163 - val_loss: 2.7906 - val_accuracy: 0.7600\n",
      "Epoch 126/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.7935 - accuracy: 0.8333\n",
      "Epoch 126: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.8199 - accuracy: 0.8265 - val_loss: 2.7951 - val_accuracy: 0.7200\n",
      "Epoch 127/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.7276 - accuracy: 0.8333\n",
      "Epoch 127: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.7219 - accuracy: 0.8367 - val_loss: 2.7623 - val_accuracy: 0.7600\n",
      "Epoch 128/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.8329 - accuracy: 0.8125\n",
      "Epoch 128: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.8354 - accuracy: 0.8061 - val_loss: 2.7443 - val_accuracy: 0.8000\n",
      "Epoch 129/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.6856 - accuracy: 0.8750\n",
      "Epoch 129: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.7072 - accuracy: 0.8673 - val_loss: 2.7511 - val_accuracy: 0.7600\n",
      "Epoch 130/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.6580 - accuracy: 0.8438\n",
      "Epoch 130: val_accuracy improved from 0.80000 to 0.84000, saving model to onehot.hdf5\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.6719 - accuracy: 0.8367 - val_loss: 2.7239 - val_accuracy: 0.8400\n",
      "Epoch 131/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.8135 - accuracy: 0.8229\n",
      "Epoch 131: val_accuracy did not improve from 0.84000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.8101 - accuracy: 0.8265 - val_loss: 2.6836 - val_accuracy: 0.7600\n",
      "Epoch 132/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.7771 - accuracy: 0.7917\n",
      "Epoch 132: val_accuracy did not improve from 0.84000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.7737 - accuracy: 0.7959 - val_loss: 2.7053 - val_accuracy: 0.7600\n",
      "Epoch 133/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.7586 - accuracy: 0.8229\n",
      "Epoch 133: val_accuracy did not improve from 0.84000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.7516 - accuracy: 0.8265 - val_loss: 2.6646 - val_accuracy: 0.8000\n",
      "Epoch 134/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.8129 - accuracy: 0.8125\n",
      "Epoch 134: val_accuracy did not improve from 0.84000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.8081 - accuracy: 0.8163 - val_loss: 2.6355 - val_accuracy: 0.7600\n",
      "Epoch 135/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.7986 - accuracy: 0.8229\n",
      "Epoch 135: val_accuracy did not improve from 0.84000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.7903 - accuracy: 0.8265 - val_loss: 2.6095 - val_accuracy: 0.8000\n",
      "Epoch 136/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.8227 - accuracy: 0.8229\n",
      "Epoch 136: val_accuracy did not improve from 0.84000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.8169 - accuracy: 0.8265 - val_loss: 2.6447 - val_accuracy: 0.6800\n",
      "Epoch 137/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.7185 - accuracy: 0.8542\n",
      "Epoch 137: val_accuracy did not improve from 0.84000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.7090 - accuracy: 0.8571 - val_loss: 2.6113 - val_accuracy: 0.8000\n",
      "Epoch 138/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.7438 - accuracy: 0.8125\n",
      "Epoch 138: val_accuracy did not improve from 0.84000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.7409 - accuracy: 0.8163 - val_loss: 2.5975 - val_accuracy: 0.8400\n",
      "Epoch 139/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.7163 - accuracy: 0.8021\n",
      "Epoch 139: val_accuracy did not improve from 0.84000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.7069 - accuracy: 0.8061 - val_loss: 2.5708 - val_accuracy: 0.8400\n",
      "Epoch 140/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.6318 - accuracy: 0.8646\n",
      "Epoch 140: val_accuracy improved from 0.84000 to 0.92000, saving model to onehot.hdf5\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.6430 - accuracy: 0.8571 - val_loss: 2.5678 - val_accuracy: 0.9200\n",
      "Epoch 141/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.7887 - accuracy: 0.8646\n",
      "Epoch 141: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.7951 - accuracy: 0.8571 - val_loss: 2.5502 - val_accuracy: 0.8400\n",
      "Epoch 142/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.6815 - accuracy: 0.8438\n",
      "Epoch 142: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.6725 - accuracy: 0.8469 - val_loss: 2.5321 - val_accuracy: 0.8000\n",
      "Epoch 143/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.6501 - accuracy: 0.8333\n",
      "Epoch 143: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.6438 - accuracy: 0.8367 - val_loss: 2.5316 - val_accuracy: 0.7600\n",
      "Epoch 144/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.6565 - accuracy: 0.8229\n",
      "Epoch 144: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.6479 - accuracy: 0.8265 - val_loss: 2.5031 - val_accuracy: 0.8400\n",
      "Epoch 145/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.6513 - accuracy: 0.8542\n",
      "Epoch 145: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.6529 - accuracy: 0.8469 - val_loss: 2.4697 - val_accuracy: 0.8400\n",
      "Epoch 146/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.7026 - accuracy: 0.8229\n",
      "Epoch 146: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.7038 - accuracy: 0.8163 - val_loss: 2.4480 - val_accuracy: 0.7600\n",
      "Epoch 147/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.7573 - accuracy: 0.8333\n",
      "Epoch 147: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.7660 - accuracy: 0.8265 - val_loss: 2.4505 - val_accuracy: 0.8000\n",
      "Epoch 148/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.6046 - accuracy: 0.8646\n",
      "Epoch 148: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.6300 - accuracy: 0.8571 - val_loss: 2.4334 - val_accuracy: 0.8000\n",
      "Epoch 149/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.6413 - accuracy: 0.8438\n",
      "Epoch 149: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.6439 - accuracy: 0.8367 - val_loss: 2.4004 - val_accuracy: 0.8400\n",
      "Epoch 150/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.6500 - accuracy: 0.8438\n",
      "Epoch 150: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.6519 - accuracy: 0.8469 - val_loss: 2.3872 - val_accuracy: 0.8400\n",
      "Epoch 151/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.6134 - accuracy: 0.8542\n",
      "Epoch 151: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.6049 - accuracy: 0.8571 - val_loss: 2.3783 - val_accuracy: 0.8400\n",
      "Epoch 152/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.5890 - accuracy: 0.8646\n",
      "Epoch 152: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.5935 - accuracy: 0.8571 - val_loss: 2.3783 - val_accuracy: 0.8000\n",
      "Epoch 153/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.5435 - accuracy: 0.8750\n",
      "Epoch 153: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.5428 - accuracy: 0.8776 - val_loss: 2.3743 - val_accuracy: 0.6800\n",
      "Epoch 154/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.6628 - accuracy: 0.8229\n",
      "Epoch 154: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.6617 - accuracy: 0.8265 - val_loss: 2.4014 - val_accuracy: 0.6400\n",
      "Epoch 155/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.6191 - accuracy: 0.8542\n",
      "Epoch 155: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.6107 - accuracy: 0.8571 - val_loss: 2.3301 - val_accuracy: 0.8000\n",
      "Epoch 156/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.5650 - accuracy: 0.8125\n",
      "Epoch 156: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.5595 - accuracy: 0.8163 - val_loss: 2.3043 - val_accuracy: 0.8000\n",
      "Epoch 157/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.6428 - accuracy: 0.8438\n",
      "Epoch 157: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.6359 - accuracy: 0.8469 - val_loss: 2.3387 - val_accuracy: 0.8000\n",
      "Epoch 158/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.6007 - accuracy: 0.8542\n",
      "Epoch 158: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.5975 - accuracy: 0.8571 - val_loss: 2.2994 - val_accuracy: 0.8000\n",
      "Epoch 159/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.5007 - accuracy: 0.8776\n",
      "Epoch 159: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.5007 - accuracy: 0.8776 - val_loss: 2.2754 - val_accuracy: 0.8400\n",
      "Epoch 160/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.5674 - accuracy: 0.8646\n",
      "Epoch 160: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.5620 - accuracy: 0.8673 - val_loss: 2.2966 - val_accuracy: 0.7200\n",
      "Epoch 161/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.5089 - accuracy: 0.8854\n",
      "Epoch 161: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.5019 - accuracy: 0.8878 - val_loss: 2.2595 - val_accuracy: 0.8000\n",
      "Epoch 162/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.5289 - accuracy: 0.8438\n",
      "Epoch 162: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.5460 - accuracy: 0.8367 - val_loss: 2.2514 - val_accuracy: 0.7600\n",
      "Epoch 163/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.5662 - accuracy: 0.8229\n",
      "Epoch 163: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.5961 - accuracy: 0.8061 - val_loss: 2.2369 - val_accuracy: 0.9200\n",
      "Epoch 164/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.6239 - accuracy: 0.8438\n",
      "Epoch 164: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.6504 - accuracy: 0.8367 - val_loss: 2.2274 - val_accuracy: 0.8400\n",
      "Epoch 165/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.4772 - accuracy: 0.8854\n",
      "Epoch 165: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.5039 - accuracy: 0.8776 - val_loss: 2.1975 - val_accuracy: 0.9200\n",
      "Epoch 166/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.5352 - accuracy: 0.8438\n",
      "Epoch 166: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.5341 - accuracy: 0.8469 - val_loss: 2.1835 - val_accuracy: 0.8000\n",
      "Epoch 167/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.5640 - accuracy: 0.8333\n",
      "Epoch 167: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.5667 - accuracy: 0.8265 - val_loss: 2.1867 - val_accuracy: 0.8400\n",
      "Epoch 168/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.5798 - accuracy: 0.8438\n",
      "Epoch 168: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.5783 - accuracy: 0.8469 - val_loss: 2.1450 - val_accuracy: 0.8800\n",
      "Epoch 169/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.4496 - accuracy: 0.9062\n",
      "Epoch 169: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.4453 - accuracy: 0.9082 - val_loss: 2.1059 - val_accuracy: 0.8800\n",
      "Epoch 170/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.4300 - accuracy: 0.9167\n",
      "Epoch 170: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.4505 - accuracy: 0.9082 - val_loss: 2.1528 - val_accuracy: 0.8800\n",
      "Epoch 171/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3944 - accuracy: 0.8958\n",
      "Epoch 171: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.3960 - accuracy: 0.8980 - val_loss: 2.1153 - val_accuracy: 0.9200\n",
      "Epoch 172/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.5868 - accuracy: 0.8438\n",
      "Epoch 172: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.5782 - accuracy: 0.8469 - val_loss: 2.1230 - val_accuracy: 0.8800\n",
      "Epoch 173/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.4400 - accuracy: 0.8646\n",
      "Epoch 173: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.4339 - accuracy: 0.8673 - val_loss: 2.1022 - val_accuracy: 0.8800\n",
      "Epoch 174/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.4585 - accuracy: 0.8958\n",
      "Epoch 174: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.4607 - accuracy: 0.8980 - val_loss: 2.1254 - val_accuracy: 0.8000\n",
      "Epoch 175/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.5079 - accuracy: 0.8646\n",
      "Epoch 175: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.5001 - accuracy: 0.8673 - val_loss: 2.0810 - val_accuracy: 0.9200\n",
      "Epoch 176/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.4806 - accuracy: 0.8646\n",
      "Epoch 176: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.4909 - accuracy: 0.8571 - val_loss: 2.0540 - val_accuracy: 0.8800\n",
      "Epoch 177/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.4553 - accuracy: 0.8750\n",
      "Epoch 177: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.4530 - accuracy: 0.8776 - val_loss: 2.0626 - val_accuracy: 0.8000\n",
      "Epoch 178/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.4481 - accuracy: 0.8542\n",
      "Epoch 178: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.4412 - accuracy: 0.8571 - val_loss: 2.0248 - val_accuracy: 0.8800\n",
      "Epoch 179/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3631 - accuracy: 0.9271\n",
      "Epoch 179: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.3591 - accuracy: 0.9286 - val_loss: 2.0206 - val_accuracy: 0.7600\n",
      "Epoch 180/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4392 - accuracy: 0.8980\n",
      "Epoch 180: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.4392 - accuracy: 0.8980 - val_loss: 2.0301 - val_accuracy: 0.8800\n",
      "Epoch 181/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3913 - accuracy: 0.9167\n",
      "Epoch 181: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.3877 - accuracy: 0.9184 - val_loss: 2.0133 - val_accuracy: 0.8800\n",
      "Epoch 182/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3860 - accuracy: 0.8854\n",
      "Epoch 182: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.3861 - accuracy: 0.8878 - val_loss: 1.9498 - val_accuracy: 0.8400\n",
      "Epoch 183/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3186 - accuracy: 0.8854\n",
      "Epoch 183: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.3149 - accuracy: 0.8878 - val_loss: 1.9512 - val_accuracy: 0.9200\n",
      "Epoch 184/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.4001 - accuracy: 0.9167\n",
      "Epoch 184: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.3946 - accuracy: 0.9184 - val_loss: 1.9654 - val_accuracy: 0.8000\n",
      "Epoch 185/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3504 - accuracy: 0.8854\n",
      "Epoch 185: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.3476 - accuracy: 0.8878 - val_loss: 1.9576 - val_accuracy: 0.8800\n",
      "Epoch 186/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3199 - accuracy: 0.9271\n",
      "Epoch 186: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.3152 - accuracy: 0.9286 - val_loss: 1.9153 - val_accuracy: 0.8000\n",
      "Epoch 187/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.4623 - accuracy: 0.8542\n",
      "Epoch 187: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.4646 - accuracy: 0.8571 - val_loss: 1.9395 - val_accuracy: 0.9200\n",
      "Epoch 188/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3645 - accuracy: 0.8958\n",
      "Epoch 188: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.3616 - accuracy: 0.8980 - val_loss: 1.9002 - val_accuracy: 0.8800\n",
      "Epoch 189/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.4043 - accuracy: 0.8750\n",
      "Epoch 189: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.3975 - accuracy: 0.8776 - val_loss: 1.8752 - val_accuracy: 0.9200\n",
      "Epoch 190/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3947 - accuracy: 0.8958\n",
      "Epoch 190: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.3945 - accuracy: 0.8980 - val_loss: 1.8820 - val_accuracy: 0.9200\n",
      "Epoch 191/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3650 - accuracy: 0.8958\n",
      "Epoch 191: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.3649 - accuracy: 0.8980 - val_loss: 1.8643 - val_accuracy: 0.8800\n",
      "Epoch 192/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3748 - accuracy: 0.8958\n",
      "Epoch 192: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.3687 - accuracy: 0.8980 - val_loss: 1.8642 - val_accuracy: 0.8800\n",
      "Epoch 193/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2590 - accuracy: 0.9271\n",
      "Epoch 193: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.2639 - accuracy: 0.9184 - val_loss: 1.8823 - val_accuracy: 0.8000\n",
      "Epoch 194/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3400 - accuracy: 0.9062\n",
      "Epoch 194: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.3378 - accuracy: 0.9082 - val_loss: 1.8391 - val_accuracy: 0.9200\n",
      "Epoch 195/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3168 - accuracy: 0.9271\n",
      "Epoch 195: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.3118 - accuracy: 0.9286 - val_loss: 1.8482 - val_accuracy: 0.9200\n",
      "Epoch 196/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3188 - accuracy: 0.9062\n",
      "Epoch 196: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.3167 - accuracy: 0.9082 - val_loss: 1.8052 - val_accuracy: 0.8800\n",
      "Epoch 197/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2286 - accuracy: 0.9479\n",
      "Epoch 197: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.2440 - accuracy: 0.9388 - val_loss: 1.9010 - val_accuracy: 0.8400\n",
      "Epoch 198/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3478 - accuracy: 0.8854\n",
      "Epoch 198: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.3426 - accuracy: 0.8878 - val_loss: 1.8576 - val_accuracy: 0.8400\n",
      "Epoch 199/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3095 - accuracy: 0.8854\n",
      "Epoch 199: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.3041 - accuracy: 0.8878 - val_loss: 1.8025 - val_accuracy: 0.8800\n",
      "Epoch 200/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3301 - accuracy: 0.8542\n",
      "Epoch 200: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.3326 - accuracy: 0.8571 - val_loss: 1.8138 - val_accuracy: 0.8400\n",
      "Epoch 201/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3901 - accuracy: 0.8542\n",
      "Epoch 201: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.3853 - accuracy: 0.8571 - val_loss: 1.7939 - val_accuracy: 0.8800\n",
      "Epoch 202/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3227 - accuracy: 0.8750\n",
      "Epoch 202: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.3284 - accuracy: 0.8776 - val_loss: 1.7503 - val_accuracy: 0.9200\n",
      "Epoch 203/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3387 - accuracy: 0.8542\n",
      "Epoch 203: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.3318 - accuracy: 0.8571 - val_loss: 1.7644 - val_accuracy: 0.9200\n",
      "Epoch 204/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2288 - accuracy: 0.9271\n",
      "Epoch 204: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.2268 - accuracy: 0.9286 - val_loss: 1.7596 - val_accuracy: 0.9200\n",
      "Epoch 205/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1857 - accuracy: 0.9592\n",
      "Epoch 205: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 1.1857 - accuracy: 0.9592 - val_loss: 1.7900 - val_accuracy: 0.8400\n",
      "Epoch 206/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2194 - accuracy: 0.9167\n",
      "Epoch 206: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.2159 - accuracy: 0.9184 - val_loss: 1.7367 - val_accuracy: 0.9200\n",
      "Epoch 207/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2186 - accuracy: 0.9167\n",
      "Epoch 207: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.2331 - accuracy: 0.9082 - val_loss: 1.7812 - val_accuracy: 0.8400\n",
      "Epoch 208/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3014 - accuracy: 0.8750\n",
      "Epoch 208: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.2952 - accuracy: 0.8776 - val_loss: 1.7466 - val_accuracy: 0.8400\n",
      "Epoch 209/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1978 - accuracy: 0.9375\n",
      "Epoch 209: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.1945 - accuracy: 0.9388 - val_loss: 1.7431 - val_accuracy: 0.8400\n",
      "Epoch 210/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2760 - accuracy: 0.9062\n",
      "Epoch 210: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.2822 - accuracy: 0.8980 - val_loss: 1.7663 - val_accuracy: 0.8000\n",
      "Epoch 211/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2723 - accuracy: 0.9167\n",
      "Epoch 211: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.2688 - accuracy: 0.9184 - val_loss: 1.6914 - val_accuracy: 0.8800\n",
      "Epoch 212/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2187 - accuracy: 0.9375\n",
      "Epoch 212: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.2139 - accuracy: 0.9388 - val_loss: 1.6883 - val_accuracy: 0.9200\n",
      "Epoch 213/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2187 - accuracy: 0.8958\n",
      "Epoch 213: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.2141 - accuracy: 0.8980 - val_loss: 1.6743 - val_accuracy: 0.9200\n",
      "Epoch 214/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1838 - accuracy: 0.9271\n",
      "Epoch 214: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.1828 - accuracy: 0.9286 - val_loss: 1.6583 - val_accuracy: 0.8800\n",
      "Epoch 215/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2143 - accuracy: 0.9271\n",
      "Epoch 215: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.2166 - accuracy: 0.9184 - val_loss: 1.7295 - val_accuracy: 0.8400\n",
      "Epoch 216/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2323 - accuracy: 0.9062\n",
      "Epoch 216: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.2337 - accuracy: 0.9082 - val_loss: 1.7615 - val_accuracy: 0.8000\n",
      "Epoch 217/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1639 - accuracy: 0.9062\n",
      "Epoch 217: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.1694 - accuracy: 0.8980 - val_loss: 1.7926 - val_accuracy: 0.8000\n",
      "Epoch 218/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2787 - accuracy: 0.8646\n",
      "Epoch 218: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.2738 - accuracy: 0.8673 - val_loss: 1.7190 - val_accuracy: 0.8400\n",
      "Epoch 219/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1831 - accuracy: 0.9062\n",
      "Epoch 219: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.1862 - accuracy: 0.9082 - val_loss: 1.7748 - val_accuracy: 0.7200\n",
      "Epoch 220/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2367 - accuracy: 0.9271\n",
      "Epoch 220: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.2310 - accuracy: 0.9286 - val_loss: 1.7295 - val_accuracy: 0.8000\n",
      "Epoch 221/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2076 - accuracy: 0.8750\n",
      "Epoch 221: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.2022 - accuracy: 0.8776 - val_loss: 1.6730 - val_accuracy: 0.8400\n",
      "Epoch 222/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1899 - accuracy: 0.8958\n",
      "Epoch 222: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.1903 - accuracy: 0.8980 - val_loss: 1.7413 - val_accuracy: 0.7600\n",
      "Epoch 223/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1980 - accuracy: 0.9167\n",
      "Epoch 223: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.1950 - accuracy: 0.9184 - val_loss: 1.7097 - val_accuracy: 0.8000\n",
      "Epoch 224/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1448 - accuracy: 0.9271\n",
      "Epoch 224: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.1504 - accuracy: 0.9286 - val_loss: 1.6871 - val_accuracy: 0.8400\n",
      "Epoch 225/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1889 - accuracy: 0.8854\n",
      "Epoch 225: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.1853 - accuracy: 0.8878 - val_loss: 1.6822 - val_accuracy: 0.8400\n",
      "Epoch 226/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1740 - accuracy: 0.9375\n",
      "Epoch 226: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.1700 - accuracy: 0.9388 - val_loss: 1.6571 - val_accuracy: 0.8000\n",
      "Epoch 227/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0840 - accuracy: 0.9688\n",
      "Epoch 227: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.0847 - accuracy: 0.9694 - val_loss: 1.7062 - val_accuracy: 0.7200\n",
      "Epoch 228/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1528 - accuracy: 0.9271\n",
      "Epoch 228: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.1481 - accuracy: 0.9286 - val_loss: 1.6336 - val_accuracy: 0.8400\n",
      "Epoch 229/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1811 - accuracy: 0.8750\n",
      "Epoch 229: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.1758 - accuracy: 0.8776 - val_loss: 1.6295 - val_accuracy: 0.8400\n",
      "Epoch 230/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1541 - accuracy: 0.9167\n",
      "Epoch 230: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.1633 - accuracy: 0.9082 - val_loss: 1.7199 - val_accuracy: 0.7600\n",
      "Epoch 231/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2046 - accuracy: 0.8958\n",
      "Epoch 231: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.1986 - accuracy: 0.8980 - val_loss: 1.6513 - val_accuracy: 0.8000\n",
      "Epoch 232/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1892 - accuracy: 0.8958\n",
      "Epoch 232: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.1909 - accuracy: 0.8980 - val_loss: 1.6865 - val_accuracy: 0.7600\n",
      "Epoch 233/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0676 - accuracy: 0.9479\n",
      "Epoch 233: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.0721 - accuracy: 0.9490 - val_loss: 1.6810 - val_accuracy: 0.6800\n",
      "Epoch 234/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1427 - accuracy: 0.9062\n",
      "Epoch 234: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.1495 - accuracy: 0.8980 - val_loss: 1.6260 - val_accuracy: 0.8400\n",
      "Epoch 235/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0700 - accuracy: 0.9490\n",
      "Epoch 235: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 1.0700 - accuracy: 0.9490 - val_loss: 1.5979 - val_accuracy: 0.8400\n",
      "Epoch 236/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0700 - accuracy: 0.9479\n",
      "Epoch 236: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.0665 - accuracy: 0.9490 - val_loss: 1.6004 - val_accuracy: 0.8000\n",
      "Epoch 237/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0999 - accuracy: 0.9167\n",
      "Epoch 237: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.0958 - accuracy: 0.9184 - val_loss: 1.6182 - val_accuracy: 0.7200\n",
      "Epoch 238/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1559 - accuracy: 0.9062\n",
      "Epoch 238: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.1515 - accuracy: 0.9082 - val_loss: 1.5765 - val_accuracy: 0.8800\n",
      "Epoch 239/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0877 - accuracy: 0.9167\n",
      "Epoch 239: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.0846 - accuracy: 0.9184 - val_loss: 1.5560 - val_accuracy: 0.8400\n",
      "Epoch 240/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0974 - accuracy: 0.9062\n",
      "Epoch 240: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.0931 - accuracy: 0.9082 - val_loss: 1.5385 - val_accuracy: 0.8000\n",
      "Epoch 241/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1790 - accuracy: 0.8854\n",
      "Epoch 241: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.1729 - accuracy: 0.8878 - val_loss: 1.5544 - val_accuracy: 0.8400\n",
      "Epoch 242/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0307 - accuracy: 0.9479\n",
      "Epoch 242: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.0304 - accuracy: 0.9490 - val_loss: 1.6053 - val_accuracy: 0.7600\n",
      "Epoch 243/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0607 - accuracy: 0.9375\n",
      "Epoch 243: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.0618 - accuracy: 0.9388 - val_loss: 1.5761 - val_accuracy: 0.7600\n",
      "Epoch 244/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0884 - accuracy: 0.9271\n",
      "Epoch 244: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.0844 - accuracy: 0.9286 - val_loss: 1.5508 - val_accuracy: 0.8000\n",
      "Epoch 245/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0448 - accuracy: 0.9375\n",
      "Epoch 245: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.0640 - accuracy: 0.9286 - val_loss: 1.5990 - val_accuracy: 0.7200\n",
      "Epoch 246/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1084 - accuracy: 0.9184\n",
      "Epoch 246: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 1.1084 - accuracy: 0.9184 - val_loss: 1.5341 - val_accuracy: 0.9200\n",
      "Epoch 247/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0873 - accuracy: 0.9167\n",
      "Epoch 247: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.0863 - accuracy: 0.9184 - val_loss: 1.5437 - val_accuracy: 0.8000\n",
      "Epoch 248/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0790 - accuracy: 0.9271\n",
      "Epoch 248: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.0747 - accuracy: 0.9286 - val_loss: 1.5245 - val_accuracy: 0.8400\n",
      "Epoch 249/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1369 - accuracy: 0.9271\n",
      "Epoch 249: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.1439 - accuracy: 0.9184 - val_loss: 1.5745 - val_accuracy: 0.7600\n",
      "Epoch 250/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0072 - accuracy: 0.9583\n",
      "Epoch 250: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.0056 - accuracy: 0.9592 - val_loss: 1.5418 - val_accuracy: 0.8000\n",
      "Epoch 251/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0099 - accuracy: 0.9479\n",
      "Epoch 251: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.0080 - accuracy: 0.9490 - val_loss: 1.5297 - val_accuracy: 0.8400\n",
      "Epoch 252/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0310 - accuracy: 0.9167\n",
      "Epoch 252: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.0273 - accuracy: 0.9184 - val_loss: 1.5142 - val_accuracy: 0.8400\n",
      "Epoch 253/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0270 - accuracy: 0.9271\n",
      "Epoch 253: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.0233 - accuracy: 0.9286 - val_loss: 1.5020 - val_accuracy: 0.8800\n",
      "Epoch 254/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0639 - accuracy: 0.9167\n",
      "Epoch 254: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.0614 - accuracy: 0.9184 - val_loss: 1.4492 - val_accuracy: 0.9200\n",
      "Epoch 255/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9804 - accuracy: 0.9479\n",
      "Epoch 255: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.9792 - accuracy: 0.9490 - val_loss: 1.4543 - val_accuracy: 0.8800\n",
      "Epoch 256/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0979 - accuracy: 0.9062\n",
      "Epoch 256: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.0927 - accuracy: 0.9082 - val_loss: 1.4739 - val_accuracy: 0.9200\n",
      "Epoch 257/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9464 - accuracy: 0.9583\n",
      "Epoch 257: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.9463 - accuracy: 0.9592 - val_loss: 1.4522 - val_accuracy: 0.8800\n",
      "Epoch 258/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0389 - accuracy: 0.9388\n",
      "Epoch 258: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.0389 - accuracy: 0.9388 - val_loss: 1.4743 - val_accuracy: 0.8800\n",
      "Epoch 259/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1181 - accuracy: 0.8854\n",
      "Epoch 259: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.1132 - accuracy: 0.8878 - val_loss: 1.4318 - val_accuracy: 0.8800\n",
      "Epoch 260/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0376 - accuracy: 0.9167\n",
      "Epoch 260: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.0332 - accuracy: 0.9184 - val_loss: 1.4383 - val_accuracy: 0.8800\n",
      "Epoch 261/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0736 - accuracy: 0.8750\n",
      "Epoch 261: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.0764 - accuracy: 0.8776 - val_loss: 1.4224 - val_accuracy: 0.9200\n",
      "Epoch 262/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0064 - accuracy: 0.9479\n",
      "Epoch 262: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.0028 - accuracy: 0.9490 - val_loss: 1.4249 - val_accuracy: 0.9200\n",
      "Epoch 263/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9438 - accuracy: 0.9583\n",
      "Epoch 263: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.9434 - accuracy: 0.9592 - val_loss: 1.4330 - val_accuracy: 0.8800\n",
      "Epoch 264/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9711 - accuracy: 0.9583\n",
      "Epoch 264: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.9680 - accuracy: 0.9592 - val_loss: 1.4204 - val_accuracy: 0.9200\n",
      "Epoch 265/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0033 - accuracy: 0.9271\n",
      "Epoch 265: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.0068 - accuracy: 0.9286 - val_loss: 1.4032 - val_accuracy: 0.8800\n",
      "Epoch 266/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0478 - accuracy: 0.9062\n",
      "Epoch 266: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.0752 - accuracy: 0.8980 - val_loss: 1.4728 - val_accuracy: 0.7600\n",
      "Epoch 267/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0660 - accuracy: 0.8958\n",
      "Epoch 267: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.0606 - accuracy: 0.8980 - val_loss: 1.4546 - val_accuracy: 0.8000\n",
      "Epoch 268/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1038 - accuracy: 0.8958\n",
      "Epoch 268: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.1022 - accuracy: 0.8980 - val_loss: 1.4320 - val_accuracy: 0.7600\n",
      "Epoch 269/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0212 - accuracy: 0.9375\n",
      "Epoch 269: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.0187 - accuracy: 0.9388 - val_loss: 1.4049 - val_accuracy: 0.8800\n",
      "Epoch 270/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9666 - accuracy: 0.9479\n",
      "Epoch 270: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.9871 - accuracy: 0.9388 - val_loss: 1.4305 - val_accuracy: 0.8400\n",
      "Epoch 271/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9687 - accuracy: 0.9271\n",
      "Epoch 271: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.9655 - accuracy: 0.9286 - val_loss: 1.4181 - val_accuracy: 0.8800\n",
      "Epoch 272/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0668 - accuracy: 0.8854\n",
      "Epoch 272: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.0614 - accuracy: 0.8878 - val_loss: 1.4166 - val_accuracy: 0.8800\n",
      "Epoch 273/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8966 - accuracy: 0.9792\n",
      "Epoch 273: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.8947 - accuracy: 0.9796 - val_loss: 1.4132 - val_accuracy: 0.8800\n",
      "Epoch 274/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9951 - accuracy: 0.9167\n",
      "Epoch 274: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.9938 - accuracy: 0.9184 - val_loss: 1.3827 - val_accuracy: 0.9200\n",
      "Epoch 275/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9411 - accuracy: 0.9167\n",
      "Epoch 275: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.9481 - accuracy: 0.9082 - val_loss: 1.4080 - val_accuracy: 0.8400\n",
      "Epoch 276/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9311 - accuracy: 0.9479\n",
      "Epoch 276: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.9286 - accuracy: 0.9490 - val_loss: 1.4076 - val_accuracy: 0.8000\n",
      "Epoch 277/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0017 - accuracy: 0.9479\n",
      "Epoch 277: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.9976 - accuracy: 0.9490 - val_loss: 1.3989 - val_accuracy: 0.8400\n",
      "Epoch 278/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8873 - accuracy: 0.9792\n",
      "Epoch 278: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8849 - accuracy: 0.9796 - val_loss: 1.4154 - val_accuracy: 0.8000\n",
      "Epoch 279/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0004 - accuracy: 0.9375\n",
      "Epoch 279: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.9963 - accuracy: 0.9388 - val_loss: 1.3797 - val_accuracy: 0.9200\n",
      "Epoch 280/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8943 - accuracy: 0.9479\n",
      "Epoch 280: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.9620 - accuracy: 0.9388 - val_loss: 1.4102 - val_accuracy: 0.8000\n",
      "Epoch 281/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0603 - accuracy: 0.8958\n",
      "Epoch 281: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 1.0543 - accuracy: 0.8980 - val_loss: 1.4133 - val_accuracy: 0.8000\n",
      "Epoch 282/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9286 - accuracy: 0.9583\n",
      "Epoch 282: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.9251 - accuracy: 0.9592 - val_loss: 1.4095 - val_accuracy: 0.8400\n",
      "Epoch 283/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8842 - accuracy: 0.9688\n",
      "Epoch 283: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.8902 - accuracy: 0.9592 - val_loss: 1.4197 - val_accuracy: 0.8000\n",
      "Epoch 284/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9248 - accuracy: 0.9479\n",
      "Epoch 284: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.9235 - accuracy: 0.9490 - val_loss: 1.3938 - val_accuracy: 0.8000\n",
      "Epoch 285/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8891 - accuracy: 0.9583\n",
      "Epoch 285: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.8877 - accuracy: 0.9592 - val_loss: 1.4046 - val_accuracy: 0.8400\n",
      "Epoch 286/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9579 - accuracy: 0.9375\n",
      "Epoch 286: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.9617 - accuracy: 0.9388 - val_loss: 1.3704 - val_accuracy: 0.8800\n",
      "Epoch 287/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8745 - accuracy: 0.9583\n",
      "Epoch 287: val_accuracy improved from 0.92000 to 0.96000, saving model to onehot.hdf5\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.8775 - accuracy: 0.9592 - val_loss: 1.3336 - val_accuracy: 0.9600\n",
      "Epoch 288/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9208 - accuracy: 0.9375\n",
      "Epoch 288: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.9173 - accuracy: 0.9388 - val_loss: 1.3518 - val_accuracy: 0.8800\n",
      "Epoch 289/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8467 - accuracy: 0.9688\n",
      "Epoch 289: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8445 - accuracy: 0.9694 - val_loss: 1.3548 - val_accuracy: 0.8800\n",
      "Epoch 290/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9849 - accuracy: 0.8980\n",
      "Epoch 290: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.9849 - accuracy: 0.8980 - val_loss: 1.3671 - val_accuracy: 0.9200\n",
      "Epoch 291/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8576 - accuracy: 0.9583\n",
      "Epoch 291: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8551 - accuracy: 0.9592 - val_loss: 1.3698 - val_accuracy: 0.8800\n",
      "Epoch 292/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9139 - accuracy: 0.9375\n",
      "Epoch 292: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.9127 - accuracy: 0.9388 - val_loss: 1.3144 - val_accuracy: 0.9200\n",
      "Epoch 293/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8524 - accuracy: 0.9792\n",
      "Epoch 293: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8499 - accuracy: 0.9796 - val_loss: 1.3435 - val_accuracy: 0.8800\n",
      "Epoch 294/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8775 - accuracy: 0.9583\n",
      "Epoch 294: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8975 - accuracy: 0.9490 - val_loss: 1.3895 - val_accuracy: 0.8000\n",
      "Epoch 295/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8917 - accuracy: 0.9271\n",
      "Epoch 295: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8883 - accuracy: 0.9286 - val_loss: 1.3281 - val_accuracy: 0.8800\n",
      "Epoch 296/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8688 - accuracy: 0.9688\n",
      "Epoch 296: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8671 - accuracy: 0.9694 - val_loss: 1.3356 - val_accuracy: 0.8800\n",
      "Epoch 297/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8833 - accuracy: 0.9271\n",
      "Epoch 297: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.8805 - accuracy: 0.9286 - val_loss: 1.2847 - val_accuracy: 0.9200\n",
      "Epoch 298/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8175 - accuracy: 0.9792\n",
      "Epoch 298: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8168 - accuracy: 0.9796 - val_loss: 1.2806 - val_accuracy: 0.9200\n",
      "Epoch 299/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8468 - accuracy: 0.9688\n",
      "Epoch 299: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.8482 - accuracy: 0.9694 - val_loss: 1.3210 - val_accuracy: 0.8000\n",
      "Epoch 300/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8707 - accuracy: 0.9583\n",
      "Epoch 300: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.8674 - accuracy: 0.9592 - val_loss: 1.3288 - val_accuracy: 0.8000\n",
      "Epoch 301/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8406 - accuracy: 0.9375\n",
      "Epoch 301: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8393 - accuracy: 0.9388 - val_loss: 1.3114 - val_accuracy: 0.8000\n",
      "Epoch 302/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8711 - accuracy: 0.9688\n",
      "Epoch 302: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8677 - accuracy: 0.9694 - val_loss: 1.3195 - val_accuracy: 0.8400\n",
      "Epoch 303/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8160 - accuracy: 0.9688\n",
      "Epoch 303: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.8138 - accuracy: 0.9694 - val_loss: 1.3400 - val_accuracy: 0.8400\n",
      "Epoch 304/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7989 - accuracy: 0.9583\n",
      "Epoch 304: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8090 - accuracy: 0.9490 - val_loss: 1.3342 - val_accuracy: 0.8400\n",
      "Epoch 305/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8907 - accuracy: 0.9479\n",
      "Epoch 305: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8867 - accuracy: 0.9490 - val_loss: 1.2914 - val_accuracy: 0.8400\n",
      "Epoch 306/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8395 - accuracy: 0.9271\n",
      "Epoch 306: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8364 - accuracy: 0.9286 - val_loss: 1.2538 - val_accuracy: 0.9200\n",
      "Epoch 307/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8160 - accuracy: 0.9583\n",
      "Epoch 307: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.8134 - accuracy: 0.9592 - val_loss: 1.2570 - val_accuracy: 0.8800\n",
      "Epoch 308/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8443 - accuracy: 0.9479\n",
      "Epoch 308: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8431 - accuracy: 0.9490 - val_loss: 1.2468 - val_accuracy: 0.9200\n",
      "Epoch 309/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8318 - accuracy: 0.9271\n",
      "Epoch 309: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8326 - accuracy: 0.9286 - val_loss: 1.2102 - val_accuracy: 0.9200\n",
      "Epoch 310/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8463 - accuracy: 0.9375\n",
      "Epoch 310: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8429 - accuracy: 0.9388 - val_loss: 1.2413 - val_accuracy: 0.9200\n",
      "Epoch 311/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7820 - accuracy: 0.9792\n",
      "Epoch 311: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7808 - accuracy: 0.9796 - val_loss: 1.2448 - val_accuracy: 0.9200\n",
      "Epoch 312/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8013 - accuracy: 0.9479\n",
      "Epoch 312: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8018 - accuracy: 0.9490 - val_loss: 1.2535 - val_accuracy: 0.8400\n",
      "Epoch 313/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8364 - accuracy: 0.9271\n",
      "Epoch 313: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.8335 - accuracy: 0.9286 - val_loss: 1.2061 - val_accuracy: 0.8400\n",
      "Epoch 314/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7441 - accuracy: 0.9898\n",
      "Epoch 314: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7441 - accuracy: 0.9898 - val_loss: 1.2264 - val_accuracy: 0.8400\n",
      "Epoch 315/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8092 - accuracy: 0.9583\n",
      "Epoch 315: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.8063 - accuracy: 0.9592 - val_loss: 1.2689 - val_accuracy: 0.8400\n",
      "Epoch 316/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7805 - accuracy: 0.9583\n",
      "Epoch 316: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7925 - accuracy: 0.9490 - val_loss: 1.2864 - val_accuracy: 0.8400\n",
      "Epoch 317/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8316 - accuracy: 0.9375\n",
      "Epoch 317: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8281 - accuracy: 0.9388 - val_loss: 1.2234 - val_accuracy: 0.9600\n",
      "Epoch 318/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8187 - accuracy: 0.9583\n",
      "Epoch 318: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8225 - accuracy: 0.9592 - val_loss: 1.2607 - val_accuracy: 0.8400\n",
      "Epoch 319/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9699 - accuracy: 0.8750\n",
      "Epoch 319: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.9634 - accuracy: 0.8776 - val_loss: 1.2047 - val_accuracy: 0.9600\n",
      "Epoch 320/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8342 - accuracy: 0.9479\n",
      "Epoch 320: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8313 - accuracy: 0.9490 - val_loss: 1.2149 - val_accuracy: 0.9600\n",
      "Epoch 321/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7364 - accuracy: 0.9688\n",
      "Epoch 321: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7445 - accuracy: 0.9592 - val_loss: 1.2317 - val_accuracy: 0.8800\n",
      "Epoch 322/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8384 - accuracy: 0.9688\n",
      "Epoch 322: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8376 - accuracy: 0.9694 - val_loss: 1.1930 - val_accuracy: 0.9600\n",
      "Epoch 323/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8385 - accuracy: 0.9271\n",
      "Epoch 323: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8456 - accuracy: 0.9184 - val_loss: 1.2302 - val_accuracy: 0.8000\n",
      "Epoch 324/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7222 - accuracy: 0.9792\n",
      "Epoch 324: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.7238 - accuracy: 0.9796 - val_loss: 1.2056 - val_accuracy: 0.9200\n",
      "Epoch 325/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7824 - accuracy: 0.9479\n",
      "Epoch 325: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.7797 - accuracy: 0.9490 - val_loss: 1.1941 - val_accuracy: 0.9600\n",
      "Epoch 326/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8010 - accuracy: 0.9688\n",
      "Epoch 326: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8074 - accuracy: 0.9592 - val_loss: 1.2087 - val_accuracy: 0.9600\n",
      "Epoch 327/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7624 - accuracy: 0.9688\n",
      "Epoch 327: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7708 - accuracy: 0.9592 - val_loss: 1.1933 - val_accuracy: 0.9200\n",
      "Epoch 328/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7750 - accuracy: 0.9479\n",
      "Epoch 328: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.7766 - accuracy: 0.9490 - val_loss: 1.1480 - val_accuracy: 0.9600\n",
      "Epoch 329/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7808 - accuracy: 0.9375\n",
      "Epoch 329: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.7789 - accuracy: 0.9388 - val_loss: 1.1412 - val_accuracy: 0.9600\n",
      "Epoch 330/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8284 - accuracy: 0.9375\n",
      "Epoch 330: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.8244 - accuracy: 0.9388 - val_loss: 1.1297 - val_accuracy: 0.9600\n",
      "Epoch 331/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8023 - accuracy: 0.9479\n",
      "Epoch 331: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7991 - accuracy: 0.9490 - val_loss: 1.1951 - val_accuracy: 0.9200\n",
      "Epoch 332/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7503 - accuracy: 0.9792\n",
      "Epoch 332: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7485 - accuracy: 0.9796 - val_loss: 1.1681 - val_accuracy: 0.9600\n",
      "Epoch 333/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7546 - accuracy: 0.9694\n",
      "Epoch 333: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7546 - accuracy: 0.9694 - val_loss: 1.1748 - val_accuracy: 0.9200\n",
      "Epoch 334/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7844 - accuracy: 0.9375\n",
      "Epoch 334: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7837 - accuracy: 0.9388 - val_loss: 1.2435 - val_accuracy: 0.8000\n",
      "Epoch 335/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7092 - accuracy: 0.9792\n",
      "Epoch 335: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.7097 - accuracy: 0.9796 - val_loss: 1.2178 - val_accuracy: 0.8000\n",
      "Epoch 336/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7668 - accuracy: 0.9583\n",
      "Epoch 336: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7638 - accuracy: 0.9592 - val_loss: 1.2028 - val_accuracy: 0.8400\n",
      "Epoch 337/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7472 - accuracy: 0.9583\n",
      "Epoch 337: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7446 - accuracy: 0.9592 - val_loss: 1.1689 - val_accuracy: 0.8400\n",
      "Epoch 338/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7266 - accuracy: 0.9688\n",
      "Epoch 338: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7250 - accuracy: 0.9694 - val_loss: 1.1422 - val_accuracy: 0.9600\n",
      "Epoch 339/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7040 - accuracy: 0.9792\n",
      "Epoch 339: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7021 - accuracy: 0.9796 - val_loss: 1.1590 - val_accuracy: 0.9600\n",
      "Epoch 340/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6979 - accuracy: 0.9688\n",
      "Epoch 340: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7011 - accuracy: 0.9694 - val_loss: 1.1301 - val_accuracy: 0.9200\n",
      "Epoch 341/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7389 - accuracy: 0.9592\n",
      "Epoch 341: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.7389 - accuracy: 0.9592 - val_loss: 1.1527 - val_accuracy: 0.8800\n",
      "Epoch 342/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7281 - accuracy: 0.9583\n",
      "Epoch 342: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7282 - accuracy: 0.9592 - val_loss: 1.2287 - val_accuracy: 0.8000\n",
      "Epoch 343/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7293 - accuracy: 0.9479\n",
      "Epoch 343: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.7272 - accuracy: 0.9490 - val_loss: 1.1868 - val_accuracy: 0.8400\n",
      "Epoch 344/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6982 - accuracy: 0.9792\n",
      "Epoch 344: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.7157 - accuracy: 0.9694 - val_loss: 1.2404 - val_accuracy: 0.7200\n",
      "Epoch 345/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7969 - accuracy: 0.9583\n",
      "Epoch 345: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7928 - accuracy: 0.9592 - val_loss: 1.1402 - val_accuracy: 0.9200\n",
      "Epoch 346/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7245 - accuracy: 0.9792\n",
      "Epoch 346: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7219 - accuracy: 0.9796 - val_loss: 1.1383 - val_accuracy: 0.8800\n",
      "Epoch 347/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6996 - accuracy: 0.9688\n",
      "Epoch 347: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6994 - accuracy: 0.9694 - val_loss: 1.1082 - val_accuracy: 0.9600\n",
      "Epoch 348/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6917 - accuracy: 0.9792\n",
      "Epoch 348: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.6898 - accuracy: 0.9796 - val_loss: 1.1219 - val_accuracy: 0.9200\n",
      "Epoch 349/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7158 - accuracy: 0.9688\n",
      "Epoch 349: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7139 - accuracy: 0.9694 - val_loss: 1.1249 - val_accuracy: 0.8800\n",
      "Epoch 350/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7460 - accuracy: 0.9688\n",
      "Epoch 350: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.7430 - accuracy: 0.9694 - val_loss: 1.1519 - val_accuracy: 0.8000\n",
      "Epoch 351/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6578 - accuracy: 0.9896\n",
      "Epoch 351: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.6563 - accuracy: 0.9898 - val_loss: 1.1325 - val_accuracy: 0.8000\n",
      "Epoch 352/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7017 - accuracy: 0.9583\n",
      "Epoch 352: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6992 - accuracy: 0.9592 - val_loss: 1.1384 - val_accuracy: 0.8000\n",
      "Epoch 353/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7397 - accuracy: 0.9479\n",
      "Epoch 353: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7368 - accuracy: 0.9490 - val_loss: 1.1208 - val_accuracy: 0.9200\n",
      "Epoch 354/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6583 - accuracy: 0.9688\n",
      "Epoch 354: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.6606 - accuracy: 0.9694 - val_loss: 1.1647 - val_accuracy: 0.8000\n",
      "Epoch 355/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7139 - accuracy: 0.9375\n",
      "Epoch 355: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7116 - accuracy: 0.9388 - val_loss: 1.1268 - val_accuracy: 0.8400\n",
      "Epoch 356/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6765 - accuracy: 0.9583\n",
      "Epoch 356: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.6750 - accuracy: 0.9592 - val_loss: 1.1094 - val_accuracy: 0.9200\n",
      "Epoch 357/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6886 - accuracy: 0.9688\n",
      "Epoch 357: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.6892 - accuracy: 0.9694 - val_loss: 1.1148 - val_accuracy: 0.8800\n",
      "Epoch 358/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6382 - accuracy: 0.9792\n",
      "Epoch 358: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6368 - accuracy: 0.9796 - val_loss: 1.0938 - val_accuracy: 0.9200\n",
      "Epoch 359/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6867 - accuracy: 0.9583\n",
      "Epoch 359: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.6843 - accuracy: 0.9592 - val_loss: 1.1555 - val_accuracy: 0.7600\n",
      "Epoch 360/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6666 - accuracy: 0.9792\n",
      "Epoch 360: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.6656 - accuracy: 0.9796 - val_loss: 1.0892 - val_accuracy: 0.8400\n",
      "Epoch 361/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7886 - accuracy: 0.9167\n",
      "Epoch 361: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7839 - accuracy: 0.9184 - val_loss: 1.1220 - val_accuracy: 0.8000\n",
      "Epoch 362/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6410 - accuracy: 0.9583\n",
      "Epoch 362: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.6399 - accuracy: 0.9592 - val_loss: 1.0673 - val_accuracy: 0.8800\n",
      "Epoch 363/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6557 - accuracy: 0.9688\n",
      "Epoch 363: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.6551 - accuracy: 0.9694 - val_loss: 1.0688 - val_accuracy: 0.8000\n",
      "Epoch 364/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7339 - accuracy: 0.9688\n",
      "Epoch 364: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7302 - accuracy: 0.9694 - val_loss: 1.0799 - val_accuracy: 0.8400\n",
      "Epoch 365/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6548 - accuracy: 0.9688\n",
      "Epoch 365: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.6527 - accuracy: 0.9694 - val_loss: 1.0842 - val_accuracy: 0.8800\n",
      "Epoch 366/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6468 - accuracy: 0.9688\n",
      "Epoch 366: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.6455 - accuracy: 0.9694 - val_loss: 1.0868 - val_accuracy: 0.8000\n",
      "Epoch 367/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6248 - accuracy: 0.9688\n",
      "Epoch 367: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.6235 - accuracy: 0.9694 - val_loss: 1.0766 - val_accuracy: 0.8800\n",
      "Epoch 368/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6580 - accuracy: 0.9688\n",
      "Epoch 368: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.6562 - accuracy: 0.9694 - val_loss: 1.0519 - val_accuracy: 0.8800\n",
      "Epoch 369/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7484 - accuracy: 0.9375\n",
      "Epoch 369: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7443 - accuracy: 0.9388 - val_loss: 1.0761 - val_accuracy: 0.8400\n",
      "Epoch 370/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7236 - accuracy: 0.9375\n",
      "Epoch 370: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7202 - accuracy: 0.9388 - val_loss: 1.0682 - val_accuracy: 0.9200\n",
      "Epoch 371/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5896 - accuracy: 0.9792\n",
      "Epoch 371: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5907 - accuracy: 0.9796 - val_loss: 1.1206 - val_accuracy: 0.8800\n",
      "Epoch 372/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6593 - accuracy: 0.9583\n",
      "Epoch 372: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.6674 - accuracy: 0.9592 - val_loss: 1.0928 - val_accuracy: 0.8800\n",
      "Epoch 373/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5873 - accuracy: 0.9896\n",
      "Epoch 373: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5863 - accuracy: 0.9898 - val_loss: 1.0712 - val_accuracy: 0.8800\n",
      "Epoch 374/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5957 - accuracy: 0.9896\n",
      "Epoch 374: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5945 - accuracy: 0.9898 - val_loss: 1.0826 - val_accuracy: 0.8800\n",
      "Epoch 375/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6119 - accuracy: 0.9583\n",
      "Epoch 375: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.6134 - accuracy: 0.9592 - val_loss: 1.0352 - val_accuracy: 0.9200\n",
      "Epoch 376/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7430 - accuracy: 0.9375\n",
      "Epoch 376: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7390 - accuracy: 0.9388 - val_loss: 1.0064 - val_accuracy: 0.9200\n",
      "Epoch 377/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5910 - accuracy: 0.9896\n",
      "Epoch 377: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.6016 - accuracy: 0.9796 - val_loss: 1.0568 - val_accuracy: 0.8800\n",
      "Epoch 378/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6553 - accuracy: 0.9479\n",
      "Epoch 378: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.6526 - accuracy: 0.9490 - val_loss: 1.0525 - val_accuracy: 0.8800\n",
      "Epoch 379/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6701 - accuracy: 0.9375\n",
      "Epoch 379: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.6680 - accuracy: 0.9388 - val_loss: 1.0506 - val_accuracy: 0.8800\n",
      "Epoch 380/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6988 - accuracy: 0.9286\n",
      "Epoch 380: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.6988 - accuracy: 0.9286 - val_loss: 1.0581 - val_accuracy: 0.8800\n",
      "Epoch 381/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6422 - accuracy: 0.9792\n",
      "Epoch 381: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.6399 - accuracy: 0.9796 - val_loss: 1.0581 - val_accuracy: 0.8800\n",
      "Epoch 382/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5927 - accuracy: 0.9896\n",
      "Epoch 382: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5913 - accuracy: 0.9898 - val_loss: 1.0677 - val_accuracy: 0.8400\n",
      "Epoch 383/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6538 - accuracy: 0.9688\n",
      "Epoch 383: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.6513 - accuracy: 0.9694 - val_loss: 1.0789 - val_accuracy: 0.8000\n",
      "Epoch 384/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6598 - accuracy: 0.9375\n",
      "Epoch 384: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.6704 - accuracy: 0.9286 - val_loss: 1.2024 - val_accuracy: 0.7600\n",
      "Epoch 385/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7325 - accuracy: 0.9271\n",
      "Epoch 385: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7292 - accuracy: 0.9286 - val_loss: 1.0632 - val_accuracy: 0.8800\n",
      "Epoch 386/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5786 - accuracy: 0.9792\n",
      "Epoch 386: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5772 - accuracy: 0.9796 - val_loss: 1.0622 - val_accuracy: 0.8400\n",
      "Epoch 387/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6065 - accuracy: 0.9583\n",
      "Epoch 387: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.6051 - accuracy: 0.9592 - val_loss: 1.0582 - val_accuracy: 0.8800\n",
      "Epoch 388/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5713 - accuracy: 0.9896\n",
      "Epoch 388: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5707 - accuracy: 0.9898 - val_loss: 1.0767 - val_accuracy: 0.8400\n",
      "Epoch 389/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5962 - accuracy: 0.9792\n",
      "Epoch 389: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.5949 - accuracy: 0.9796 - val_loss: 1.0407 - val_accuracy: 0.8400\n",
      "Epoch 390/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5901 - accuracy: 0.9796\n",
      "Epoch 390: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.5901 - accuracy: 0.9796 - val_loss: 0.9980 - val_accuracy: 0.9600\n",
      "Epoch 391/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6034 - accuracy: 0.9479\n",
      "Epoch 391: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.6015 - accuracy: 0.9490 - val_loss: 0.9963 - val_accuracy: 0.9600\n",
      "Epoch 392/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5851 - accuracy: 0.9688\n",
      "Epoch 392: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5890 - accuracy: 0.9694 - val_loss: 1.0087 - val_accuracy: 0.8800\n",
      "Epoch 393/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6279 - accuracy: 0.9688\n",
      "Epoch 393: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.6252 - accuracy: 0.9694 - val_loss: 0.9966 - val_accuracy: 0.8800\n",
      "Epoch 394/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6070 - accuracy: 0.9375\n",
      "Epoch 394: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.6047 - accuracy: 0.9388 - val_loss: 1.0449 - val_accuracy: 0.8400\n",
      "Epoch 395/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6056 - accuracy: 0.9688\n",
      "Epoch 395: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.6033 - accuracy: 0.9694 - val_loss: 1.0894 - val_accuracy: 0.8400\n",
      "Epoch 396/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5913 - accuracy: 0.9792\n",
      "Epoch 396: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5961 - accuracy: 0.9796 - val_loss: 1.0867 - val_accuracy: 0.7600\n",
      "Epoch 397/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5951 - accuracy: 0.9688\n",
      "Epoch 397: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5929 - accuracy: 0.9694 - val_loss: 1.0605 - val_accuracy: 0.7600\n",
      "Epoch 398/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5557 - accuracy: 0.9896\n",
      "Epoch 398: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5545 - accuracy: 0.9898 - val_loss: 1.0678 - val_accuracy: 0.7600\n",
      "Epoch 399/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6014 - accuracy: 0.9583\n",
      "Epoch 399: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5991 - accuracy: 0.9592 - val_loss: 1.1173 - val_accuracy: 0.7600\n",
      "Epoch 400/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5362 - accuracy: 0.9896\n",
      "Epoch 400: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5360 - accuracy: 0.9898 - val_loss: 1.0987 - val_accuracy: 0.7600\n",
      "Epoch 401/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5311 - accuracy: 0.9896\n",
      "Epoch 401: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5301 - accuracy: 0.9898 - val_loss: 1.0730 - val_accuracy: 0.7600\n",
      "Epoch 402/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5990 - accuracy: 0.9688\n",
      "Epoch 402: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5968 - accuracy: 0.9694 - val_loss: 1.0476 - val_accuracy: 0.8000\n",
      "Epoch 403/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5476 - accuracy: 0.9688\n",
      "Epoch 403: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5463 - accuracy: 0.9694 - val_loss: 1.0085 - val_accuracy: 0.8400\n",
      "Epoch 404/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5660 - accuracy: 0.9792\n",
      "Epoch 404: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.5642 - accuracy: 0.9796 - val_loss: 1.0521 - val_accuracy: 0.8000\n",
      "Epoch 405/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5880 - accuracy: 0.9583\n",
      "Epoch 405: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5861 - accuracy: 0.9592 - val_loss: 1.0371 - val_accuracy: 0.8000\n",
      "Epoch 406/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5195 - accuracy: 1.0000\n",
      "Epoch 406: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5198 - accuracy: 1.0000 - val_loss: 0.9668 - val_accuracy: 0.9200\n",
      "Epoch 407/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6186 - accuracy: 0.9688\n",
      "Epoch 407: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.6373 - accuracy: 0.9592 - val_loss: 1.0333 - val_accuracy: 0.9200\n",
      "Epoch 408/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6267 - accuracy: 0.9375\n",
      "Epoch 408: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.6236 - accuracy: 0.9388 - val_loss: 1.0044 - val_accuracy: 0.8800\n",
      "Epoch 409/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6110 - accuracy: 0.9792\n",
      "Epoch 409: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.6162 - accuracy: 0.9796 - val_loss: 0.9936 - val_accuracy: 0.9200\n",
      "Epoch 410/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5659 - accuracy: 0.9583\n",
      "Epoch 410: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5639 - accuracy: 0.9592 - val_loss: 0.9791 - val_accuracy: 0.9200\n",
      "Epoch 411/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5607 - accuracy: 0.9583\n",
      "Epoch 411: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5676 - accuracy: 0.9490 - val_loss: 0.9935 - val_accuracy: 0.9200\n",
      "Epoch 412/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5694 - accuracy: 0.9583\n",
      "Epoch 412: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5677 - accuracy: 0.9592 - val_loss: 1.0038 - val_accuracy: 0.8400\n",
      "Epoch 413/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6058 - accuracy: 0.9375\n",
      "Epoch 413: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.6030 - accuracy: 0.9388 - val_loss: 0.9578 - val_accuracy: 0.9200\n",
      "Epoch 414/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5519 - accuracy: 0.9792\n",
      "Epoch 414: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5522 - accuracy: 0.9796 - val_loss: 0.9800 - val_accuracy: 0.8800\n",
      "Epoch 415/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5555 - accuracy: 0.9583\n",
      "Epoch 415: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5634 - accuracy: 0.9490 - val_loss: 1.0077 - val_accuracy: 0.9200\n",
      "Epoch 416/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5681 - accuracy: 0.9688\n",
      "Epoch 416: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5687 - accuracy: 0.9694 - val_loss: 1.0767 - val_accuracy: 0.8000\n",
      "Epoch 417/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5494 - accuracy: 0.9792\n",
      "Epoch 417: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5476 - accuracy: 0.9796 - val_loss: 1.0030 - val_accuracy: 0.8400\n",
      "Epoch 418/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5334 - accuracy: 0.9688\n",
      "Epoch 418: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5332 - accuracy: 0.9694 - val_loss: 0.9557 - val_accuracy: 0.9200\n",
      "Epoch 419/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5513 - accuracy: 0.9694\n",
      "Epoch 419: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.5513 - accuracy: 0.9694 - val_loss: 0.9681 - val_accuracy: 0.8800\n",
      "Epoch 420/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5025 - accuracy: 0.9896\n",
      "Epoch 420: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5044 - accuracy: 0.9898 - val_loss: 0.9418 - val_accuracy: 0.9200\n",
      "Epoch 421/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5160 - accuracy: 0.9896\n",
      "Epoch 421: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5157 - accuracy: 0.9898 - val_loss: 0.9446 - val_accuracy: 0.9200\n",
      "Epoch 422/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5627 - accuracy: 0.9479\n",
      "Epoch 422: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5604 - accuracy: 0.9490 - val_loss: 0.9345 - val_accuracy: 0.9200\n",
      "Epoch 423/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5403 - accuracy: 0.9688\n",
      "Epoch 423: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5419 - accuracy: 0.9694 - val_loss: 0.9048 - val_accuracy: 0.9200\n",
      "Epoch 424/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5231 - accuracy: 0.9583\n",
      "Epoch 424: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5218 - accuracy: 0.9592 - val_loss: 0.9097 - val_accuracy: 0.9200\n",
      "Epoch 425/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5411 - accuracy: 0.9792\n",
      "Epoch 425: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.5391 - accuracy: 0.9796 - val_loss: 0.9274 - val_accuracy: 0.9200\n",
      "Epoch 426/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5845 - accuracy: 0.9688\n",
      "Epoch 426: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5817 - accuracy: 0.9694 - val_loss: 0.9440 - val_accuracy: 0.9200\n",
      "Epoch 427/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4989 - accuracy: 0.9896\n",
      "Epoch 427: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4978 - accuracy: 0.9898 - val_loss: 0.9215 - val_accuracy: 0.9200\n",
      "Epoch 428/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5730 - accuracy: 0.9375\n",
      "Epoch 428: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5707 - accuracy: 0.9388 - val_loss: 0.9127 - val_accuracy: 0.9200\n",
      "Epoch 429/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5613 - accuracy: 0.9479\n",
      "Epoch 429: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5591 - accuracy: 0.9490 - val_loss: 0.9558 - val_accuracy: 0.8400\n",
      "Epoch 430/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4975 - accuracy: 1.0000\n",
      "Epoch 430: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4979 - accuracy: 1.0000 - val_loss: 0.9378 - val_accuracy: 0.8400\n",
      "Epoch 431/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4883 - accuracy: 0.9896\n",
      "Epoch 431: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4973 - accuracy: 0.9898 - val_loss: 0.9400 - val_accuracy: 0.8000\n",
      "Epoch 432/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5916 - accuracy: 0.9490\n",
      "Epoch 432: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.5916 - accuracy: 0.9490 - val_loss: 0.9070 - val_accuracy: 0.9200\n",
      "Epoch 433/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5184 - accuracy: 0.9792\n",
      "Epoch 433: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5201 - accuracy: 0.9796 - val_loss: 0.9346 - val_accuracy: 0.8400\n",
      "Epoch 434/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4748 - accuracy: 0.9896\n",
      "Epoch 434: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4740 - accuracy: 0.9898 - val_loss: 0.9135 - val_accuracy: 0.8800\n",
      "Epoch 435/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5900 - accuracy: 0.9583\n",
      "Epoch 435: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5869 - accuracy: 0.9592 - val_loss: 0.9277 - val_accuracy: 0.8400\n",
      "Epoch 436/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5932 - accuracy: 0.9375\n",
      "Epoch 436: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5899 - accuracy: 0.9388 - val_loss: 0.9365 - val_accuracy: 0.8800\n",
      "Epoch 437/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5143 - accuracy: 0.9688\n",
      "Epoch 437: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5127 - accuracy: 0.9694 - val_loss: 0.9253 - val_accuracy: 0.9600\n",
      "Epoch 438/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5419 - accuracy: 0.9792\n",
      "Epoch 438: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.5396 - accuracy: 0.9796 - val_loss: 0.9762 - val_accuracy: 0.8000\n",
      "Epoch 439/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5526 - accuracy: 0.9583\n",
      "Epoch 439: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5503 - accuracy: 0.9592 - val_loss: 0.9055 - val_accuracy: 0.9200\n",
      "Epoch 440/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4761 - accuracy: 0.9896\n",
      "Epoch 440: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4782 - accuracy: 0.9898 - val_loss: 0.9159 - val_accuracy: 0.8800\n",
      "Epoch 441/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5762 - accuracy: 0.9688\n",
      "Epoch 441: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5742 - accuracy: 0.9694 - val_loss: 0.9151 - val_accuracy: 0.8400\n",
      "Epoch 442/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5654 - accuracy: 0.9583\n",
      "Epoch 442: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5660 - accuracy: 0.9592 - val_loss: 0.9542 - val_accuracy: 0.8000\n",
      "Epoch 443/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4947 - accuracy: 0.9792\n",
      "Epoch 443: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4942 - accuracy: 0.9796 - val_loss: 0.9188 - val_accuracy: 0.8000\n",
      "Epoch 444/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5105 - accuracy: 0.9792\n",
      "Epoch 444: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5087 - accuracy: 0.9796 - val_loss: 0.9215 - val_accuracy: 0.8800\n",
      "Epoch 445/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4781 - accuracy: 0.9688\n",
      "Epoch 445: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.4779 - accuracy: 0.9694 - val_loss: 0.9459 - val_accuracy: 0.8000\n",
      "Epoch 446/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4817 - accuracy: 0.9896\n",
      "Epoch 446: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4805 - accuracy: 0.9898 - val_loss: 0.9440 - val_accuracy: 0.8000\n",
      "Epoch 447/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4843 - accuracy: 0.9792\n",
      "Epoch 447: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4980 - accuracy: 0.9694 - val_loss: 0.9493 - val_accuracy: 0.8400\n",
      "Epoch 448/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4612 - accuracy: 0.9792\n",
      "Epoch 448: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4643 - accuracy: 0.9796 - val_loss: 0.9423 - val_accuracy: 0.8800\n",
      "Epoch 449/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4480 - accuracy: 0.9896\n",
      "Epoch 449: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4512 - accuracy: 0.9898 - val_loss: 0.8989 - val_accuracy: 0.9200\n",
      "Epoch 450/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4831 - accuracy: 0.9896\n",
      "Epoch 450: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4875 - accuracy: 0.9898 - val_loss: 0.8942 - val_accuracy: 0.9200\n",
      "Epoch 451/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4843 - accuracy: 0.9792\n",
      "Epoch 451: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4828 - accuracy: 0.9796 - val_loss: 0.9069 - val_accuracy: 0.9200\n",
      "Epoch 452/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4285 - accuracy: 1.0000\n",
      "Epoch 452: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.4285 - accuracy: 1.0000 - val_loss: 0.9038 - val_accuracy: 0.9200\n",
      "Epoch 453/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4883 - accuracy: 0.9583\n",
      "Epoch 453: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4868 - accuracy: 0.9592 - val_loss: 0.9121 - val_accuracy: 0.8400\n",
      "Epoch 454/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4813 - accuracy: 0.9688\n",
      "Epoch 454: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4798 - accuracy: 0.9694 - val_loss: 0.8764 - val_accuracy: 0.8800\n",
      "Epoch 455/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4779 - accuracy: 0.9792\n",
      "Epoch 455: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4763 - accuracy: 0.9796 - val_loss: 0.8883 - val_accuracy: 0.8800\n",
      "Epoch 456/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4860 - accuracy: 0.9792\n",
      "Epoch 456: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4843 - accuracy: 0.9796 - val_loss: 0.8981 - val_accuracy: 0.8400\n",
      "Epoch 457/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4750 - accuracy: 0.9688\n",
      "Epoch 457: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4735 - accuracy: 0.9694 - val_loss: 0.8827 - val_accuracy: 0.8400\n",
      "Epoch 458/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4770 - accuracy: 0.9688\n",
      "Epoch 458: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4762 - accuracy: 0.9694 - val_loss: 0.9243 - val_accuracy: 0.8400\n",
      "Epoch 459/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4693 - accuracy: 0.9583\n",
      "Epoch 459: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4771 - accuracy: 0.9490 - val_loss: 0.8873 - val_accuracy: 0.9200\n",
      "Epoch 460/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4724 - accuracy: 0.9792\n",
      "Epoch 460: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4709 - accuracy: 0.9796 - val_loss: 0.8670 - val_accuracy: 0.9200\n",
      "Epoch 461/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4412 - accuracy: 0.9896\n",
      "Epoch 461: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4403 - accuracy: 0.9898 - val_loss: 0.8960 - val_accuracy: 0.8400\n",
      "Epoch 462/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5291 - accuracy: 0.9479\n",
      "Epoch 462: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5271 - accuracy: 0.9490 - val_loss: 0.9251 - val_accuracy: 0.8000\n",
      "Epoch 463/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4993 - accuracy: 0.9688\n",
      "Epoch 463: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4971 - accuracy: 0.9694 - val_loss: 0.8738 - val_accuracy: 0.9200\n",
      "Epoch 464/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4633 - accuracy: 0.9896\n",
      "Epoch 464: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.4619 - accuracy: 0.9898 - val_loss: 0.8591 - val_accuracy: 0.9200\n",
      "Epoch 465/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4844 - accuracy: 0.9792\n",
      "Epoch 465: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.4832 - accuracy: 0.9796 - val_loss: 0.8386 - val_accuracy: 0.9200\n",
      "Epoch 466/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4480 - accuracy: 0.9792\n",
      "Epoch 466: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4478 - accuracy: 0.9796 - val_loss: 0.8246 - val_accuracy: 0.9600\n",
      "Epoch 467/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4703 - accuracy: 0.9583\n",
      "Epoch 467: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4688 - accuracy: 0.9592 - val_loss: 0.8194 - val_accuracy: 0.9200\n",
      "Epoch 468/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4792 - accuracy: 0.9583\n",
      "Epoch 468: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4772 - accuracy: 0.9592 - val_loss: 0.8178 - val_accuracy: 0.9200\n",
      "Epoch 469/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4245 - accuracy: 0.9896\n",
      "Epoch 469: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4237 - accuracy: 0.9898 - val_loss: 0.8695 - val_accuracy: 0.8800\n",
      "Epoch 470/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4676 - accuracy: 0.9792\n",
      "Epoch 470: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4659 - accuracy: 0.9796 - val_loss: 0.8819 - val_accuracy: 0.8000\n",
      "Epoch 471/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4404 - accuracy: 0.9688\n",
      "Epoch 471: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4393 - accuracy: 0.9694 - val_loss: 0.8404 - val_accuracy: 0.9200\n",
      "Epoch 472/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4346 - accuracy: 0.9898\n",
      "Epoch 472: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.4346 - accuracy: 0.9898 - val_loss: 0.8662 - val_accuracy: 0.8400\n",
      "Epoch 473/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4903 - accuracy: 0.9792\n",
      "Epoch 473: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4879 - accuracy: 0.9796 - val_loss: 0.8562 - val_accuracy: 0.8000\n",
      "Epoch 474/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4938 - accuracy: 0.9583\n",
      "Epoch 474: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4915 - accuracy: 0.9592 - val_loss: 0.8493 - val_accuracy: 0.9200\n",
      "Epoch 475/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4040 - accuracy: 1.0000\n",
      "Epoch 475: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.4040 - accuracy: 1.0000 - val_loss: 0.8517 - val_accuracy: 0.9200\n",
      "Epoch 476/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4322 - accuracy: 0.9792\n",
      "Epoch 476: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4310 - accuracy: 0.9796 - val_loss: 0.8842 - val_accuracy: 0.8400\n",
      "Epoch 477/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4374 - accuracy: 0.9688\n",
      "Epoch 477: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.4362 - accuracy: 0.9694 - val_loss: 0.8547 - val_accuracy: 0.8000\n",
      "Epoch 478/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4259 - accuracy: 0.9792\n",
      "Epoch 478: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4269 - accuracy: 0.9796 - val_loss: 0.8960 - val_accuracy: 0.8000\n",
      "Epoch 479/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4397 - accuracy: 0.9792\n",
      "Epoch 479: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4392 - accuracy: 0.9796 - val_loss: 0.9004 - val_accuracy: 0.8000\n",
      "Epoch 480/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4586 - accuracy: 0.9688\n",
      "Epoch 480: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4567 - accuracy: 0.9694 - val_loss: 0.8608 - val_accuracy: 0.8800\n",
      "Epoch 481/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4137 - accuracy: 0.9792\n",
      "Epoch 481: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4127 - accuracy: 0.9796 - val_loss: 0.8523 - val_accuracy: 0.8800\n",
      "Epoch 482/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4035 - accuracy: 0.9792\n",
      "Epoch 482: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4027 - accuracy: 0.9796 - val_loss: 0.8743 - val_accuracy: 0.8800\n",
      "Epoch 483/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4624 - accuracy: 0.9375\n",
      "Epoch 483: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.4603 - accuracy: 0.9388 - val_loss: 0.8774 - val_accuracy: 0.8400\n",
      "Epoch 484/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4033 - accuracy: 1.0000\n",
      "Epoch 484: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4024 - accuracy: 1.0000 - val_loss: 0.9003 - val_accuracy: 0.8000\n",
      "Epoch 485/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4059 - accuracy: 0.9896\n",
      "Epoch 485: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4052 - accuracy: 0.9898 - val_loss: 0.8717 - val_accuracy: 0.8800\n",
      "Epoch 486/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5191 - accuracy: 0.9479\n",
      "Epoch 486: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5158 - accuracy: 0.9490 - val_loss: 0.8470 - val_accuracy: 0.8800\n",
      "Epoch 487/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4926 - accuracy: 0.9583\n",
      "Epoch 487: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4901 - accuracy: 0.9592 - val_loss: 0.8432 - val_accuracy: 0.8800\n",
      "Epoch 488/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4203 - accuracy: 0.9792\n",
      "Epoch 488: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4189 - accuracy: 0.9796 - val_loss: 0.8722 - val_accuracy: 0.8400\n",
      "Epoch 489/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4308 - accuracy: 0.9792\n",
      "Epoch 489: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.4493 - accuracy: 0.9694 - val_loss: 0.8727 - val_accuracy: 0.8800\n",
      "Epoch 490/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4934 - accuracy: 0.9583\n",
      "Epoch 490: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4906 - accuracy: 0.9592 - val_loss: 0.9108 - val_accuracy: 0.8400\n",
      "Epoch 491/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4425 - accuracy: 0.9583\n",
      "Epoch 491: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4416 - accuracy: 0.9592 - val_loss: 0.8817 - val_accuracy: 0.8000\n",
      "Epoch 492/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3816 - accuracy: 1.0000\n",
      "Epoch 492: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3810 - accuracy: 1.0000 - val_loss: 0.8640 - val_accuracy: 0.8800\n",
      "Epoch 493/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4052 - accuracy: 0.9896\n",
      "Epoch 493: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4044 - accuracy: 0.9898 - val_loss: 0.8628 - val_accuracy: 0.8800\n",
      "Epoch 494/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5084 - accuracy: 0.9479\n",
      "Epoch 494: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 0.5075 - accuracy: 0.9490 - val_loss: 0.8395 - val_accuracy: 0.8800\n",
      "Epoch 495/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4327 - accuracy: 0.9898\n",
      "Epoch 495: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.4327 - accuracy: 0.9898 - val_loss: 0.8413 - val_accuracy: 0.8800\n",
      "Epoch 496/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4750 - accuracy: 0.9479\n",
      "Epoch 496: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4724 - accuracy: 0.9490 - val_loss: 0.8893 - val_accuracy: 0.8000\n",
      "Epoch 497/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4000 - accuracy: 0.9688\n",
      "Epoch 497: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3993 - accuracy: 0.9694 - val_loss: 0.8612 - val_accuracy: 0.8000\n",
      "Epoch 498/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4633 - accuracy: 0.9592\n",
      "Epoch 498: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.4633 - accuracy: 0.9592 - val_loss: 0.8417 - val_accuracy: 0.8800\n",
      "Epoch 499/500\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4083 - accuracy: 0.9898\n",
      "Epoch 499: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.4083 - accuracy: 0.9898 - val_loss: 0.8470 - val_accuracy: 0.8800\n",
      "Epoch 500/500\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4166 - accuracy: 0.9792\n",
      "Epoch 500: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4217 - accuracy: 0.9796 - val_loss: 0.8945 - val_accuracy: 0.8800\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.8945 - accuracy: 0.8800\n",
      "Test accuracy: 0.8799999952316284\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs = 500\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"onehot.hdf5\", monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "seqModel = model.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpoint])\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15f122dc0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(seqModel.history.keys())\n",
    "xc         = range(num_epochs)\n",
    "\n",
    "plt.plot(xc, seqModel.history['loss'], label='train loss')\n",
    "plt.plot(xc, seqModel.history['val_loss'], label='validation loss')\n",
    "plt.plot(xc, seqModel.history['accuracy'], label='accuracy')\n",
    "plt.plot(xc, seqModel.history['val_accuracy'], label='val_accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with custom_object_scope({'SeqSelfAttention': SeqSelfAttention}):\n",
    "    load_model = keras.models.load_model('onehot.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 18ms/step - loss: 0.9630 - accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 82ms/step\n"
     ]
    }
   ],
   "source": [
    "load_model.evaluate(X_train, y_train)\n",
    "y_test_ordinal = np.argmax(y_test, axis=1)\n",
    "y_pred_prob = load_model.predict(X_test)\n",
    "y_pred_ordinal = np.argmax(y_pred_prob, axis=1)\n",
    "confusion = confusion_matrix(y_test_ordinal, y_pred_ordinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[1 0 0 0 0 0]\n",
      " [0 5 0 0 0 0]\n",
      " [0 0 8 0 0 0]\n",
      " [0 0 1 2 0 0]\n",
      " [0 0 0 0 6 0]\n",
      " [0 0 0 0 0 2]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(confusion, classes = np.unique(y_test_ordinal), title='Confusion matrix', normalize=False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3adb7d5fef717c587deb8377a86ec7783da6fdece6d2a9408ba836e669f2be8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
