{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337) \n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler, Normalizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, BatchNormalization, MaxPooling1D, LeakyReLU, Flatten, Dropout\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from keras.utils import custom_object_scope\n",
    "from keras.callbacks import History, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras import metrics, regularizers\n",
    "from keras.optimizers import Adam, Adagrad, Adadelta, RMSprop\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import keras.regularizers\n",
    "import keras\n",
    "import glob\n",
    "import os\n",
    "import itertools\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/dimitrygrebenyuk/Yandex.Disk.localized/Working/PDF/Refinements/PDF-Cluster-Prediction/all_data/')\n",
    "files_calc = glob.glob('*.dat')\n",
    "files_exp = glob.glob('*processed.gr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_points = []\n",
    "\n",
    "with open('/Users/dimitrygrebenyuk/Yandex.Disk.localized/Working/PDF/Refinements/PDF-Cluster-Prediction/clusters/labels.txt', 'w') as labels:\n",
    "    for f in files_calc:\n",
    "        df = pd.read_csv(f, usecols=[1], skiprows=201, header=None, delim_whitespace=True, skipfooter=0, engine='python')\n",
    "        raw_data_points.append(df.values.ravel())\n",
    "        labels.write(f[0])\n",
    "        labels.write('\\n')\n",
    "    for f in files_exp:\n",
    "        df = pd.read_csv(f, usecols=[1], skiprows=1, header=None, delim_whitespace=True, skipfooter=1, engine='python')\n",
    "        raw_data_points.append(df.values.ravel())\n",
    "        labels.write(f[0])\n",
    "        labels.write('\\n')\n",
    "        \n",
    "raw_data_points = np.array(raw_data_points)\n",
    "\n",
    "# Load the labels\n",
    "labels = pd.read_csv(\"/Users/dimitrygrebenyuk/Yandex.Disk.localized/Working/PDF/Refinements/PDF-Cluster-Prediction/clusters/labels.txt\", header=None)\n",
    "labels = labels.values.ravel()  # convert the labels to a 1D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x158008820>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# Preprocessing\n",
    "#scaler = MinMaxScaler()\n",
    "#scaler = StandardScaler()\n",
    "#scaler =MaxAbsScaler()\n",
    "#data_points = scaler.fit_transform(data_points)\n",
    "normalize = Normalizer()\n",
    "data_points = normalize.fit_transform(raw_data_points)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(len(data_points[120,:]))/100, data_points[120,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_points, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 745, 32)           8224      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 745, 32)          128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 372, 32)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 372, 32)           0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 357, 32)           16416     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 357, 32)           0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 178, 32)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 178, 32)           0         \n",
      "                                                                 \n",
      " seq_self_attention (SeqSelf  (None, 178, 32)          1025      \n",
      " Attention)                                                      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 5696)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               729216    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 756,299\n",
      "Trainable params: 756,235\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Tuning of the model\n",
    "\n",
    "model = Sequential()\n",
    "# Add the convolutional layers\n",
    "model.add(Conv1D(filters=32, kernel_size=256, activation='relu', input_shape=(1000,1))) # 256, 32\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2)) # 2\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters=32, kernel_size=16, activation='relu')) # 64, 32\n",
    "model.add(Dropout(0.5))\n",
    "model.add(MaxPooling1D(pool_size=2)) # 2\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(SeqSelfAttention(attention_width=16, attention_type=SeqSelfAttention.ATTENTION_TYPE_MUL)) # 16\n",
    "\n",
    "# Flatten the output of the convolutional layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add the fully connected layers\n",
    "model.add(Dense(units=128, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01))) # 128 0.01\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(units=10, activation='softmax', kernel_regularizer=keras.regularizers.l2(0.01))) # 10 0.01\n",
    "\n",
    "# Compile the model\n",
    "optimizer = RMSprop(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-27 18:34:52.055092: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/4 [=====================>........] - ETA: 0s - loss: 4.9211 - accuracy: 0.1979\n",
      "Epoch 1: val_accuracy improved from -inf to 0.32000, saving model to calc_and_exp_2-12.hdf5\n",
      "4/4 [==============================] - 1s 82ms/step - loss: 4.9313 - accuracy: 0.1939 - val_loss: 4.9206 - val_accuracy: 0.3200\n",
      "Epoch 2/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 4.5661 - accuracy: 0.4479\n",
      "Epoch 2: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 4.5669 - accuracy: 0.4490 - val_loss: 4.8768 - val_accuracy: 0.3200\n",
      "Epoch 3/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 4.4018 - accuracy: 0.4375\n",
      "Epoch 3: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 4.4103 - accuracy: 0.4286 - val_loss: 4.8426 - val_accuracy: 0.3200\n",
      "Epoch 4/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 4.4180 - accuracy: 0.4479\n",
      "Epoch 4: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 4.4097 - accuracy: 0.4490 - val_loss: 4.8110 - val_accuracy: 0.3200\n",
      "Epoch 5/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 4.3157 - accuracy: 0.4286\n",
      "Epoch 5: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 4.3157 - accuracy: 0.4286 - val_loss: 4.7824 - val_accuracy: 0.3200\n",
      "Epoch 6/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 4.2753 - accuracy: 0.4167\n",
      "Epoch 6: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 4.2752 - accuracy: 0.4082 - val_loss: 4.7572 - val_accuracy: 0.3200\n",
      "Epoch 7/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 4.3039 - accuracy: 0.4479\n",
      "Epoch 7: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 4.2911 - accuracy: 0.4592 - val_loss: 4.7281 - val_accuracy: 0.3200\n",
      "Epoch 8/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 4.1536 - accuracy: 0.4375\n",
      "Epoch 8: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 4.1570 - accuracy: 0.4388 - val_loss: 4.7029 - val_accuracy: 0.3200\n",
      "Epoch 9/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 4.0771 - accuracy: 0.4271\n",
      "Epoch 9: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 4.0882 - accuracy: 0.4286 - val_loss: 4.6804 - val_accuracy: 0.3200\n",
      "Epoch 10/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 4.0344 - accuracy: 0.4896\n",
      "Epoch 10: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 4.0418 - accuracy: 0.4898 - val_loss: 4.6536 - val_accuracy: 0.3200\n",
      "Epoch 11/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 4.0222 - accuracy: 0.4694\n",
      "Epoch 11: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 4.0222 - accuracy: 0.4694 - val_loss: 4.6282 - val_accuracy: 0.3200\n",
      "Epoch 12/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 4.0332 - accuracy: 0.3980\n",
      "Epoch 12: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 4.0332 - accuracy: 0.3980 - val_loss: 4.6069 - val_accuracy: 0.3200\n",
      "Epoch 13/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.8827 - accuracy: 0.5306\n",
      "Epoch 13: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 3.8827 - accuracy: 0.5306 - val_loss: 4.5835 - val_accuracy: 0.3200\n",
      "Epoch 14/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.8677 - accuracy: 0.4375\n",
      "Epoch 14: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 3.8693 - accuracy: 0.4388 - val_loss: 4.5604 - val_accuracy: 0.3200\n",
      "Epoch 15/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.8474 - accuracy: 0.5312\n",
      "Epoch 15: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 3.8387 - accuracy: 0.5306 - val_loss: 4.5353 - val_accuracy: 0.3200\n",
      "Epoch 16/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.7834 - accuracy: 0.5000\n",
      "Epoch 16: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 3.7832 - accuracy: 0.5000 - val_loss: 4.5143 - val_accuracy: 0.3200\n",
      "Epoch 17/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.6450 - accuracy: 0.5312\n",
      "Epoch 17: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 3.6502 - accuracy: 0.5306 - val_loss: 4.4890 - val_accuracy: 0.3200\n",
      "Epoch 18/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.6020 - accuracy: 0.6042\n",
      "Epoch 18: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 3.6047 - accuracy: 0.6020 - val_loss: 4.4670 - val_accuracy: 0.3200\n",
      "Epoch 19/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.6204 - accuracy: 0.5521\n",
      "Epoch 19: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 3.6265 - accuracy: 0.5510 - val_loss: 4.4425 - val_accuracy: 0.3200\n",
      "Epoch 20/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.6744 - accuracy: 0.5104\n",
      "Epoch 20: val_accuracy did not improve from 0.32000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 3.6595 - accuracy: 0.5102 - val_loss: 4.4241 - val_accuracy: 0.2400\n",
      "Epoch 21/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.5358 - accuracy: 0.5625\n",
      "Epoch 21: val_accuracy improved from 0.32000 to 0.36000, saving model to calc_and_exp_2-12.hdf5\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 3.5245 - accuracy: 0.5714 - val_loss: 4.3986 - val_accuracy: 0.3600\n",
      "Epoch 22/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.5064 - accuracy: 0.5306\n",
      "Epoch 22: val_accuracy did not improve from 0.36000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 3.5064 - accuracy: 0.5306 - val_loss: 4.3825 - val_accuracy: 0.3200\n",
      "Epoch 23/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.5338 - accuracy: 0.4896\n",
      "Epoch 23: val_accuracy did not improve from 0.36000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 3.5248 - accuracy: 0.5000 - val_loss: 4.3606 - val_accuracy: 0.3200\n",
      "Epoch 24/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.5601 - accuracy: 0.5312\n",
      "Epoch 24: val_accuracy did not improve from 0.36000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 3.5436 - accuracy: 0.5408 - val_loss: 4.3417 - val_accuracy: 0.3200\n",
      "Epoch 25/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.4282 - accuracy: 0.5306\n",
      "Epoch 25: val_accuracy did not improve from 0.36000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 3.4282 - accuracy: 0.5306 - val_loss: 4.3262 - val_accuracy: 0.3200\n",
      "Epoch 26/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.3621 - accuracy: 0.5612\n",
      "Epoch 26: val_accuracy did not improve from 0.36000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 3.3621 - accuracy: 0.5612 - val_loss: 4.3074 - val_accuracy: 0.3200\n",
      "Epoch 27/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.4569 - accuracy: 0.5714\n",
      "Epoch 27: val_accuracy did not improve from 0.36000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 3.4569 - accuracy: 0.5714 - val_loss: 4.2944 - val_accuracy: 0.2400\n",
      "Epoch 28/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.2769 - accuracy: 0.5833\n",
      "Epoch 28: val_accuracy did not improve from 0.36000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 3.2712 - accuracy: 0.5816 - val_loss: 4.2735 - val_accuracy: 0.3200\n",
      "Epoch 29/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.3116 - accuracy: 0.6146\n",
      "Epoch 29: val_accuracy did not improve from 0.36000\n",
      "4/4 [==============================] - 0s 38ms/step - loss: 3.3008 - accuracy: 0.6224 - val_loss: 4.2527 - val_accuracy: 0.3200\n",
      "Epoch 30/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.3302 - accuracy: 0.5625\n",
      "Epoch 30: val_accuracy did not improve from 0.36000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 3.3250 - accuracy: 0.5612 - val_loss: 4.2395 - val_accuracy: 0.3200\n",
      "Epoch 31/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.3914 - accuracy: 0.5521\n",
      "Epoch 31: val_accuracy improved from 0.36000 to 0.40000, saving model to calc_and_exp_2-12.hdf5\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 3.3997 - accuracy: 0.5510 - val_loss: 4.2279 - val_accuracy: 0.4000\n",
      "Epoch 32/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.2062 - accuracy: 0.6354\n",
      "Epoch 32: val_accuracy did not improve from 0.40000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 3.2256 - accuracy: 0.6327 - val_loss: 4.2146 - val_accuracy: 0.4000\n",
      "Epoch 33/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.1756 - accuracy: 0.6042\n",
      "Epoch 33: val_accuracy did not improve from 0.40000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 3.1874 - accuracy: 0.5918 - val_loss: 4.1984 - val_accuracy: 0.3600\n",
      "Epoch 34/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.1900 - accuracy: 0.5625\n",
      "Epoch 34: val_accuracy did not improve from 0.40000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 3.1811 - accuracy: 0.5612 - val_loss: 4.1795 - val_accuracy: 0.3600\n",
      "Epoch 35/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.1084 - accuracy: 0.5938\n",
      "Epoch 35: val_accuracy did not improve from 0.40000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 3.1072 - accuracy: 0.5918 - val_loss: 4.1675 - val_accuracy: 0.3600\n",
      "Epoch 36/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.1185 - accuracy: 0.6327\n",
      "Epoch 36: val_accuracy did not improve from 0.40000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 3.1185 - accuracy: 0.6327 - val_loss: 4.1507 - val_accuracy: 0.3600\n",
      "Epoch 37/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 3.1026 - accuracy: 0.6327\n",
      "Epoch 37: val_accuracy did not improve from 0.40000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 3.1026 - accuracy: 0.6327 - val_loss: 4.1414 - val_accuracy: 0.3200\n",
      "Epoch 38/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.0904 - accuracy: 0.5938\n",
      "Epoch 38: val_accuracy did not improve from 0.40000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 3.0775 - accuracy: 0.6020 - val_loss: 4.1188 - val_accuracy: 0.3600\n",
      "Epoch 39/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.0551 - accuracy: 0.5833\n",
      "Epoch 39: val_accuracy did not improve from 0.40000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 3.0580 - accuracy: 0.5816 - val_loss: 4.1106 - val_accuracy: 0.4000\n",
      "Epoch 40/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.9546 - accuracy: 0.6667\n",
      "Epoch 40: val_accuracy improved from 0.40000 to 0.44000, saving model to calc_and_exp_2-12.hdf5\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 2.9637 - accuracy: 0.6531 - val_loss: 4.0906 - val_accuracy: 0.4400\n",
      "Epoch 41/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 3.0675 - accuracy: 0.6146\n",
      "Epoch 41: val_accuracy did not improve from 0.44000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 3.0535 - accuracy: 0.6224 - val_loss: 4.0781 - val_accuracy: 0.4000\n",
      "Epoch 42/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.9977 - accuracy: 0.6042\n",
      "Epoch 42: val_accuracy did not improve from 0.44000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 2.9867 - accuracy: 0.6122 - val_loss: 4.0682 - val_accuracy: 0.2800\n",
      "Epoch 43/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.9602 - accuracy: 0.6667\n",
      "Epoch 43: val_accuracy did not improve from 0.44000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.9490 - accuracy: 0.6735 - val_loss: 4.0512 - val_accuracy: 0.2800\n",
      "Epoch 44/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.9267 - accuracy: 0.6146\n",
      "Epoch 44: val_accuracy did not improve from 0.44000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.9070 - accuracy: 0.6224 - val_loss: 4.0373 - val_accuracy: 0.3600\n",
      "Epoch 45/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.8848 - accuracy: 0.6667\n",
      "Epoch 45: val_accuracy did not improve from 0.44000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.9016 - accuracy: 0.6633 - val_loss: 4.0221 - val_accuracy: 0.4000\n",
      "Epoch 46/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.9703 - accuracy: 0.5938\n",
      "Epoch 46: val_accuracy improved from 0.44000 to 0.64000, saving model to calc_and_exp_2-12.hdf5\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 2.9891 - accuracy: 0.5816 - val_loss: 4.0087 - val_accuracy: 0.6400\n",
      "Epoch 47/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.8605 - accuracy: 0.5833\n",
      "Epoch 47: val_accuracy did not improve from 0.64000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.8599 - accuracy: 0.5714 - val_loss: 3.9949 - val_accuracy: 0.4400\n",
      "Epoch 48/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.8932 - accuracy: 0.6429\n",
      "Epoch 48: val_accuracy did not improve from 0.64000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 2.8932 - accuracy: 0.6429 - val_loss: 3.9876 - val_accuracy: 0.3600\n",
      "Epoch 49/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.8892 - accuracy: 0.6667\n",
      "Epoch 49: val_accuracy did not improve from 0.64000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.8919 - accuracy: 0.6633 - val_loss: 3.9705 - val_accuracy: 0.6400\n",
      "Epoch 50/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.8145 - accuracy: 0.6875\n",
      "Epoch 50: val_accuracy did not improve from 0.64000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 2.8142 - accuracy: 0.6837 - val_loss: 3.9565 - val_accuracy: 0.6000\n",
      "Epoch 51/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.7709 - accuracy: 0.6771\n",
      "Epoch 51: val_accuracy did not improve from 0.64000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.7541 - accuracy: 0.6837 - val_loss: 3.9438 - val_accuracy: 0.4400\n",
      "Epoch 52/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.8713 - accuracy: 0.6562\n",
      "Epoch 52: val_accuracy did not improve from 0.64000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 2.8638 - accuracy: 0.6633 - val_loss: 3.9226 - val_accuracy: 0.4400\n",
      "Epoch 53/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.7403 - accuracy: 0.6667\n",
      "Epoch 53: val_accuracy did not improve from 0.64000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.7329 - accuracy: 0.6633 - val_loss: 3.9063 - val_accuracy: 0.4800\n",
      "Epoch 54/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.6791 - accuracy: 0.7083\n",
      "Epoch 54: val_accuracy did not improve from 0.64000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.6760 - accuracy: 0.7143 - val_loss: 3.8991 - val_accuracy: 0.4400\n",
      "Epoch 55/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.7122 - accuracy: 0.6771\n",
      "Epoch 55: val_accuracy did not improve from 0.64000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 2.7049 - accuracy: 0.6837 - val_loss: 3.8860 - val_accuracy: 0.4400\n",
      "Epoch 56/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.8245 - accuracy: 0.6224\n",
      "Epoch 56: val_accuracy did not improve from 0.64000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 2.8245 - accuracy: 0.6224 - val_loss: 3.8678 - val_accuracy: 0.4000\n",
      "Epoch 57/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.6072 - accuracy: 0.6771\n",
      "Epoch 57: val_accuracy did not improve from 0.64000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.6144 - accuracy: 0.6735 - val_loss: 3.8570 - val_accuracy: 0.5200\n",
      "Epoch 58/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.6117 - accuracy: 0.6771\n",
      "Epoch 58: val_accuracy did not improve from 0.64000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.6426 - accuracy: 0.6633 - val_loss: 3.8528 - val_accuracy: 0.5600\n",
      "Epoch 59/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.6969 - accuracy: 0.6354\n",
      "Epoch 59: val_accuracy did not improve from 0.64000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.7027 - accuracy: 0.6327 - val_loss: 3.8383 - val_accuracy: 0.5600\n",
      "Epoch 60/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.6088 - accuracy: 0.6979\n",
      "Epoch 60: val_accuracy did not improve from 0.64000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.6011 - accuracy: 0.7041 - val_loss: 3.8192 - val_accuracy: 0.5200\n",
      "Epoch 61/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.6650 - accuracy: 0.6875\n",
      "Epoch 61: val_accuracy did not improve from 0.64000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.6626 - accuracy: 0.6837 - val_loss: 3.8109 - val_accuracy: 0.6000\n",
      "Epoch 62/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.5699 - accuracy: 0.6771\n",
      "Epoch 62: val_accuracy did not improve from 0.64000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.5547 - accuracy: 0.6837 - val_loss: 3.7965 - val_accuracy: 0.4400\n",
      "Epoch 63/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.5634 - accuracy: 0.7083\n",
      "Epoch 63: val_accuracy did not improve from 0.64000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.5498 - accuracy: 0.7143 - val_loss: 3.7816 - val_accuracy: 0.4400\n",
      "Epoch 64/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.4775 - accuracy: 0.7500\n",
      "Epoch 64: val_accuracy improved from 0.64000 to 0.68000, saving model to calc_and_exp_2-12.hdf5\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 2.4962 - accuracy: 0.7347 - val_loss: 3.7645 - val_accuracy: 0.6800\n",
      "Epoch 65/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.5310 - accuracy: 0.6667\n",
      "Epoch 65: val_accuracy did not improve from 0.68000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.5189 - accuracy: 0.6735 - val_loss: 3.7405 - val_accuracy: 0.5200\n",
      "Epoch 66/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.4803 - accuracy: 0.7188\n",
      "Epoch 66: val_accuracy did not improve from 0.68000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.5150 - accuracy: 0.7041 - val_loss: 3.7454 - val_accuracy: 0.6400\n",
      "Epoch 67/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.5096 - accuracy: 0.7292\n",
      "Epoch 67: val_accuracy did not improve from 0.68000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.5103 - accuracy: 0.7245 - val_loss: 3.7235 - val_accuracy: 0.5200\n",
      "Epoch 68/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.4683 - accuracy: 0.7292\n",
      "Epoch 68: val_accuracy did not improve from 0.68000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.4657 - accuracy: 0.7347 - val_loss: 3.7040 - val_accuracy: 0.5600\n",
      "Epoch 69/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.4836 - accuracy: 0.6979\n",
      "Epoch 69: val_accuracy did not improve from 0.68000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.4664 - accuracy: 0.7041 - val_loss: 3.6877 - val_accuracy: 0.5200\n",
      "Epoch 70/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.5659 - accuracy: 0.6875\n",
      "Epoch 70: val_accuracy did not improve from 0.68000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.5585 - accuracy: 0.6939 - val_loss: 3.6749 - val_accuracy: 0.6000\n",
      "Epoch 71/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.5096 - accuracy: 0.6979\n",
      "Epoch 71: val_accuracy did not improve from 0.68000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 2.5125 - accuracy: 0.6939 - val_loss: 3.6752 - val_accuracy: 0.6400\n",
      "Epoch 72/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.4003 - accuracy: 0.7708\n",
      "Epoch 72: val_accuracy did not improve from 0.68000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.3935 - accuracy: 0.7755 - val_loss: 3.6640 - val_accuracy: 0.5600\n",
      "Epoch 73/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.4113 - accuracy: 0.6979\n",
      "Epoch 73: val_accuracy did not improve from 0.68000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 2.3966 - accuracy: 0.7041 - val_loss: 3.6518 - val_accuracy: 0.6000\n",
      "Epoch 74/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.3715 - accuracy: 0.6939\n",
      "Epoch 74: val_accuracy improved from 0.68000 to 0.76000, saving model to calc_and_exp_2-12.hdf5\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 2.3715 - accuracy: 0.6939 - val_loss: 3.6451 - val_accuracy: 0.7600\n",
      "Epoch 75/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.4544 - accuracy: 0.7083\n",
      "Epoch 75: val_accuracy did not improve from 0.76000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.4438 - accuracy: 0.7143 - val_loss: 3.6271 - val_accuracy: 0.6800\n",
      "Epoch 76/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.4028 - accuracy: 0.6875\n",
      "Epoch 76: val_accuracy did not improve from 0.76000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.4083 - accuracy: 0.6837 - val_loss: 3.6148 - val_accuracy: 0.5200\n",
      "Epoch 77/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.3962 - accuracy: 0.6771\n",
      "Epoch 77: val_accuracy did not improve from 0.76000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 2.3908 - accuracy: 0.6735 - val_loss: 3.6145 - val_accuracy: 0.6400\n",
      "Epoch 78/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.3185 - accuracy: 0.7292\n",
      "Epoch 78: val_accuracy did not improve from 0.76000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.3289 - accuracy: 0.7245 - val_loss: 3.5903 - val_accuracy: 0.6400\n",
      "Epoch 79/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.3195 - accuracy: 0.7083\n",
      "Epoch 79: val_accuracy did not improve from 0.76000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.3348 - accuracy: 0.7041 - val_loss: 3.5794 - val_accuracy: 0.6800\n",
      "Epoch 80/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.2370 - accuracy: 0.7604\n",
      "Epoch 80: val_accuracy did not improve from 0.76000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.2824 - accuracy: 0.7449 - val_loss: 3.5924 - val_accuracy: 0.7200\n",
      "Epoch 81/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.4480 - accuracy: 0.6667\n",
      "Epoch 81: val_accuracy did not improve from 0.76000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 2.4362 - accuracy: 0.6735 - val_loss: 3.5664 - val_accuracy: 0.6800\n",
      "Epoch 82/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.4007 - accuracy: 0.6979\n",
      "Epoch 82: val_accuracy did not improve from 0.76000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.3893 - accuracy: 0.7041 - val_loss: 3.5479 - val_accuracy: 0.6400\n",
      "Epoch 83/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.2752 - accuracy: 0.7396\n",
      "Epoch 83: val_accuracy did not improve from 0.76000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 2.2650 - accuracy: 0.7449 - val_loss: 3.5233 - val_accuracy: 0.5200\n",
      "Epoch 84/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.2525 - accuracy: 0.7041\n",
      "Epoch 84: val_accuracy did not improve from 0.76000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 2.2525 - accuracy: 0.7041 - val_loss: 3.5024 - val_accuracy: 0.5200\n",
      "Epoch 85/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.3522 - accuracy: 0.6771\n",
      "Epoch 85: val_accuracy did not improve from 0.76000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 2.3715 - accuracy: 0.6735 - val_loss: 3.4925 - val_accuracy: 0.5200\n",
      "Epoch 86/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.2472 - accuracy: 0.7396\n",
      "Epoch 86: val_accuracy did not improve from 0.76000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.2387 - accuracy: 0.7449 - val_loss: 3.4727 - val_accuracy: 0.5600\n",
      "Epoch 87/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.2522 - accuracy: 0.7143\n",
      "Epoch 87: val_accuracy did not improve from 0.76000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 2.2522 - accuracy: 0.7143 - val_loss: 3.4639 - val_accuracy: 0.5600\n",
      "Epoch 88/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.1295 - accuracy: 0.7917\n",
      "Epoch 88: val_accuracy did not improve from 0.76000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 2.1354 - accuracy: 0.7857 - val_loss: 3.4590 - val_accuracy: 0.5200\n",
      "Epoch 89/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.1743 - accuracy: 0.7812\n",
      "Epoch 89: val_accuracy did not improve from 0.76000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.1602 - accuracy: 0.7857 - val_loss: 3.4417 - val_accuracy: 0.5600\n",
      "Epoch 90/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.1911 - accuracy: 0.7396\n",
      "Epoch 90: val_accuracy did not improve from 0.76000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.1777 - accuracy: 0.7449 - val_loss: 3.4183 - val_accuracy: 0.5200\n",
      "Epoch 91/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.2437 - accuracy: 0.7396\n",
      "Epoch 91: val_accuracy did not improve from 0.76000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.2342 - accuracy: 0.7449 - val_loss: 3.4093 - val_accuracy: 0.6400\n",
      "Epoch 92/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.1401 - accuracy: 0.8021\n",
      "Epoch 92: val_accuracy did not improve from 0.76000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.1399 - accuracy: 0.8061 - val_loss: 3.3750 - val_accuracy: 0.5600\n",
      "Epoch 93/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 2.1513 - accuracy: 0.6939\n",
      "Epoch 93: val_accuracy did not improve from 0.76000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 2.1513 - accuracy: 0.6939 - val_loss: 3.3881 - val_accuracy: 0.6400\n",
      "Epoch 94/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.2346 - accuracy: 0.7188\n",
      "Epoch 94: val_accuracy did not improve from 0.76000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.2267 - accuracy: 0.7245 - val_loss: 3.3613 - val_accuracy: 0.6800\n",
      "Epoch 95/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.1438 - accuracy: 0.7396\n",
      "Epoch 95: val_accuracy did not improve from 0.76000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.1354 - accuracy: 0.7449 - val_loss: 3.3424 - val_accuracy: 0.6800\n",
      "Epoch 96/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.2318 - accuracy: 0.6979\n",
      "Epoch 96: val_accuracy did not improve from 0.76000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.2314 - accuracy: 0.6939 - val_loss: 3.3369 - val_accuracy: 0.6400\n",
      "Epoch 97/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.1097 - accuracy: 0.7708\n",
      "Epoch 97: val_accuracy improved from 0.76000 to 0.80000, saving model to calc_and_exp_2-12.hdf5\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 2.1093 - accuracy: 0.7755 - val_loss: 3.3120 - val_accuracy: 0.8000\n",
      "Epoch 98/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.1026 - accuracy: 0.7604\n",
      "Epoch 98: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.1039 - accuracy: 0.7551 - val_loss: 3.3091 - val_accuracy: 0.6800\n",
      "Epoch 99/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.1392 - accuracy: 0.6979\n",
      "Epoch 99: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 2.1266 - accuracy: 0.7041 - val_loss: 3.2908 - val_accuracy: 0.7200\n",
      "Epoch 100/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.9970 - accuracy: 0.8021\n",
      "Epoch 100: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.9851 - accuracy: 0.8061 - val_loss: 3.2589 - val_accuracy: 0.7600\n",
      "Epoch 101/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.0137 - accuracy: 0.7812\n",
      "Epoch 101: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.0010 - accuracy: 0.7857 - val_loss: 3.2424 - val_accuracy: 0.7600\n",
      "Epoch 102/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.0970 - accuracy: 0.7500\n",
      "Epoch 102: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.1157 - accuracy: 0.7347 - val_loss: 3.2306 - val_accuracy: 0.7200\n",
      "Epoch 103/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.0191 - accuracy: 0.7917\n",
      "Epoch 103: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.0084 - accuracy: 0.7959 - val_loss: 3.1915 - val_accuracy: 0.6800\n",
      "Epoch 104/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.0714 - accuracy: 0.7292\n",
      "Epoch 104: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.0595 - accuracy: 0.7347 - val_loss: 3.1915 - val_accuracy: 0.7600\n",
      "Epoch 105/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.0028 - accuracy: 0.7917\n",
      "Epoch 105: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.0052 - accuracy: 0.7959 - val_loss: 3.1893 - val_accuracy: 0.6400\n",
      "Epoch 106/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.0990 - accuracy: 0.7500\n",
      "Epoch 106: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 2.1061 - accuracy: 0.7449 - val_loss: 3.1940 - val_accuracy: 0.6400\n",
      "Epoch 107/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.9702 - accuracy: 0.8125\n",
      "Epoch 107: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.9648 - accuracy: 0.8163 - val_loss: 3.1440 - val_accuracy: 0.7200\n",
      "Epoch 108/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.1217 - accuracy: 0.7604\n",
      "Epoch 108: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 2.1069 - accuracy: 0.7653 - val_loss: 3.1365 - val_accuracy: 0.8000\n",
      "Epoch 109/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.9438 - accuracy: 0.8333\n",
      "Epoch 109: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.9517 - accuracy: 0.8265 - val_loss: 3.1123 - val_accuracy: 0.7600\n",
      "Epoch 110/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.9851 - accuracy: 0.7396\n",
      "Epoch 110: val_accuracy did not improve from 0.80000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.9874 - accuracy: 0.7347 - val_loss: 3.1164 - val_accuracy: 0.8000\n",
      "Epoch 111/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.0085 - accuracy: 0.7500\n",
      "Epoch 111: val_accuracy improved from 0.80000 to 0.88000, saving model to calc_and_exp_2-12.hdf5\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 2.0057 - accuracy: 0.7449 - val_loss: 3.1008 - val_accuracy: 0.8800\n",
      "Epoch 112/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.8768 - accuracy: 0.7917\n",
      "Epoch 112: val_accuracy did not improve from 0.88000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.8767 - accuracy: 0.7959 - val_loss: 3.0989 - val_accuracy: 0.7600\n",
      "Epoch 113/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.9950 - accuracy: 0.7857\n",
      "Epoch 113: val_accuracy did not improve from 0.88000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.9950 - accuracy: 0.7857 - val_loss: 3.0776 - val_accuracy: 0.7600\n",
      "Epoch 114/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.9097 - accuracy: 0.7812\n",
      "Epoch 114: val_accuracy did not improve from 0.88000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 1.9012 - accuracy: 0.7857 - val_loss: 3.0652 - val_accuracy: 0.7200\n",
      "Epoch 115/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.8333 - accuracy: 0.8367\n",
      "Epoch 115: val_accuracy did not improve from 0.88000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.8333 - accuracy: 0.8367 - val_loss: 3.0246 - val_accuracy: 0.8400\n",
      "Epoch 116/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 2.0135 - accuracy: 0.7604\n",
      "Epoch 116: val_accuracy did not improve from 0.88000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 2.0289 - accuracy: 0.7449 - val_loss: 3.0140 - val_accuracy: 0.7600\n",
      "Epoch 117/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.8594 - accuracy: 0.8265\n",
      "Epoch 117: val_accuracy did not improve from 0.88000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.8594 - accuracy: 0.8265 - val_loss: 3.0111 - val_accuracy: 0.7200\n",
      "Epoch 118/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.8322 - accuracy: 0.8125\n",
      "Epoch 118: val_accuracy did not improve from 0.88000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.8238 - accuracy: 0.8163 - val_loss: 2.9944 - val_accuracy: 0.7200\n",
      "Epoch 119/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.9115 - accuracy: 0.7708\n",
      "Epoch 119: val_accuracy did not improve from 0.88000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.9071 - accuracy: 0.7755 - val_loss: 2.9881 - val_accuracy: 0.6000\n",
      "Epoch 120/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.9357 - accuracy: 0.7812\n",
      "Epoch 120: val_accuracy did not improve from 0.88000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 1.9242 - accuracy: 0.7857 - val_loss: 2.9583 - val_accuracy: 0.6800\n",
      "Epoch 121/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.8149 - accuracy: 0.8061\n",
      "Epoch 121: val_accuracy did not improve from 0.88000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.8149 - accuracy: 0.8061 - val_loss: 2.9328 - val_accuracy: 0.8000\n",
      "Epoch 122/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.7787 - accuracy: 0.8229\n",
      "Epoch 122: val_accuracy did not improve from 0.88000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 1.7911 - accuracy: 0.8163 - val_loss: 2.9198 - val_accuracy: 0.8000\n",
      "Epoch 123/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.8744 - accuracy: 0.7755\n",
      "Epoch 123: val_accuracy did not improve from 0.88000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.8744 - accuracy: 0.7755 - val_loss: 2.9070 - val_accuracy: 0.7600\n",
      "Epoch 124/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.8386 - accuracy: 0.8438\n",
      "Epoch 124: val_accuracy did not improve from 0.88000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.8581 - accuracy: 0.8367 - val_loss: 2.9068 - val_accuracy: 0.8400\n",
      "Epoch 125/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.7877 - accuracy: 0.8229\n",
      "Epoch 125: val_accuracy did not improve from 0.88000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.7783 - accuracy: 0.8265 - val_loss: 2.8881 - val_accuracy: 0.8000\n",
      "Epoch 126/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.7724 - accuracy: 0.8333\n",
      "Epoch 126: val_accuracy did not improve from 0.88000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.7652 - accuracy: 0.8367 - val_loss: 2.8606 - val_accuracy: 0.8400\n",
      "Epoch 127/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.7443 - accuracy: 0.8125\n",
      "Epoch 127: val_accuracy did not improve from 0.88000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.7402 - accuracy: 0.8163 - val_loss: 2.8345 - val_accuracy: 0.7200\n",
      "Epoch 128/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.8844 - accuracy: 0.7917\n",
      "Epoch 128: val_accuracy did not improve from 0.88000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.8914 - accuracy: 0.7857 - val_loss: 2.8324 - val_accuracy: 0.7200\n",
      "Epoch 129/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.8257 - accuracy: 0.8125\n",
      "Epoch 129: val_accuracy did not improve from 0.88000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.8274 - accuracy: 0.8061 - val_loss: 2.7872 - val_accuracy: 0.6400\n",
      "Epoch 130/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.7942 - accuracy: 0.7812\n",
      "Epoch 130: val_accuracy improved from 0.88000 to 0.92000, saving model to calc_and_exp_2-12.hdf5\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.8129 - accuracy: 0.7755 - val_loss: 2.7623 - val_accuracy: 0.9200\n",
      "Epoch 131/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.7345 - accuracy: 0.8333\n",
      "Epoch 131: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.7404 - accuracy: 0.8265 - val_loss: 2.7547 - val_accuracy: 0.8000\n",
      "Epoch 132/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.7042 - accuracy: 0.8542\n",
      "Epoch 132: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.7017 - accuracy: 0.8571 - val_loss: 2.7257 - val_accuracy: 0.8000\n",
      "Epoch 133/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.6559 - accuracy: 0.8646\n",
      "Epoch 133: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.6567 - accuracy: 0.8673 - val_loss: 2.7108 - val_accuracy: 0.8400\n",
      "Epoch 134/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.7468 - accuracy: 0.8333\n",
      "Epoch 134: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.7456 - accuracy: 0.8367 - val_loss: 2.7281 - val_accuracy: 0.8400\n",
      "Epoch 135/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.7452 - accuracy: 0.8542\n",
      "Epoch 135: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.7422 - accuracy: 0.8571 - val_loss: 2.7159 - val_accuracy: 0.7200\n",
      "Epoch 136/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.8038 - accuracy: 0.7755\n",
      "Epoch 136: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 1.8038 - accuracy: 0.7755 - val_loss: 2.6956 - val_accuracy: 0.7200\n",
      "Epoch 137/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.7750 - accuracy: 0.8021\n",
      "Epoch 137: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.7767 - accuracy: 0.7959 - val_loss: 2.6506 - val_accuracy: 0.8400\n",
      "Epoch 138/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.6829 - accuracy: 0.8229\n",
      "Epoch 138: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.6815 - accuracy: 0.8265 - val_loss: 2.6179 - val_accuracy: 0.7600\n",
      "Epoch 139/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.7987 - accuracy: 0.7812\n",
      "Epoch 139: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.7961 - accuracy: 0.7857 - val_loss: 2.6002 - val_accuracy: 0.7200\n",
      "Epoch 140/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.6332 - accuracy: 0.8646\n",
      "Epoch 140: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.6250 - accuracy: 0.8673 - val_loss: 2.6009 - val_accuracy: 0.7600\n",
      "Epoch 141/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.6173 - accuracy: 0.8438\n",
      "Epoch 141: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.6384 - accuracy: 0.8367 - val_loss: 2.5801 - val_accuracy: 0.6800\n",
      "Epoch 142/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.6748 - accuracy: 0.8438\n",
      "Epoch 142: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.6910 - accuracy: 0.8367 - val_loss: 2.5565 - val_accuracy: 0.7600\n",
      "Epoch 143/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.6656 - accuracy: 0.8229\n",
      "Epoch 143: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.6636 - accuracy: 0.8265 - val_loss: 2.5532 - val_accuracy: 0.7200\n",
      "Epoch 144/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.7488 - accuracy: 0.7653\n",
      "Epoch 144: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.7488 - accuracy: 0.7653 - val_loss: 2.5223 - val_accuracy: 0.8000\n",
      "Epoch 145/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.6376 - accuracy: 0.8542\n",
      "Epoch 145: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.6433 - accuracy: 0.8469 - val_loss: 2.4941 - val_accuracy: 0.8400\n",
      "Epoch 146/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.5546 - accuracy: 0.8646\n",
      "Epoch 146: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.5486 - accuracy: 0.8673 - val_loss: 2.4782 - val_accuracy: 0.8400\n",
      "Epoch 147/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.6334 - accuracy: 0.8163\n",
      "Epoch 147: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.6334 - accuracy: 0.8163 - val_loss: 2.4713 - val_accuracy: 0.7600\n",
      "Epoch 148/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.5980 - accuracy: 0.8542\n",
      "Epoch 148: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.5927 - accuracy: 0.8571 - val_loss: 2.4418 - val_accuracy: 0.8000\n",
      "Epoch 149/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.6922 - accuracy: 0.8542\n",
      "Epoch 149: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.6815 - accuracy: 0.8571 - val_loss: 2.4262 - val_accuracy: 0.8000\n",
      "Epoch 150/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.6636 - accuracy: 0.8229\n",
      "Epoch 150: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.6582 - accuracy: 0.8265 - val_loss: 2.4323 - val_accuracy: 0.7600\n",
      "Epoch 151/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.6599 - accuracy: 0.8229\n",
      "Epoch 151: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.6496 - accuracy: 0.8265 - val_loss: 2.4103 - val_accuracy: 0.7600\n",
      "Epoch 152/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.6691 - accuracy: 0.7812\n",
      "Epoch 152: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.6587 - accuracy: 0.7857 - val_loss: 2.3983 - val_accuracy: 0.8000\n",
      "Epoch 153/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.4851 - accuracy: 0.8958\n",
      "Epoch 153: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.4898 - accuracy: 0.8878 - val_loss: 2.3918 - val_accuracy: 0.8400\n",
      "Epoch 154/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.6581 - accuracy: 0.8438\n",
      "Epoch 154: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.6570 - accuracy: 0.8469 - val_loss: 2.3594 - val_accuracy: 0.8800\n",
      "Epoch 155/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.5146 - accuracy: 0.8646\n",
      "Epoch 155: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.5077 - accuracy: 0.8673 - val_loss: 2.3392 - val_accuracy: 0.8000\n",
      "Epoch 156/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.5235 - accuracy: 0.8542\n",
      "Epoch 156: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.5157 - accuracy: 0.8571 - val_loss: 2.3090 - val_accuracy: 0.8400\n",
      "Epoch 157/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.5291 - accuracy: 0.8542\n",
      "Epoch 157: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.5211 - accuracy: 0.8571 - val_loss: 2.3111 - val_accuracy: 0.8000\n",
      "Epoch 158/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.6217 - accuracy: 0.8125\n",
      "Epoch 158: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.6116 - accuracy: 0.8163 - val_loss: 2.2864 - val_accuracy: 0.8000\n",
      "Epoch 159/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.5373 - accuracy: 0.8333\n",
      "Epoch 159: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.5339 - accuracy: 0.8367 - val_loss: 2.2954 - val_accuracy: 0.6800\n",
      "Epoch 160/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.6484 - accuracy: 0.8125\n",
      "Epoch 160: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.6521 - accuracy: 0.8061 - val_loss: 2.3478 - val_accuracy: 0.6800\n",
      "Epoch 161/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.5197 - accuracy: 0.8438\n",
      "Epoch 161: val_accuracy did not improve from 0.92000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.5211 - accuracy: 0.8469 - val_loss: 2.2743 - val_accuracy: 0.8400\n",
      "Epoch 162/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.5253 - accuracy: 0.8854\n",
      "Epoch 162: val_accuracy improved from 0.92000 to 0.96000, saving model to calc_and_exp_2-12.hdf5\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 1.5227 - accuracy: 0.8878 - val_loss: 2.2140 - val_accuracy: 0.9600\n",
      "Epoch 163/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.5142 - accuracy: 0.8125\n",
      "Epoch 163: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.5061 - accuracy: 0.8163 - val_loss: 2.2297 - val_accuracy: 0.8400\n",
      "Epoch 164/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.4639 - accuracy: 0.8878\n",
      "Epoch 164: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.4639 - accuracy: 0.8878 - val_loss: 2.2514 - val_accuracy: 0.8000\n",
      "Epoch 165/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.4685 - accuracy: 0.8750\n",
      "Epoch 165: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.4627 - accuracy: 0.8776 - val_loss: 2.2268 - val_accuracy: 0.7600\n",
      "Epoch 166/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.5344 - accuracy: 0.8229\n",
      "Epoch 166: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.5338 - accuracy: 0.8265 - val_loss: 2.1708 - val_accuracy: 0.8800\n",
      "Epoch 167/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.5605 - accuracy: 0.8542\n",
      "Epoch 167: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.5510 - accuracy: 0.8571 - val_loss: 2.1697 - val_accuracy: 0.8400\n",
      "Epoch 168/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.4600 - accuracy: 0.8646\n",
      "Epoch 168: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.4548 - accuracy: 0.8673 - val_loss: 2.1769 - val_accuracy: 0.7200\n",
      "Epoch 169/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.4896 - accuracy: 0.8229\n",
      "Epoch 169: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.4830 - accuracy: 0.8265 - val_loss: 2.1379 - val_accuracy: 0.8000\n",
      "Epoch 170/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.4485 - accuracy: 0.8854\n",
      "Epoch 170: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.4421 - accuracy: 0.8878 - val_loss: 2.1136 - val_accuracy: 0.8000\n",
      "Epoch 171/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.4129 - accuracy: 0.8958\n",
      "Epoch 171: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.4097 - accuracy: 0.8980 - val_loss: 2.0962 - val_accuracy: 0.8400\n",
      "Epoch 172/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.4451 - accuracy: 0.8958\n",
      "Epoch 172: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.4384 - accuracy: 0.8980 - val_loss: 2.0631 - val_accuracy: 0.8400\n",
      "Epoch 173/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.4604 - accuracy: 0.8021\n",
      "Epoch 173: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.4523 - accuracy: 0.8061 - val_loss: 2.0358 - val_accuracy: 0.8400\n",
      "Epoch 174/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3582 - accuracy: 0.8958\n",
      "Epoch 174: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.3665 - accuracy: 0.8878 - val_loss: 2.1080 - val_accuracy: 0.7600\n",
      "Epoch 175/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.4046 - accuracy: 0.8958\n",
      "Epoch 175: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.4148 - accuracy: 0.8878 - val_loss: 2.0404 - val_accuracy: 0.7600\n",
      "Epoch 176/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3572 - accuracy: 0.8750\n",
      "Epoch 176: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.3673 - accuracy: 0.8673 - val_loss: 2.0361 - val_accuracy: 0.8800\n",
      "Epoch 177/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3205 - accuracy: 0.9062\n",
      "Epoch 177: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.3149 - accuracy: 0.9082 - val_loss: 2.0124 - val_accuracy: 0.8800\n",
      "Epoch 178/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3405 - accuracy: 0.8958\n",
      "Epoch 178: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.3557 - accuracy: 0.8878 - val_loss: 2.0403 - val_accuracy: 0.8400\n",
      "Epoch 179/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3363 - accuracy: 0.8854\n",
      "Epoch 179: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 1.3314 - accuracy: 0.8878 - val_loss: 2.0021 - val_accuracy: 0.8400\n",
      "Epoch 180/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.4531 - accuracy: 0.8646\n",
      "Epoch 180: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.4454 - accuracy: 0.8673 - val_loss: 2.0374 - val_accuracy: 0.8000\n",
      "Epoch 181/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3818 - accuracy: 0.8958\n",
      "Epoch 181: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.3753 - accuracy: 0.8980 - val_loss: 2.0228 - val_accuracy: 0.8400\n",
      "Epoch 182/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.4993 - accuracy: 0.8229\n",
      "Epoch 182: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.4910 - accuracy: 0.8265 - val_loss: 1.9685 - val_accuracy: 0.8400\n",
      "Epoch 183/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3098 - accuracy: 0.9167\n",
      "Epoch 183: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.3080 - accuracy: 0.9184 - val_loss: 1.9087 - val_accuracy: 0.8800\n",
      "Epoch 184/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.4240 - accuracy: 0.8542\n",
      "Epoch 184: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.4241 - accuracy: 0.8571 - val_loss: 1.9312 - val_accuracy: 0.9200\n",
      "Epoch 185/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3412 - accuracy: 0.8750\n",
      "Epoch 185: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.3372 - accuracy: 0.8776 - val_loss: 1.9019 - val_accuracy: 0.8800\n",
      "Epoch 186/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2778 - accuracy: 0.9062\n",
      "Epoch 186: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.2733 - accuracy: 0.9082 - val_loss: 1.9042 - val_accuracy: 0.8800\n",
      "Epoch 187/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2563 - accuracy: 0.9184\n",
      "Epoch 187: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.2563 - accuracy: 0.9184 - val_loss: 1.9384 - val_accuracy: 0.8400\n",
      "Epoch 188/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3996 - accuracy: 0.8750\n",
      "Epoch 188: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.3926 - accuracy: 0.8776 - val_loss: 1.9167 - val_accuracy: 0.8800\n",
      "Epoch 189/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3071 - accuracy: 0.8854\n",
      "Epoch 189: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.3127 - accuracy: 0.8878 - val_loss: 1.8672 - val_accuracy: 0.8800\n",
      "Epoch 190/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.4077 - accuracy: 0.8542\n",
      "Epoch 190: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.3995 - accuracy: 0.8571 - val_loss: 1.8640 - val_accuracy: 0.8400\n",
      "Epoch 191/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2853 - accuracy: 0.9167\n",
      "Epoch 191: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.2853 - accuracy: 0.9184 - val_loss: 1.8791 - val_accuracy: 0.8800\n",
      "Epoch 192/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2653 - accuracy: 0.8958\n",
      "Epoch 192: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.2602 - accuracy: 0.8980 - val_loss: 1.8538 - val_accuracy: 0.8800\n",
      "Epoch 193/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.3225 - accuracy: 0.8958\n",
      "Epoch 193: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.3174 - accuracy: 0.8980 - val_loss: 1.8611 - val_accuracy: 0.8800\n",
      "Epoch 194/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2244 - accuracy: 0.9271\n",
      "Epoch 194: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.2197 - accuracy: 0.9286 - val_loss: 1.8628 - val_accuracy: 0.8800\n",
      "Epoch 195/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2793 - accuracy: 0.8958\n",
      "Epoch 195: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.2863 - accuracy: 0.8878 - val_loss: 1.9114 - val_accuracy: 0.8000\n",
      "Epoch 196/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2653 - accuracy: 0.8958\n",
      "Epoch 196: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.2597 - accuracy: 0.8980 - val_loss: 1.8459 - val_accuracy: 0.8800\n",
      "Epoch 197/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2723 - accuracy: 0.8750\n",
      "Epoch 197: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.2662 - accuracy: 0.8776 - val_loss: 1.8161 - val_accuracy: 0.8800\n",
      "Epoch 198/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2494 - accuracy: 0.9375\n",
      "Epoch 198: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.2784 - accuracy: 0.9184 - val_loss: 1.8090 - val_accuracy: 0.9200\n",
      "Epoch 199/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2941 - accuracy: 0.8542\n",
      "Epoch 199: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.2886 - accuracy: 0.8571 - val_loss: 1.7945 - val_accuracy: 0.8800\n",
      "Epoch 200/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.2450 - accuracy: 0.8878\n",
      "Epoch 200: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 1.2450 - accuracy: 0.8878 - val_loss: 1.7850 - val_accuracy: 0.8800\n",
      "Epoch 201/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2507 - accuracy: 0.8854\n",
      "Epoch 201: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.2497 - accuracy: 0.8878 - val_loss: 1.8489 - val_accuracy: 0.8000\n",
      "Epoch 202/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2889 - accuracy: 0.8958\n",
      "Epoch 202: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.3198 - accuracy: 0.8878 - val_loss: 1.8174 - val_accuracy: 0.8400\n",
      "Epoch 203/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2930 - accuracy: 0.8854\n",
      "Epoch 203: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.2861 - accuracy: 0.8878 - val_loss: 1.7899 - val_accuracy: 0.9200\n",
      "Epoch 204/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2215 - accuracy: 0.8958\n",
      "Epoch 204: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.2180 - accuracy: 0.8980 - val_loss: 1.7616 - val_accuracy: 0.9200\n",
      "Epoch 205/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1580 - accuracy: 0.9271\n",
      "Epoch 205: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.1547 - accuracy: 0.9286 - val_loss: 1.7261 - val_accuracy: 0.9200\n",
      "Epoch 206/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2238 - accuracy: 0.8958\n",
      "Epoch 206: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.2397 - accuracy: 0.8878 - val_loss: 1.7234 - val_accuracy: 0.9200\n",
      "Epoch 207/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2264 - accuracy: 0.9375\n",
      "Epoch 207: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.2218 - accuracy: 0.9388 - val_loss: 1.7203 - val_accuracy: 0.9600\n",
      "Epoch 208/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1944 - accuracy: 0.8854\n",
      "Epoch 208: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.1896 - accuracy: 0.8878 - val_loss: 1.7173 - val_accuracy: 0.8800\n",
      "Epoch 209/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1508 - accuracy: 0.9271\n",
      "Epoch 209: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.1472 - accuracy: 0.9286 - val_loss: 1.7260 - val_accuracy: 0.8800\n",
      "Epoch 210/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2332 - accuracy: 0.8854\n",
      "Epoch 210: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.2397 - accuracy: 0.8878 - val_loss: 1.8155 - val_accuracy: 0.7600\n",
      "Epoch 211/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2296 - accuracy: 0.9062\n",
      "Epoch 211: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.2310 - accuracy: 0.9082 - val_loss: 1.7636 - val_accuracy: 0.8400\n",
      "Epoch 212/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2286 - accuracy: 0.8750\n",
      "Epoch 212: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.2223 - accuracy: 0.8776 - val_loss: 1.7302 - val_accuracy: 0.8800\n",
      "Epoch 213/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1757 - accuracy: 0.8854\n",
      "Epoch 213: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.1735 - accuracy: 0.8878 - val_loss: 1.8112 - val_accuracy: 0.7200\n",
      "Epoch 214/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1348 - accuracy: 0.9184\n",
      "Epoch 214: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 1.1348 - accuracy: 0.9184 - val_loss: 1.7240 - val_accuracy: 0.8800\n",
      "Epoch 215/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2113 - accuracy: 0.8854\n",
      "Epoch 215: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.2151 - accuracy: 0.8878 - val_loss: 1.6978 - val_accuracy: 0.8800\n",
      "Epoch 216/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2214 - accuracy: 0.9062\n",
      "Epoch 216: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.2151 - accuracy: 0.9082 - val_loss: 1.6689 - val_accuracy: 0.8800\n",
      "Epoch 217/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1601 - accuracy: 0.9062\n",
      "Epoch 217: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.1590 - accuracy: 0.9082 - val_loss: 1.6561 - val_accuracy: 0.9200\n",
      "Epoch 218/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.1256 - accuracy: 0.9388\n",
      "Epoch 218: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 1.1256 - accuracy: 0.9388 - val_loss: 1.7152 - val_accuracy: 0.8400\n",
      "Epoch 219/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1623 - accuracy: 0.9271\n",
      "Epoch 219: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.1752 - accuracy: 0.9184 - val_loss: 1.6367 - val_accuracy: 0.8800\n",
      "Epoch 220/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1443 - accuracy: 0.9167\n",
      "Epoch 220: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.1398 - accuracy: 0.9184 - val_loss: 1.6593 - val_accuracy: 0.8800\n",
      "Epoch 221/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0844 - accuracy: 0.9583\n",
      "Epoch 221: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 1.0808 - accuracy: 0.9592 - val_loss: 1.6546 - val_accuracy: 0.9200\n",
      "Epoch 222/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.2021 - accuracy: 0.8646\n",
      "Epoch 222: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.1982 - accuracy: 0.8673 - val_loss: 1.6064 - val_accuracy: 0.8800\n",
      "Epoch 223/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0984 - accuracy: 0.9271\n",
      "Epoch 223: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.0941 - accuracy: 0.9286 - val_loss: 1.6040 - val_accuracy: 0.8800\n",
      "Epoch 224/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1561 - accuracy: 0.9271\n",
      "Epoch 224: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.1505 - accuracy: 0.9286 - val_loss: 1.6033 - val_accuracy: 0.8800\n",
      "Epoch 225/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0741 - accuracy: 0.9375\n",
      "Epoch 225: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.0703 - accuracy: 0.9388 - val_loss: 1.5969 - val_accuracy: 0.8800\n",
      "Epoch 226/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0706 - accuracy: 0.9688\n",
      "Epoch 226: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.0668 - accuracy: 0.9694 - val_loss: 1.5743 - val_accuracy: 0.8800\n",
      "Epoch 227/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0629 - accuracy: 0.9688\n",
      "Epoch 227: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.0592 - accuracy: 0.9694 - val_loss: 1.5560 - val_accuracy: 0.8800\n",
      "Epoch 228/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0924 - accuracy: 0.9375\n",
      "Epoch 228: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.0945 - accuracy: 0.9388 - val_loss: 1.6096 - val_accuracy: 0.8000\n",
      "Epoch 229/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1039 - accuracy: 0.9271\n",
      "Epoch 229: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.1002 - accuracy: 0.9286 - val_loss: 1.5502 - val_accuracy: 0.9200\n",
      "Epoch 230/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1313 - accuracy: 0.8958\n",
      "Epoch 230: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.1296 - accuracy: 0.8980 - val_loss: 1.6428 - val_accuracy: 0.8400\n",
      "Epoch 231/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0968 - accuracy: 0.8958\n",
      "Epoch 231: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.0952 - accuracy: 0.8980 - val_loss: 1.5712 - val_accuracy: 0.8800\n",
      "Epoch 232/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1406 - accuracy: 0.9167\n",
      "Epoch 232: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.1358 - accuracy: 0.9184 - val_loss: 1.5687 - val_accuracy: 0.9200\n",
      "Epoch 233/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1642 - accuracy: 0.9062\n",
      "Epoch 233: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.1580 - accuracy: 0.9082 - val_loss: 1.5748 - val_accuracy: 0.8800\n",
      "Epoch 234/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1460 - accuracy: 0.9062\n",
      "Epoch 234: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.1399 - accuracy: 0.9082 - val_loss: 1.5281 - val_accuracy: 0.9200\n",
      "Epoch 235/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1052 - accuracy: 0.8958\n",
      "Epoch 235: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 1.1014 - accuracy: 0.8980 - val_loss: 1.5229 - val_accuracy: 0.8800\n",
      "Epoch 236/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0300 - accuracy: 0.9167\n",
      "Epoch 236: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.0265 - accuracy: 0.9184 - val_loss: 1.5240 - val_accuracy: 0.9200\n",
      "Epoch 237/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0097 - accuracy: 0.9479\n",
      "Epoch 237: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.0063 - accuracy: 0.9490 - val_loss: 1.5481 - val_accuracy: 0.8800\n",
      "Epoch 238/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1503 - accuracy: 0.9062\n",
      "Epoch 238: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.1443 - accuracy: 0.9082 - val_loss: 1.5590 - val_accuracy: 0.8800\n",
      "Epoch 239/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1271 - accuracy: 0.9062\n",
      "Epoch 239: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.1353 - accuracy: 0.8980 - val_loss: 1.5628 - val_accuracy: 0.8400\n",
      "Epoch 240/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0835 - accuracy: 0.9167\n",
      "Epoch 240: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.0812 - accuracy: 0.9184 - val_loss: 1.5249 - val_accuracy: 0.8800\n",
      "Epoch 241/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0084 - accuracy: 0.9479\n",
      "Epoch 241: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.0048 - accuracy: 0.9490 - val_loss: 1.4898 - val_accuracy: 0.9200\n",
      "Epoch 242/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9571 - accuracy: 0.9688\n",
      "Epoch 242: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.9543 - accuracy: 0.9694 - val_loss: 1.4807 - val_accuracy: 0.9200\n",
      "Epoch 243/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.1505 - accuracy: 0.8958\n",
      "Epoch 243: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.1457 - accuracy: 0.8980 - val_loss: 1.4995 - val_accuracy: 0.8400\n",
      "Epoch 244/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9517 - accuracy: 0.9792\n",
      "Epoch 244: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.9569 - accuracy: 0.9796 - val_loss: 1.5770 - val_accuracy: 0.8400\n",
      "Epoch 245/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0578 - accuracy: 0.8958\n",
      "Epoch 245: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.0531 - accuracy: 0.8980 - val_loss: 1.4920 - val_accuracy: 0.9200\n",
      "Epoch 246/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0467 - accuracy: 0.9271\n",
      "Epoch 246: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.0449 - accuracy: 0.9286 - val_loss: 1.5350 - val_accuracy: 0.8400\n",
      "Epoch 247/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9767 - accuracy: 0.9375\n",
      "Epoch 247: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.9764 - accuracy: 0.9388 - val_loss: 1.5176 - val_accuracy: 0.8400\n",
      "Epoch 248/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0568 - accuracy: 0.9062\n",
      "Epoch 248: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 1.0517 - accuracy: 0.9082 - val_loss: 1.4842 - val_accuracy: 0.8400\n",
      "Epoch 249/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9628 - accuracy: 0.9688\n",
      "Epoch 249: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.9635 - accuracy: 0.9694 - val_loss: 1.4416 - val_accuracy: 0.8800\n",
      "Epoch 250/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0186 - accuracy: 0.9184\n",
      "Epoch 250: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 1.0186 - accuracy: 0.9184 - val_loss: 1.4918 - val_accuracy: 0.8800\n",
      "Epoch 251/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9741 - accuracy: 0.9062\n",
      "Epoch 251: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.9713 - accuracy: 0.9082 - val_loss: 1.4638 - val_accuracy: 0.8800\n",
      "Epoch 252/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0215 - accuracy: 0.9082\n",
      "Epoch 252: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 1.0215 - accuracy: 0.9082 - val_loss: 1.4847 - val_accuracy: 0.8400\n",
      "Epoch 253/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0025 - accuracy: 0.8980\n",
      "Epoch 253: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 1.0025 - accuracy: 0.8980 - val_loss: 1.4695 - val_accuracy: 0.8800\n",
      "Epoch 254/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0111 - accuracy: 0.9271\n",
      "Epoch 254: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 1.0151 - accuracy: 0.9286 - val_loss: 1.4599 - val_accuracy: 0.8800\n",
      "Epoch 255/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9168 - accuracy: 0.9688\n",
      "Epoch 255: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.9156 - accuracy: 0.9694 - val_loss: 1.4525 - val_accuracy: 0.8400\n",
      "Epoch 256/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0321 - accuracy: 0.9167\n",
      "Epoch 256: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.0280 - accuracy: 0.9184 - val_loss: 1.4908 - val_accuracy: 0.8000\n",
      "Epoch 257/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9728 - accuracy: 0.9167\n",
      "Epoch 257: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.9690 - accuracy: 0.9184 - val_loss: 1.5033 - val_accuracy: 0.7600\n",
      "Epoch 258/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9274 - accuracy: 0.9479\n",
      "Epoch 258: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.9244 - accuracy: 0.9490 - val_loss: 1.4575 - val_accuracy: 0.8400\n",
      "Epoch 259/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9019 - accuracy: 0.9694\n",
      "Epoch 259: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.9019 - accuracy: 0.9694 - val_loss: 1.5295 - val_accuracy: 0.7600\n",
      "Epoch 260/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9058 - accuracy: 0.9479\n",
      "Epoch 260: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.9032 - accuracy: 0.9490 - val_loss: 1.4518 - val_accuracy: 0.8400\n",
      "Epoch 261/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8975 - accuracy: 0.9792\n",
      "Epoch 261: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8981 - accuracy: 0.9796 - val_loss: 1.4037 - val_accuracy: 0.8400\n",
      "Epoch 262/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9179 - accuracy: 0.9583\n",
      "Epoch 262: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.9151 - accuracy: 0.9592 - val_loss: 1.3876 - val_accuracy: 0.8800\n",
      "Epoch 263/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9415 - accuracy: 0.9375\n",
      "Epoch 263: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.9619 - accuracy: 0.9286 - val_loss: 1.3878 - val_accuracy: 0.8400\n",
      "Epoch 264/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9113 - accuracy: 0.9479\n",
      "Epoch 264: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.9194 - accuracy: 0.9388 - val_loss: 1.4053 - val_accuracy: 0.8800\n",
      "Epoch 265/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0343 - accuracy: 0.9062\n",
      "Epoch 265: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.0461 - accuracy: 0.8980 - val_loss: 1.5586 - val_accuracy: 0.7600\n",
      "Epoch 266/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 1.0391 - accuracy: 0.8750\n",
      "Epoch 266: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 1.0335 - accuracy: 0.8776 - val_loss: 1.4835 - val_accuracy: 0.8000\n",
      "Epoch 267/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9190 - accuracy: 0.9694\n",
      "Epoch 267: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.9190 - accuracy: 0.9694 - val_loss: 1.4200 - val_accuracy: 0.8400\n",
      "Epoch 268/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9573 - accuracy: 0.9167\n",
      "Epoch 268: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.9530 - accuracy: 0.9184 - val_loss: 1.4018 - val_accuracy: 0.8800\n",
      "Epoch 269/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8755 - accuracy: 0.9583\n",
      "Epoch 269: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8741 - accuracy: 0.9592 - val_loss: 1.4030 - val_accuracy: 0.8400\n",
      "Epoch 270/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9461 - accuracy: 0.9062\n",
      "Epoch 270: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.9448 - accuracy: 0.9082 - val_loss: 1.4134 - val_accuracy: 0.8400\n",
      "Epoch 271/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8696 - accuracy: 0.9688\n",
      "Epoch 271: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8678 - accuracy: 0.9694 - val_loss: 1.3548 - val_accuracy: 0.9200\n",
      "Epoch 272/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9399 - accuracy: 0.9375\n",
      "Epoch 272: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.9397 - accuracy: 0.9388 - val_loss: 1.4704 - val_accuracy: 0.8800\n",
      "Epoch 273/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9091 - accuracy: 0.9271\n",
      "Epoch 273: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.9062 - accuracy: 0.9286 - val_loss: 1.4133 - val_accuracy: 0.8400\n",
      "Epoch 274/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9019 - accuracy: 0.9688\n",
      "Epoch 274: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8988 - accuracy: 0.9694 - val_loss: 1.4113 - val_accuracy: 0.8800\n",
      "Epoch 275/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8655 - accuracy: 0.9583\n",
      "Epoch 275: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8719 - accuracy: 0.9490 - val_loss: 1.5496 - val_accuracy: 0.7600\n",
      "Epoch 276/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9857 - accuracy: 0.9167\n",
      "Epoch 276: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.9817 - accuracy: 0.9184 - val_loss: 1.4363 - val_accuracy: 0.7600\n",
      "Epoch 277/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8793 - accuracy: 0.9479\n",
      "Epoch 277: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8761 - accuracy: 0.9490 - val_loss: 1.3994 - val_accuracy: 0.8400\n",
      "Epoch 278/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9547 - accuracy: 0.8958\n",
      "Epoch 278: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.9597 - accuracy: 0.8980 - val_loss: 1.4016 - val_accuracy: 0.8400\n",
      "Epoch 279/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8433 - accuracy: 0.9688\n",
      "Epoch 279: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8417 - accuracy: 0.9694 - val_loss: 1.3845 - val_accuracy: 0.8000\n",
      "Epoch 280/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8764 - accuracy: 0.9375\n",
      "Epoch 280: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8812 - accuracy: 0.9388 - val_loss: 1.4167 - val_accuracy: 0.8000\n",
      "Epoch 281/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8497 - accuracy: 0.9688\n",
      "Epoch 281: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8469 - accuracy: 0.9694 - val_loss: 1.4135 - val_accuracy: 0.7600\n",
      "Epoch 282/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8537 - accuracy: 0.9490\n",
      "Epoch 282: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.8537 - accuracy: 0.9490 - val_loss: 1.4909 - val_accuracy: 0.7600\n",
      "Epoch 283/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9326 - accuracy: 0.9375\n",
      "Epoch 283: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.9418 - accuracy: 0.9286 - val_loss: 1.4217 - val_accuracy: 0.8400\n",
      "Epoch 284/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8972 - accuracy: 0.9271\n",
      "Epoch 284: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8935 - accuracy: 0.9286 - val_loss: 1.3727 - val_accuracy: 0.8800\n",
      "Epoch 285/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8662 - accuracy: 0.9375\n",
      "Epoch 285: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8651 - accuracy: 0.9388 - val_loss: 1.3610 - val_accuracy: 0.8800\n",
      "Epoch 286/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8070 - accuracy: 0.9583\n",
      "Epoch 286: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8055 - accuracy: 0.9592 - val_loss: 1.3578 - val_accuracy: 0.9200\n",
      "Epoch 287/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8455 - accuracy: 0.9583\n",
      "Epoch 287: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8425 - accuracy: 0.9592 - val_loss: 1.3937 - val_accuracy: 0.8400\n",
      "Epoch 288/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8563 - accuracy: 0.9479\n",
      "Epoch 288: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8533 - accuracy: 0.9490 - val_loss: 1.3846 - val_accuracy: 0.9200\n",
      "Epoch 289/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8581 - accuracy: 0.9271\n",
      "Epoch 289: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8879 - accuracy: 0.9184 - val_loss: 1.3324 - val_accuracy: 0.8800\n",
      "Epoch 290/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8515 - accuracy: 0.9479\n",
      "Epoch 290: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.8500 - accuracy: 0.9490 - val_loss: 1.3679 - val_accuracy: 0.8800\n",
      "Epoch 291/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9185 - accuracy: 0.9184\n",
      "Epoch 291: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.9185 - accuracy: 0.9184 - val_loss: 1.3749 - val_accuracy: 0.8800\n",
      "Epoch 292/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8659 - accuracy: 0.9375\n",
      "Epoch 292: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.8623 - accuracy: 0.9388 - val_loss: 1.3655 - val_accuracy: 0.8800\n",
      "Epoch 293/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8099 - accuracy: 0.9583\n",
      "Epoch 293: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.8075 - accuracy: 0.9592 - val_loss: 1.3620 - val_accuracy: 0.8800\n",
      "Epoch 294/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9085 - accuracy: 0.9062\n",
      "Epoch 294: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.9040 - accuracy: 0.9082 - val_loss: 1.3816 - val_accuracy: 0.8800\n",
      "Epoch 295/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8898 - accuracy: 0.9167\n",
      "Epoch 295: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.8958 - accuracy: 0.9082 - val_loss: 1.4208 - val_accuracy: 0.8000\n",
      "Epoch 296/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8384 - accuracy: 0.9490\n",
      "Epoch 296: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.8384 - accuracy: 0.9490 - val_loss: 1.3798 - val_accuracy: 0.8400\n",
      "Epoch 297/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7495 - accuracy: 0.9896\n",
      "Epoch 297: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 67ms/step - loss: 0.7482 - accuracy: 0.9898 - val_loss: 1.3850 - val_accuracy: 0.8000\n",
      "Epoch 298/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7726 - accuracy: 0.9792\n",
      "Epoch 298: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7723 - accuracy: 0.9796 - val_loss: 1.3608 - val_accuracy: 0.8000\n",
      "Epoch 299/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8148 - accuracy: 0.9375\n",
      "Epoch 299: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8165 - accuracy: 0.9388 - val_loss: 1.4794 - val_accuracy: 0.7600\n",
      "Epoch 300/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.9331 - accuracy: 0.9062\n",
      "Epoch 300: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.9419 - accuracy: 0.8980 - val_loss: 1.4348 - val_accuracy: 0.7600\n",
      "Epoch 301/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7794 - accuracy: 0.9583\n",
      "Epoch 301: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7773 - accuracy: 0.9592 - val_loss: 1.3571 - val_accuracy: 0.8000\n",
      "Epoch 302/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7936 - accuracy: 0.9688\n",
      "Epoch 302: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8000 - accuracy: 0.9694 - val_loss: 1.2868 - val_accuracy: 0.8800\n",
      "Epoch 303/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8413 - accuracy: 0.9479\n",
      "Epoch 303: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.8527 - accuracy: 0.9388 - val_loss: 1.3333 - val_accuracy: 0.8400\n",
      "Epoch 304/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7970 - accuracy: 0.9792\n",
      "Epoch 304: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7965 - accuracy: 0.9796 - val_loss: 1.3121 - val_accuracy: 0.8400\n",
      "Epoch 305/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7374 - accuracy: 0.9896\n",
      "Epoch 305: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7364 - accuracy: 0.9898 - val_loss: 1.2741 - val_accuracy: 0.8800\n",
      "Epoch 306/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7949 - accuracy: 0.9479\n",
      "Epoch 306: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7968 - accuracy: 0.9490 - val_loss: 1.2976 - val_accuracy: 0.9200\n",
      "Epoch 307/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7576 - accuracy: 0.9792\n",
      "Epoch 307: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7580 - accuracy: 0.9796 - val_loss: 1.3522 - val_accuracy: 0.8000\n",
      "Epoch 308/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.8313 - accuracy: 0.9592\n",
      "Epoch 308: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.8313 - accuracy: 0.9592 - val_loss: 1.2803 - val_accuracy: 0.8800\n",
      "Epoch 309/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7570 - accuracy: 0.9688\n",
      "Epoch 309: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7550 - accuracy: 0.9694 - val_loss: 1.2517 - val_accuracy: 0.8800\n",
      "Epoch 310/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7488 - accuracy: 0.9792\n",
      "Epoch 310: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7467 - accuracy: 0.9796 - val_loss: 1.2747 - val_accuracy: 0.8800\n",
      "Epoch 311/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7642 - accuracy: 0.9583\n",
      "Epoch 311: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7626 - accuracy: 0.9592 - val_loss: 1.2765 - val_accuracy: 0.8400\n",
      "Epoch 312/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7523 - accuracy: 0.9688\n",
      "Epoch 312: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7934 - accuracy: 0.9592 - val_loss: 1.2692 - val_accuracy: 0.8800\n",
      "Epoch 313/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7836 - accuracy: 0.9688\n",
      "Epoch 313: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7806 - accuracy: 0.9694 - val_loss: 1.2454 - val_accuracy: 0.8800\n",
      "Epoch 314/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7569 - accuracy: 0.9583\n",
      "Epoch 314: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7570 - accuracy: 0.9592 - val_loss: 1.2919 - val_accuracy: 0.8400\n",
      "Epoch 315/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7978 - accuracy: 0.9479\n",
      "Epoch 315: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7944 - accuracy: 0.9490 - val_loss: 1.2559 - val_accuracy: 0.8800\n",
      "Epoch 316/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7379 - accuracy: 0.9688\n",
      "Epoch 316: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7575 - accuracy: 0.9592 - val_loss: 1.2082 - val_accuracy: 0.8800\n",
      "Epoch 317/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7471 - accuracy: 0.9479\n",
      "Epoch 317: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7446 - accuracy: 0.9490 - val_loss: 1.2305 - val_accuracy: 0.8800\n",
      "Epoch 318/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.8021 - accuracy: 0.9375\n",
      "Epoch 318: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7999 - accuracy: 0.9388 - val_loss: 1.2835 - val_accuracy: 0.8800\n",
      "Epoch 319/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7935 - accuracy: 0.9583\n",
      "Epoch 319: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7906 - accuracy: 0.9592 - val_loss: 1.2897 - val_accuracy: 0.8400\n",
      "Epoch 320/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7572 - accuracy: 0.9583\n",
      "Epoch 320: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7548 - accuracy: 0.9592 - val_loss: 1.2749 - val_accuracy: 0.8400\n",
      "Epoch 321/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6985 - accuracy: 0.9592\n",
      "Epoch 321: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.6985 - accuracy: 0.9592 - val_loss: 1.2873 - val_accuracy: 0.7600\n",
      "Epoch 322/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7244 - accuracy: 0.9688\n",
      "Epoch 322: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7233 - accuracy: 0.9694 - val_loss: 1.2193 - val_accuracy: 0.8400\n",
      "Epoch 323/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7578 - accuracy: 0.9583\n",
      "Epoch 323: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7548 - accuracy: 0.9592 - val_loss: 1.2609 - val_accuracy: 0.8400\n",
      "Epoch 324/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7501 - accuracy: 0.9688\n",
      "Epoch 324: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7482 - accuracy: 0.9694 - val_loss: 1.2154 - val_accuracy: 0.8800\n",
      "Epoch 325/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7653 - accuracy: 0.9490\n",
      "Epoch 325: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.7653 - accuracy: 0.9490 - val_loss: 1.2157 - val_accuracy: 0.8800\n",
      "Epoch 326/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7504 - accuracy: 0.9583\n",
      "Epoch 326: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7490 - accuracy: 0.9592 - val_loss: 1.2239 - val_accuracy: 0.8800\n",
      "Epoch 327/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6789 - accuracy: 0.9792\n",
      "Epoch 327: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.6774 - accuracy: 0.9796 - val_loss: 1.2479 - val_accuracy: 0.8800\n",
      "Epoch 328/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7418 - accuracy: 0.9271\n",
      "Epoch 328: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7822 - accuracy: 0.9184 - val_loss: 1.3052 - val_accuracy: 0.8400\n",
      "Epoch 329/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6976 - accuracy: 0.9694\n",
      "Epoch 329: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.6976 - accuracy: 0.9694 - val_loss: 1.2737 - val_accuracy: 0.8400\n",
      "Epoch 330/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6954 - accuracy: 0.9688\n",
      "Epoch 330: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7138 - accuracy: 0.9592 - val_loss: 1.3314 - val_accuracy: 0.7200\n",
      "Epoch 331/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7513 - accuracy: 0.9583\n",
      "Epoch 331: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7556 - accuracy: 0.9592 - val_loss: 1.2940 - val_accuracy: 0.7200\n",
      "Epoch 332/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6865 - accuracy: 0.9792\n",
      "Epoch 332: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.6856 - accuracy: 0.9796 - val_loss: 1.2279 - val_accuracy: 0.7600\n",
      "Epoch 333/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7360 - accuracy: 0.9375\n",
      "Epoch 333: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7399 - accuracy: 0.9388 - val_loss: 1.2177 - val_accuracy: 0.8800\n",
      "Epoch 334/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7463 - accuracy: 0.9479\n",
      "Epoch 334: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7437 - accuracy: 0.9490 - val_loss: 1.2186 - val_accuracy: 0.8800\n",
      "Epoch 335/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6905 - accuracy: 0.9792\n",
      "Epoch 335: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.6884 - accuracy: 0.9796 - val_loss: 1.2090 - val_accuracy: 0.8800\n",
      "Epoch 336/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7270 - accuracy: 0.9583\n",
      "Epoch 336: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7244 - accuracy: 0.9592 - val_loss: 1.1983 - val_accuracy: 0.8800\n",
      "Epoch 337/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7108 - accuracy: 0.9271\n",
      "Epoch 337: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7122 - accuracy: 0.9286 - val_loss: 1.1564 - val_accuracy: 0.8800\n",
      "Epoch 338/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6912 - accuracy: 0.9583\n",
      "Epoch 338: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.7027 - accuracy: 0.9490 - val_loss: 1.1684 - val_accuracy: 0.8800\n",
      "Epoch 339/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6971 - accuracy: 0.9583\n",
      "Epoch 339: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6957 - accuracy: 0.9592 - val_loss: 1.2075 - val_accuracy: 0.8800\n",
      "Epoch 340/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7258 - accuracy: 0.9375\n",
      "Epoch 340: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7230 - accuracy: 0.9388 - val_loss: 1.2128 - val_accuracy: 0.8400\n",
      "Epoch 341/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6800 - accuracy: 0.9479\n",
      "Epoch 341: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.6779 - accuracy: 0.9490 - val_loss: 1.1988 - val_accuracy: 0.8800\n",
      "Epoch 342/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6387 - accuracy: 0.9896\n",
      "Epoch 342: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6377 - accuracy: 0.9898 - val_loss: 1.1940 - val_accuracy: 0.8400\n",
      "Epoch 343/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6560 - accuracy: 0.9688\n",
      "Epoch 343: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6609 - accuracy: 0.9694 - val_loss: 1.1999 - val_accuracy: 0.8800\n",
      "Epoch 344/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7040 - accuracy: 0.9688\n",
      "Epoch 344: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.7018 - accuracy: 0.9694 - val_loss: 1.1414 - val_accuracy: 0.8800\n",
      "Epoch 345/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7161 - accuracy: 0.9388\n",
      "Epoch 345: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.7161 - accuracy: 0.9388 - val_loss: 1.1602 - val_accuracy: 0.8800\n",
      "Epoch 346/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7315 - accuracy: 0.9375\n",
      "Epoch 346: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7287 - accuracy: 0.9388 - val_loss: 1.2158 - val_accuracy: 0.7600\n",
      "Epoch 347/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7284 - accuracy: 0.9167\n",
      "Epoch 347: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7448 - accuracy: 0.9082 - val_loss: 1.1963 - val_accuracy: 0.8800\n",
      "Epoch 348/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7095 - accuracy: 0.9375\n",
      "Epoch 348: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.7067 - accuracy: 0.9388 - val_loss: 1.1733 - val_accuracy: 0.8800\n",
      "Epoch 349/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6692 - accuracy: 0.9792\n",
      "Epoch 349: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.6677 - accuracy: 0.9796 - val_loss: 1.1536 - val_accuracy: 0.8800\n",
      "Epoch 350/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6640 - accuracy: 0.9688\n",
      "Epoch 350: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6619 - accuracy: 0.9694 - val_loss: 1.1921 - val_accuracy: 0.8400\n",
      "Epoch 351/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6647 - accuracy: 0.9688\n",
      "Epoch 351: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.6627 - accuracy: 0.9694 - val_loss: 1.1653 - val_accuracy: 0.8800\n",
      "Epoch 352/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6909 - accuracy: 0.9688\n",
      "Epoch 352: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.6882 - accuracy: 0.9694 - val_loss: 1.2047 - val_accuracy: 0.8000\n",
      "Epoch 353/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6233 - accuracy: 0.9792\n",
      "Epoch 353: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.6243 - accuracy: 0.9796 - val_loss: 1.1733 - val_accuracy: 0.8000\n",
      "Epoch 354/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6359 - accuracy: 0.9792\n",
      "Epoch 354: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.6387 - accuracy: 0.9796 - val_loss: 1.1512 - val_accuracy: 0.8800\n",
      "Epoch 355/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6380 - accuracy: 0.9792\n",
      "Epoch 355: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.6364 - accuracy: 0.9796 - val_loss: 1.1161 - val_accuracy: 0.8800\n",
      "Epoch 356/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6545 - accuracy: 0.9688\n",
      "Epoch 356: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.6554 - accuracy: 0.9694 - val_loss: 1.1771 - val_accuracy: 0.9200\n",
      "Epoch 357/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6842 - accuracy: 0.9583\n",
      "Epoch 357: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6816 - accuracy: 0.9592 - val_loss: 1.1115 - val_accuracy: 0.8800\n",
      "Epoch 358/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6474 - accuracy: 0.9688\n",
      "Epoch 358: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6487 - accuracy: 0.9694 - val_loss: 1.1947 - val_accuracy: 0.8800\n",
      "Epoch 359/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7342 - accuracy: 0.9271\n",
      "Epoch 359: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7302 - accuracy: 0.9286 - val_loss: 1.1507 - val_accuracy: 0.8400\n",
      "Epoch 360/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7393 - accuracy: 0.9479\n",
      "Epoch 360: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.7360 - accuracy: 0.9490 - val_loss: 1.1906 - val_accuracy: 0.8800\n",
      "Epoch 361/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5931 - accuracy: 0.9792\n",
      "Epoch 361: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5920 - accuracy: 0.9796 - val_loss: 1.1491 - val_accuracy: 0.8800\n",
      "Epoch 362/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6001 - accuracy: 0.9792\n",
      "Epoch 362: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5988 - accuracy: 0.9796 - val_loss: 1.1389 - val_accuracy: 0.8800\n",
      "Epoch 363/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6899 - accuracy: 0.9479\n",
      "Epoch 363: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.6875 - accuracy: 0.9490 - val_loss: 1.2117 - val_accuracy: 0.8800\n",
      "Epoch 364/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6779 - accuracy: 0.9479\n",
      "Epoch 364: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6749 - accuracy: 0.9490 - val_loss: 1.1871 - val_accuracy: 0.8000\n",
      "Epoch 365/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6191 - accuracy: 0.9688\n",
      "Epoch 365: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.6172 - accuracy: 0.9694 - val_loss: 1.1695 - val_accuracy: 0.8800\n",
      "Epoch 366/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6632 - accuracy: 0.9583\n",
      "Epoch 366: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6603 - accuracy: 0.9592 - val_loss: 1.1823 - val_accuracy: 0.8400\n",
      "Epoch 367/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6242 - accuracy: 0.9896\n",
      "Epoch 367: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.6223 - accuracy: 0.9898 - val_loss: 1.1528 - val_accuracy: 0.8400\n",
      "Epoch 368/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.7038 - accuracy: 0.9388\n",
      "Epoch 368: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.7038 - accuracy: 0.9388 - val_loss: 1.1308 - val_accuracy: 0.8800\n",
      "Epoch 369/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6313 - accuracy: 0.9688\n",
      "Epoch 369: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6292 - accuracy: 0.9694 - val_loss: 1.1096 - val_accuracy: 0.9200\n",
      "Epoch 370/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6317 - accuracy: 0.9583\n",
      "Epoch 370: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6319 - accuracy: 0.9592 - val_loss: 1.2192 - val_accuracy: 0.7600\n",
      "Epoch 371/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5910 - accuracy: 0.9688\n",
      "Epoch 371: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5910 - accuracy: 0.9694 - val_loss: 1.2424 - val_accuracy: 0.7600\n",
      "Epoch 372/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6233 - accuracy: 0.9583\n",
      "Epoch 372: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6211 - accuracy: 0.9592 - val_loss: 1.1494 - val_accuracy: 0.8800\n",
      "Epoch 373/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5755 - accuracy: 0.9792\n",
      "Epoch 373: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5742 - accuracy: 0.9796 - val_loss: 1.1490 - val_accuracy: 0.8800\n",
      "Epoch 374/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5930 - accuracy: 0.9792\n",
      "Epoch 374: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5913 - accuracy: 0.9796 - val_loss: 1.1310 - val_accuracy: 0.8000\n",
      "Epoch 375/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5990 - accuracy: 0.9792\n",
      "Epoch 375: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6119 - accuracy: 0.9694 - val_loss: 1.0881 - val_accuracy: 0.8800\n",
      "Epoch 376/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6301 - accuracy: 0.9792\n",
      "Epoch 376: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6280 - accuracy: 0.9796 - val_loss: 1.1504 - val_accuracy: 0.9200\n",
      "Epoch 377/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5787 - accuracy: 1.0000\n",
      "Epoch 377: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5802 - accuracy: 1.0000 - val_loss: 1.2281 - val_accuracy: 0.8000\n",
      "Epoch 378/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6203 - accuracy: 0.9688\n",
      "Epoch 378: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6182 - accuracy: 0.9694 - val_loss: 1.1625 - val_accuracy: 0.8000\n",
      "Epoch 379/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6489 - accuracy: 0.9490\n",
      "Epoch 379: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.6489 - accuracy: 0.9490 - val_loss: 1.1157 - val_accuracy: 0.8400\n",
      "Epoch 380/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5784 - accuracy: 0.9792\n",
      "Epoch 380: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5800 - accuracy: 0.9796 - val_loss: 1.0724 - val_accuracy: 0.9200\n",
      "Epoch 381/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6261 - accuracy: 0.9479\n",
      "Epoch 381: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.6249 - accuracy: 0.9490 - val_loss: 1.0910 - val_accuracy: 0.8800\n",
      "Epoch 382/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5941 - accuracy: 0.9479\n",
      "Epoch 382: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5921 - accuracy: 0.9490 - val_loss: 1.1113 - val_accuracy: 0.8400\n",
      "Epoch 383/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5638 - accuracy: 0.9896\n",
      "Epoch 383: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5663 - accuracy: 0.9898 - val_loss: 1.1967 - val_accuracy: 0.8000\n",
      "Epoch 384/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.7107 - accuracy: 0.9062\n",
      "Epoch 384: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.7065 - accuracy: 0.9082 - val_loss: 1.1168 - val_accuracy: 0.8400\n",
      "Epoch 385/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5589 - accuracy: 0.9896\n",
      "Epoch 385: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5594 - accuracy: 0.9898 - val_loss: 1.1151 - val_accuracy: 0.8400\n",
      "Epoch 386/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5468 - accuracy: 0.9896\n",
      "Epoch 386: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5457 - accuracy: 0.9898 - val_loss: 1.0855 - val_accuracy: 0.8800\n",
      "Epoch 387/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5905 - accuracy: 0.9583\n",
      "Epoch 387: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5884 - accuracy: 0.9592 - val_loss: 1.1027 - val_accuracy: 0.8800\n",
      "Epoch 388/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6863 - accuracy: 0.9375\n",
      "Epoch 388: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.6821 - accuracy: 0.9388 - val_loss: 1.1389 - val_accuracy: 0.8000\n",
      "Epoch 389/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5703 - accuracy: 0.9792\n",
      "Epoch 389: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5686 - accuracy: 0.9796 - val_loss: 1.1077 - val_accuracy: 0.8400\n",
      "Epoch 390/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5932 - accuracy: 0.9796\n",
      "Epoch 390: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.5932 - accuracy: 0.9796 - val_loss: 1.1426 - val_accuracy: 0.7600\n",
      "Epoch 391/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6559 - accuracy: 0.9375\n",
      "Epoch 391: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6827 - accuracy: 0.9286 - val_loss: 1.0491 - val_accuracy: 0.8800\n",
      "Epoch 392/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6371 - accuracy: 0.9490\n",
      "Epoch 392: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.6371 - accuracy: 0.9490 - val_loss: 1.0874 - val_accuracy: 0.9200\n",
      "Epoch 393/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5283 - accuracy: 0.9896\n",
      "Epoch 393: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5273 - accuracy: 0.9898 - val_loss: 1.0680 - val_accuracy: 0.9200\n",
      "Epoch 394/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5694 - accuracy: 0.9792\n",
      "Epoch 394: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5908 - accuracy: 0.9694 - val_loss: 1.1317 - val_accuracy: 0.8000\n",
      "Epoch 395/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6416 - accuracy: 0.9479\n",
      "Epoch 395: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.6382 - accuracy: 0.9490 - val_loss: 1.0807 - val_accuracy: 0.8400\n",
      "Epoch 396/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6236 - accuracy: 0.9167\n",
      "Epoch 396: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.6222 - accuracy: 0.9184 - val_loss: 1.0081 - val_accuracy: 0.8800\n",
      "Epoch 397/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6590 - accuracy: 0.9375\n",
      "Epoch 397: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.6552 - accuracy: 0.9388 - val_loss: 1.0239 - val_accuracy: 0.9200\n",
      "Epoch 398/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5891 - accuracy: 0.9792\n",
      "Epoch 398: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5867 - accuracy: 0.9796 - val_loss: 1.0533 - val_accuracy: 0.9200\n",
      "Epoch 399/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5118 - accuracy: 0.9792\n",
      "Epoch 399: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.5109 - accuracy: 0.9796 - val_loss: 1.0594 - val_accuracy: 0.9200\n",
      "Epoch 400/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5164 - accuracy: 0.9896\n",
      "Epoch 400: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5154 - accuracy: 0.9898 - val_loss: 1.0751 - val_accuracy: 0.8400\n",
      "Epoch 401/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5758 - accuracy: 0.9479\n",
      "Epoch 401: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5744 - accuracy: 0.9490 - val_loss: 1.1176 - val_accuracy: 0.8000\n",
      "Epoch 402/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6086 - accuracy: 0.9375\n",
      "Epoch 402: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.6056 - accuracy: 0.9388 - val_loss: 1.0475 - val_accuracy: 0.8800\n",
      "Epoch 403/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5307 - accuracy: 0.9896\n",
      "Epoch 403: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.5293 - accuracy: 0.9898 - val_loss: 1.0957 - val_accuracy: 0.8000\n",
      "Epoch 404/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5609 - accuracy: 0.9688\n",
      "Epoch 404: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5593 - accuracy: 0.9694 - val_loss: 1.0813 - val_accuracy: 0.9200\n",
      "Epoch 405/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5090 - accuracy: 0.9896\n",
      "Epoch 405: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5081 - accuracy: 0.9898 - val_loss: 1.0473 - val_accuracy: 0.9200\n",
      "Epoch 406/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5664 - accuracy: 0.9688\n",
      "Epoch 406: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5788 - accuracy: 0.9592 - val_loss: 1.1062 - val_accuracy: 0.8800\n",
      "Epoch 407/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.6329 - accuracy: 0.9375\n",
      "Epoch 407: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.6325 - accuracy: 0.9388 - val_loss: 1.0442 - val_accuracy: 0.8800\n",
      "Epoch 408/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4824 - accuracy: 1.0000\n",
      "Epoch 408: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4828 - accuracy: 1.0000 - val_loss: 1.0470 - val_accuracy: 0.8800\n",
      "Epoch 409/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5367 - accuracy: 0.9792\n",
      "Epoch 409: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.5349 - accuracy: 0.9796 - val_loss: 1.0107 - val_accuracy: 0.8800\n",
      "Epoch 410/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5287 - accuracy: 0.9792\n",
      "Epoch 410: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5286 - accuracy: 0.9796 - val_loss: 1.0446 - val_accuracy: 0.9200\n",
      "Epoch 411/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5901 - accuracy: 0.9479\n",
      "Epoch 411: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5871 - accuracy: 0.9490 - val_loss: 1.0913 - val_accuracy: 0.8000\n",
      "Epoch 412/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5332 - accuracy: 0.9792\n",
      "Epoch 412: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5364 - accuracy: 0.9796 - val_loss: 1.1801 - val_accuracy: 0.7600\n",
      "Epoch 413/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5091 - accuracy: 0.9896\n",
      "Epoch 413: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5081 - accuracy: 0.9898 - val_loss: 1.1408 - val_accuracy: 0.8000\n",
      "Epoch 414/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5155 - accuracy: 0.9796\n",
      "Epoch 414: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.5155 - accuracy: 0.9796 - val_loss: 1.1389 - val_accuracy: 0.7600\n",
      "Epoch 415/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5228 - accuracy: 0.9688\n",
      "Epoch 415: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5573 - accuracy: 0.9592 - val_loss: 1.0650 - val_accuracy: 0.8000\n",
      "Epoch 416/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5314 - accuracy: 0.9688\n",
      "Epoch 416: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5324 - accuracy: 0.9694 - val_loss: 1.0471 - val_accuracy: 0.8000\n",
      "Epoch 417/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.6002 - accuracy: 0.9388\n",
      "Epoch 417: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.6002 - accuracy: 0.9388 - val_loss: 1.0824 - val_accuracy: 0.7600\n",
      "Epoch 418/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5280 - accuracy: 0.9896\n",
      "Epoch 418: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5262 - accuracy: 0.9898 - val_loss: 1.0540 - val_accuracy: 0.8400\n",
      "Epoch 419/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5333 - accuracy: 0.9896\n",
      "Epoch 419: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5313 - accuracy: 0.9898 - val_loss: 1.0733 - val_accuracy: 0.8000\n",
      "Epoch 420/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5403 - accuracy: 0.9694\n",
      "Epoch 420: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.5403 - accuracy: 0.9694 - val_loss: 1.1595 - val_accuracy: 0.8000\n",
      "Epoch 421/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5430 - accuracy: 0.9583\n",
      "Epoch 421: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.5407 - accuracy: 0.9592 - val_loss: 1.0849 - val_accuracy: 0.8000\n",
      "Epoch 422/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5338 - accuracy: 0.9583\n",
      "Epoch 422: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5317 - accuracy: 0.9592 - val_loss: 1.0650 - val_accuracy: 0.8800\n",
      "Epoch 423/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5182 - accuracy: 0.9796\n",
      "Epoch 423: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.5182 - accuracy: 0.9796 - val_loss: 1.0595 - val_accuracy: 0.8000\n",
      "Epoch 424/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5312 - accuracy: 0.9688\n",
      "Epoch 424: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5291 - accuracy: 0.9694 - val_loss: 1.0041 - val_accuracy: 0.8800\n",
      "Epoch 425/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5636 - accuracy: 0.9583\n",
      "Epoch 425: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5633 - accuracy: 0.9592 - val_loss: 1.0118 - val_accuracy: 0.9200\n",
      "Epoch 426/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5707 - accuracy: 0.9490\n",
      "Epoch 426: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.5707 - accuracy: 0.9490 - val_loss: 0.9869 - val_accuracy: 0.9200\n",
      "Epoch 427/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4803 - accuracy: 0.9792\n",
      "Epoch 427: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4791 - accuracy: 0.9796 - val_loss: 0.9948 - val_accuracy: 0.9200\n",
      "Epoch 428/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5197 - accuracy: 0.9792\n",
      "Epoch 428: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5190 - accuracy: 0.9796 - val_loss: 0.9805 - val_accuracy: 0.8800\n",
      "Epoch 429/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5118 - accuracy: 0.9694\n",
      "Epoch 429: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.5118 - accuracy: 0.9694 - val_loss: 0.9815 - val_accuracy: 0.9200\n",
      "Epoch 430/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4963 - accuracy: 0.9896\n",
      "Epoch 430: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4957 - accuracy: 0.9898 - val_loss: 0.9802 - val_accuracy: 0.9200\n",
      "Epoch 431/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5379 - accuracy: 0.9479\n",
      "Epoch 431: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5356 - accuracy: 0.9490 - val_loss: 0.9912 - val_accuracy: 0.9200\n",
      "Epoch 432/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5678 - accuracy: 0.9592\n",
      "Epoch 432: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.5678 - accuracy: 0.9592 - val_loss: 1.0416 - val_accuracy: 0.8400\n",
      "Epoch 433/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4802 - accuracy: 0.9688\n",
      "Epoch 433: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.4792 - accuracy: 0.9694 - val_loss: 1.0125 - val_accuracy: 0.9200\n",
      "Epoch 434/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5445 - accuracy: 0.9375\n",
      "Epoch 434: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.5419 - accuracy: 0.9388 - val_loss: 0.9806 - val_accuracy: 0.9200\n",
      "Epoch 435/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.5013 - accuracy: 0.9694\n",
      "Epoch 435: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.5013 - accuracy: 0.9694 - val_loss: 1.0049 - val_accuracy: 0.9200\n",
      "Epoch 436/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5262 - accuracy: 0.9688\n",
      "Epoch 436: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5252 - accuracy: 0.9694 - val_loss: 0.9884 - val_accuracy: 0.9200\n",
      "Epoch 437/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5490 - accuracy: 0.9375\n",
      "Epoch 437: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5462 - accuracy: 0.9388 - val_loss: 0.9814 - val_accuracy: 0.8800\n",
      "Epoch 438/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4858 - accuracy: 0.9592\n",
      "Epoch 438: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.4858 - accuracy: 0.9592 - val_loss: 1.0208 - val_accuracy: 0.8400\n",
      "Epoch 439/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4918 - accuracy: 0.9688\n",
      "Epoch 439: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4925 - accuracy: 0.9694 - val_loss: 0.9540 - val_accuracy: 0.9200\n",
      "Epoch 440/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5024 - accuracy: 0.9583\n",
      "Epoch 440: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.5004 - accuracy: 0.9592 - val_loss: 0.9835 - val_accuracy: 0.9200\n",
      "Epoch 441/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4593 - accuracy: 0.9796\n",
      "Epoch 441: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.4593 - accuracy: 0.9796 - val_loss: 1.0567 - val_accuracy: 0.8000\n",
      "Epoch 442/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4473 - accuracy: 1.0000\n",
      "Epoch 442: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4465 - accuracy: 1.0000 - val_loss: 1.0660 - val_accuracy: 0.7600\n",
      "Epoch 443/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4670 - accuracy: 0.9896\n",
      "Epoch 443: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4658 - accuracy: 0.9898 - val_loss: 1.0314 - val_accuracy: 0.7600\n",
      "Epoch 444/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4601 - accuracy: 0.9688\n",
      "Epoch 444: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4589 - accuracy: 0.9694 - val_loss: 1.0384 - val_accuracy: 0.9200\n",
      "Epoch 445/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4845 - accuracy: 0.9688\n",
      "Epoch 445: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4840 - accuracy: 0.9694 - val_loss: 1.0494 - val_accuracy: 0.8000\n",
      "Epoch 446/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4975 - accuracy: 0.9479\n",
      "Epoch 446: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5018 - accuracy: 0.9490 - val_loss: 1.0426 - val_accuracy: 0.8800\n",
      "Epoch 447/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4949 - accuracy: 0.9583\n",
      "Epoch 447: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4939 - accuracy: 0.9592 - val_loss: 1.0375 - val_accuracy: 0.8800\n",
      "Epoch 448/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4741 - accuracy: 0.9792\n",
      "Epoch 448: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.4726 - accuracy: 0.9796 - val_loss: 1.0157 - val_accuracy: 0.8800\n",
      "Epoch 449/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4574 - accuracy: 0.9896\n",
      "Epoch 449: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4574 - accuracy: 0.9898 - val_loss: 0.9732 - val_accuracy: 0.9200\n",
      "Epoch 450/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5198 - accuracy: 0.9583\n",
      "Epoch 450: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.5172 - accuracy: 0.9592 - val_loss: 1.0056 - val_accuracy: 0.8400\n",
      "Epoch 451/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5113 - accuracy: 0.9375\n",
      "Epoch 451: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5089 - accuracy: 0.9388 - val_loss: 0.9731 - val_accuracy: 0.9200\n",
      "Epoch 452/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4696 - accuracy: 0.9792\n",
      "Epoch 452: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4703 - accuracy: 0.9796 - val_loss: 0.9501 - val_accuracy: 0.9200\n",
      "Epoch 453/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4389 - accuracy: 0.9896\n",
      "Epoch 453: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4380 - accuracy: 0.9898 - val_loss: 0.9720 - val_accuracy: 0.8800\n",
      "Epoch 454/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4272 - accuracy: 0.9896\n",
      "Epoch 454: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4266 - accuracy: 0.9898 - val_loss: 1.0301 - val_accuracy: 0.7600\n",
      "Epoch 455/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4239 - accuracy: 0.9896\n",
      "Epoch 455: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4284 - accuracy: 0.9898 - val_loss: 1.0386 - val_accuracy: 0.8000\n",
      "Epoch 456/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4715 - accuracy: 0.9688\n",
      "Epoch 456: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.4712 - accuracy: 0.9694 - val_loss: 1.0166 - val_accuracy: 0.7600\n",
      "Epoch 457/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4761 - accuracy: 0.9792\n",
      "Epoch 457: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4746 - accuracy: 0.9796 - val_loss: 0.9430 - val_accuracy: 0.8800\n",
      "Epoch 458/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4354 - accuracy: 1.0000\n",
      "Epoch 458: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4348 - accuracy: 1.0000 - val_loss: 0.9771 - val_accuracy: 0.8000\n",
      "Epoch 459/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4477 - accuracy: 0.9896\n",
      "Epoch 459: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4481 - accuracy: 0.9898 - val_loss: 0.9546 - val_accuracy: 0.9200\n",
      "Epoch 460/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5604 - accuracy: 0.9479\n",
      "Epoch 460: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5702 - accuracy: 0.9388 - val_loss: 0.9319 - val_accuracy: 0.8800\n",
      "Epoch 461/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4511 - accuracy: 0.9896\n",
      "Epoch 461: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4496 - accuracy: 0.9898 - val_loss: 0.9366 - val_accuracy: 0.8800\n",
      "Epoch 462/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4187 - accuracy: 0.9896\n",
      "Epoch 462: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4178 - accuracy: 0.9898 - val_loss: 0.9260 - val_accuracy: 0.8800\n",
      "Epoch 463/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4380 - accuracy: 0.9792\n",
      "Epoch 463: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4368 - accuracy: 0.9796 - val_loss: 0.9357 - val_accuracy: 0.8800\n",
      "Epoch 464/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4542 - accuracy: 0.9792\n",
      "Epoch 464: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4526 - accuracy: 0.9796 - val_loss: 0.9239 - val_accuracy: 0.8800\n",
      "Epoch 465/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4268 - accuracy: 0.9896\n",
      "Epoch 465: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4257 - accuracy: 0.9898 - val_loss: 0.9657 - val_accuracy: 0.8800\n",
      "Epoch 466/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4122 - accuracy: 0.9898\n",
      "Epoch 466: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.4122 - accuracy: 0.9898 - val_loss: 0.9952 - val_accuracy: 0.8400\n",
      "Epoch 467/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5021 - accuracy: 0.9375\n",
      "Epoch 467: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4993 - accuracy: 0.9388 - val_loss: 1.0264 - val_accuracy: 0.8000\n",
      "Epoch 468/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4380 - accuracy: 0.9792\n",
      "Epoch 468: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4368 - accuracy: 0.9796 - val_loss: 1.0105 - val_accuracy: 0.8000\n",
      "Epoch 469/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4838 - accuracy: 0.9688\n",
      "Epoch 469: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4818 - accuracy: 0.9694 - val_loss: 0.9258 - val_accuracy: 0.8800\n",
      "Epoch 470/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4707 - accuracy: 0.9583\n",
      "Epoch 470: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4688 - accuracy: 0.9592 - val_loss: 0.9824 - val_accuracy: 0.8400\n",
      "Epoch 471/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4744 - accuracy: 0.9479\n",
      "Epoch 471: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4783 - accuracy: 0.9490 - val_loss: 0.8969 - val_accuracy: 0.9200\n",
      "Epoch 472/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4725 - accuracy: 0.9792\n",
      "Epoch 472: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4720 - accuracy: 0.9796 - val_loss: 0.9790 - val_accuracy: 0.8800\n",
      "Epoch 473/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4389 - accuracy: 0.9896\n",
      "Epoch 473: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4375 - accuracy: 0.9898 - val_loss: 0.9373 - val_accuracy: 0.8800\n",
      "Epoch 474/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4586 - accuracy: 0.9792\n",
      "Epoch 474: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4688 - accuracy: 0.9694 - val_loss: 0.9578 - val_accuracy: 0.8800\n",
      "Epoch 475/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4298 - accuracy: 0.9796\n",
      "Epoch 475: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.4298 - accuracy: 0.9796 - val_loss: 0.9511 - val_accuracy: 0.8400\n",
      "Epoch 476/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4486 - accuracy: 0.9583\n",
      "Epoch 476: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4467 - accuracy: 0.9592 - val_loss: 0.9422 - val_accuracy: 0.8400\n",
      "Epoch 477/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4503 - accuracy: 0.9688\n",
      "Epoch 477: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4484 - accuracy: 0.9694 - val_loss: 0.9258 - val_accuracy: 0.8800\n",
      "Epoch 478/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4702 - accuracy: 0.9479\n",
      "Epoch 478: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4682 - accuracy: 0.9490 - val_loss: 0.9870 - val_accuracy: 0.8000\n",
      "Epoch 479/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4328 - accuracy: 0.9583\n",
      "Epoch 479: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4313 - accuracy: 0.9592 - val_loss: 0.9523 - val_accuracy: 0.8400\n",
      "Epoch 480/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4582 - accuracy: 0.9479\n",
      "Epoch 480: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4565 - accuracy: 0.9490 - val_loss: 0.9977 - val_accuracy: 0.8000\n",
      "Epoch 481/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4999 - accuracy: 0.9375\n",
      "Epoch 481: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5005 - accuracy: 0.9388 - val_loss: 1.0238 - val_accuracy: 0.7600\n",
      "Epoch 482/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4860 - accuracy: 0.9688\n",
      "Epoch 482: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4850 - accuracy: 0.9694 - val_loss: 0.9492 - val_accuracy: 0.8000\n",
      "Epoch 483/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4469 - accuracy: 0.9792\n",
      "Epoch 483: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4456 - accuracy: 0.9796 - val_loss: 1.0066 - val_accuracy: 0.7600\n",
      "Epoch 484/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3925 - accuracy: 0.9896\n",
      "Epoch 484: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.3917 - accuracy: 0.9898 - val_loss: 0.9687 - val_accuracy: 0.7600\n",
      "Epoch 485/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4349 - accuracy: 0.9792\n",
      "Epoch 485: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4464 - accuracy: 0.9694 - val_loss: 1.1031 - val_accuracy: 0.8000\n",
      "Epoch 486/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4057 - accuracy: 0.9896\n",
      "Epoch 486: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4046 - accuracy: 0.9898 - val_loss: 1.0388 - val_accuracy: 0.8000\n",
      "Epoch 487/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4160 - accuracy: 0.9896\n",
      "Epoch 487: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4147 - accuracy: 0.9898 - val_loss: 0.9877 - val_accuracy: 0.8400\n",
      "Epoch 488/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4055 - accuracy: 0.9792\n",
      "Epoch 488: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4117 - accuracy: 0.9796 - val_loss: 1.0038 - val_accuracy: 0.8000\n",
      "Epoch 489/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3991 - accuracy: 0.9896\n",
      "Epoch 489: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3981 - accuracy: 0.9898 - val_loss: 0.9594 - val_accuracy: 0.8400\n",
      "Epoch 490/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4244 - accuracy: 0.9792\n",
      "Epoch 490: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.4228 - accuracy: 0.9796 - val_loss: 0.9476 - val_accuracy: 0.9200\n",
      "Epoch 491/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4005 - accuracy: 0.9694\n",
      "Epoch 491: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.4005 - accuracy: 0.9694 - val_loss: 0.9993 - val_accuracy: 0.8400\n",
      "Epoch 492/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4023 - accuracy: 0.9792\n",
      "Epoch 492: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4011 - accuracy: 0.9796 - val_loss: 0.9711 - val_accuracy: 0.8000\n",
      "Epoch 493/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4109 - accuracy: 0.9688\n",
      "Epoch 493: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.4095 - accuracy: 0.9694 - val_loss: 0.9286 - val_accuracy: 0.8400\n",
      "Epoch 494/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4543 - accuracy: 0.9688\n",
      "Epoch 494: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4539 - accuracy: 0.9694 - val_loss: 0.9175 - val_accuracy: 0.8400\n",
      "Epoch 495/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4213 - accuracy: 0.9792\n",
      "Epoch 495: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.4197 - accuracy: 0.9796 - val_loss: 0.9450 - val_accuracy: 0.8000\n",
      "Epoch 496/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3820 - accuracy: 1.0000\n",
      "Epoch 496: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.3811 - accuracy: 1.0000 - val_loss: 0.9228 - val_accuracy: 0.8400\n",
      "Epoch 497/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3924 - accuracy: 0.9792\n",
      "Epoch 497: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.4072 - accuracy: 0.9694 - val_loss: 0.8869 - val_accuracy: 0.9200\n",
      "Epoch 498/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3819 - accuracy: 0.9792\n",
      "Epoch 498: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3811 - accuracy: 0.9796 - val_loss: 0.8859 - val_accuracy: 0.9200\n",
      "Epoch 499/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4162 - accuracy: 0.9792\n",
      "Epoch 499: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4146 - accuracy: 0.9796 - val_loss: 0.9235 - val_accuracy: 0.8400\n",
      "Epoch 500/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3673 - accuracy: 0.9896\n",
      "Epoch 500: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3808 - accuracy: 0.9796 - val_loss: 0.9780 - val_accuracy: 0.7600\n",
      "Epoch 501/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3859 - accuracy: 0.9792\n",
      "Epoch 501: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3849 - accuracy: 0.9796 - val_loss: 0.9559 - val_accuracy: 0.8000\n",
      "Epoch 502/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3766 - accuracy: 1.0000\n",
      "Epoch 502: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3757 - accuracy: 1.0000 - val_loss: 0.9761 - val_accuracy: 0.8000\n",
      "Epoch 503/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3794 - accuracy: 0.9792\n",
      "Epoch 503: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3787 - accuracy: 0.9796 - val_loss: 0.9773 - val_accuracy: 0.7600\n",
      "Epoch 504/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3907 - accuracy: 0.9792\n",
      "Epoch 504: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3898 - accuracy: 0.9796 - val_loss: 0.9484 - val_accuracy: 0.8800\n",
      "Epoch 505/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3827 - accuracy: 0.9792\n",
      "Epoch 505: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3817 - accuracy: 0.9796 - val_loss: 0.9045 - val_accuracy: 0.8800\n",
      "Epoch 506/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3834 - accuracy: 0.9792\n",
      "Epoch 506: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3822 - accuracy: 0.9796 - val_loss: 0.9127 - val_accuracy: 0.7600\n",
      "Epoch 507/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4333 - accuracy: 0.9583\n",
      "Epoch 507: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4311 - accuracy: 0.9592 - val_loss: 0.8995 - val_accuracy: 0.8800\n",
      "Epoch 508/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3653 - accuracy: 0.9896\n",
      "Epoch 508: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.3649 - accuracy: 0.9898 - val_loss: 0.9330 - val_accuracy: 0.8000\n",
      "Epoch 509/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4003 - accuracy: 0.9583\n",
      "Epoch 509: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3988 - accuracy: 0.9592 - val_loss: 0.8763 - val_accuracy: 0.8800\n",
      "Epoch 510/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4226 - accuracy: 0.9688\n",
      "Epoch 510: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4240 - accuracy: 0.9694 - val_loss: 0.8774 - val_accuracy: 0.8800\n",
      "Epoch 511/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.5364 - accuracy: 0.9583\n",
      "Epoch 511: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.5319 - accuracy: 0.9592 - val_loss: 0.8792 - val_accuracy: 0.9200\n",
      "Epoch 512/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3778 - accuracy: 0.9896\n",
      "Epoch 512: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3766 - accuracy: 0.9898 - val_loss: 0.8593 - val_accuracy: 0.8800\n",
      "Epoch 513/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4033 - accuracy: 0.9583\n",
      "Epoch 513: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4017 - accuracy: 0.9592 - val_loss: 0.9320 - val_accuracy: 0.7600\n",
      "Epoch 514/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4904 - accuracy: 0.9271\n",
      "Epoch 514: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.5162 - accuracy: 0.9184 - val_loss: 0.9319 - val_accuracy: 0.9200\n",
      "Epoch 515/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3707 - accuracy: 0.9792\n",
      "Epoch 515: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3706 - accuracy: 0.9796 - val_loss: 0.9367 - val_accuracy: 0.9200\n",
      "Epoch 516/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3561 - accuracy: 1.0000\n",
      "Epoch 516: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.3561 - accuracy: 1.0000 - val_loss: 0.9135 - val_accuracy: 0.9200\n",
      "Epoch 517/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4026 - accuracy: 0.9688\n",
      "Epoch 517: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4008 - accuracy: 0.9694 - val_loss: 0.9522 - val_accuracy: 0.8000\n",
      "Epoch 518/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3391 - accuracy: 1.0000\n",
      "Epoch 518: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3386 - accuracy: 1.0000 - val_loss: 0.9353 - val_accuracy: 0.8000\n",
      "Epoch 519/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3862 - accuracy: 0.9792\n",
      "Epoch 519: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3857 - accuracy: 0.9796 - val_loss: 0.8870 - val_accuracy: 0.9200\n",
      "Epoch 520/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3400 - accuracy: 1.0000\n",
      "Epoch 520: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3421 - accuracy: 1.0000 - val_loss: 0.8763 - val_accuracy: 0.9200\n",
      "Epoch 521/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4487 - accuracy: 0.9479\n",
      "Epoch 521: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.4459 - accuracy: 0.9490 - val_loss: 0.9178 - val_accuracy: 0.8000\n",
      "Epoch 522/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3886 - accuracy: 0.9792\n",
      "Epoch 522: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3873 - accuracy: 0.9796 - val_loss: 0.9424 - val_accuracy: 0.8000\n",
      "Epoch 523/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3432 - accuracy: 1.0000\n",
      "Epoch 523: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3439 - accuracy: 1.0000 - val_loss: 0.9429 - val_accuracy: 0.8000\n",
      "Epoch 524/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3701 - accuracy: 0.9792\n",
      "Epoch 524: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3690 - accuracy: 0.9796 - val_loss: 0.9524 - val_accuracy: 0.8000\n",
      "Epoch 525/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4148 - accuracy: 0.9479\n",
      "Epoch 525: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.4132 - accuracy: 0.9490 - val_loss: 0.9527 - val_accuracy: 0.8000\n",
      "Epoch 526/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3732 - accuracy: 0.9792\n",
      "Epoch 526: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3719 - accuracy: 0.9796 - val_loss: 0.9594 - val_accuracy: 0.8000\n",
      "Epoch 527/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3949 - accuracy: 0.9688\n",
      "Epoch 527: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3935 - accuracy: 0.9694 - val_loss: 0.9133 - val_accuracy: 0.8000\n",
      "Epoch 528/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3538 - accuracy: 1.0000\n",
      "Epoch 528: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.3538 - accuracy: 1.0000 - val_loss: 0.8774 - val_accuracy: 0.8000\n",
      "Epoch 529/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3771 - accuracy: 0.9688\n",
      "Epoch 529: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3757 - accuracy: 0.9694 - val_loss: 0.8507 - val_accuracy: 0.9200\n",
      "Epoch 530/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3571 - accuracy: 0.9896\n",
      "Epoch 530: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3563 - accuracy: 0.9898 - val_loss: 0.9061 - val_accuracy: 0.8000\n",
      "Epoch 531/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4805 - accuracy: 0.9167\n",
      "Epoch 531: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.4769 - accuracy: 0.9184 - val_loss: 0.9448 - val_accuracy: 0.8000\n",
      "Epoch 532/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3698 - accuracy: 0.9796\n",
      "Epoch 532: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.3698 - accuracy: 0.9796 - val_loss: 0.9405 - val_accuracy: 0.8000\n",
      "Epoch 533/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3780 - accuracy: 0.9688\n",
      "Epoch 533: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3848 - accuracy: 0.9592 - val_loss: 1.0184 - val_accuracy: 0.8000\n",
      "Epoch 534/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.4482 - accuracy: 0.9592\n",
      "Epoch 534: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.4482 - accuracy: 0.9592 - val_loss: 0.9642 - val_accuracy: 0.8000\n",
      "Epoch 535/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3470 - accuracy: 1.0000\n",
      "Epoch 535: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3470 - accuracy: 1.0000 - val_loss: 0.9454 - val_accuracy: 0.8000\n",
      "Epoch 536/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4026 - accuracy: 0.9688\n",
      "Epoch 536: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4005 - accuracy: 0.9694 - val_loss: 0.8897 - val_accuracy: 0.8000\n",
      "Epoch 537/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3760 - accuracy: 0.9688\n",
      "Epoch 537: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3753 - accuracy: 0.9694 - val_loss: 0.9544 - val_accuracy: 0.8000\n",
      "Epoch 538/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3432 - accuracy: 0.9792\n",
      "Epoch 538: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3422 - accuracy: 0.9796 - val_loss: 0.9106 - val_accuracy: 0.8000\n",
      "Epoch 539/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3309 - accuracy: 0.9896\n",
      "Epoch 539: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.3302 - accuracy: 0.9898 - val_loss: 0.8847 - val_accuracy: 0.8000\n",
      "Epoch 540/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3307 - accuracy: 1.0000\n",
      "Epoch 540: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3300 - accuracy: 1.0000 - val_loss: 0.8660 - val_accuracy: 0.8400\n",
      "Epoch 541/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3465 - accuracy: 0.9792\n",
      "Epoch 541: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3468 - accuracy: 0.9796 - val_loss: 0.8940 - val_accuracy: 0.8000\n",
      "Epoch 542/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3814 - accuracy: 0.9796\n",
      "Epoch 542: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.3814 - accuracy: 0.9796 - val_loss: 0.8109 - val_accuracy: 0.8000\n",
      "Epoch 543/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3354 - accuracy: 1.0000\n",
      "Epoch 543: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3361 - accuracy: 1.0000 - val_loss: 0.8621 - val_accuracy: 0.8000\n",
      "Epoch 544/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3469 - accuracy: 0.9896\n",
      "Epoch 544: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3460 - accuracy: 0.9898 - val_loss: 0.8722 - val_accuracy: 0.8000\n",
      "Epoch 545/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3196 - accuracy: 0.9896\n",
      "Epoch 545: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3190 - accuracy: 0.9898 - val_loss: 0.8547 - val_accuracy: 0.8000\n",
      "Epoch 546/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3632 - accuracy: 0.9583\n",
      "Epoch 546: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3617 - accuracy: 0.9592 - val_loss: 0.8594 - val_accuracy: 0.8800\n",
      "Epoch 547/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3759 - accuracy: 0.9688\n",
      "Epoch 547: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.3741 - accuracy: 0.9694 - val_loss: 0.9043 - val_accuracy: 0.8000\n",
      "Epoch 548/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3409 - accuracy: 0.9792\n",
      "Epoch 548: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3398 - accuracy: 0.9796 - val_loss: 0.8958 - val_accuracy: 0.8000\n",
      "Epoch 549/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3539 - accuracy: 0.9792\n",
      "Epoch 549: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3526 - accuracy: 0.9796 - val_loss: 0.8304 - val_accuracy: 0.8000\n",
      "Epoch 550/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3385 - accuracy: 0.9688\n",
      "Epoch 550: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3374 - accuracy: 0.9694 - val_loss: 0.8486 - val_accuracy: 0.8000\n",
      "Epoch 551/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3608 - accuracy: 0.9792\n",
      "Epoch 551: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3594 - accuracy: 0.9796 - val_loss: 0.8915 - val_accuracy: 0.8000\n",
      "Epoch 552/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3388 - accuracy: 0.9792\n",
      "Epoch 552: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.3376 - accuracy: 0.9796 - val_loss: 0.8904 - val_accuracy: 0.8000\n",
      "Epoch 553/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3169 - accuracy: 0.9898\n",
      "Epoch 553: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.3169 - accuracy: 0.9898 - val_loss: 0.8690 - val_accuracy: 0.7600\n",
      "Epoch 554/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3634 - accuracy: 0.9688\n",
      "Epoch 554: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3617 - accuracy: 0.9694 - val_loss: 0.9169 - val_accuracy: 0.7600\n",
      "Epoch 555/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3570 - accuracy: 0.9694\n",
      "Epoch 555: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.3570 - accuracy: 0.9694 - val_loss: 0.9338 - val_accuracy: 0.8000\n",
      "Epoch 556/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3077 - accuracy: 1.0000\n",
      "Epoch 556: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3072 - accuracy: 1.0000 - val_loss: 0.9296 - val_accuracy: 0.7600\n",
      "Epoch 557/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3422 - accuracy: 0.9792\n",
      "Epoch 557: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3409 - accuracy: 0.9796 - val_loss: 0.8960 - val_accuracy: 0.8800\n",
      "Epoch 558/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3277 - accuracy: 0.9792\n",
      "Epoch 558: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3266 - accuracy: 0.9796 - val_loss: 0.9177 - val_accuracy: 0.8800\n",
      "Epoch 559/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3757 - accuracy: 0.9592\n",
      "Epoch 559: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.3757 - accuracy: 0.9592 - val_loss: 0.9734 - val_accuracy: 0.8000\n",
      "Epoch 560/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3127 - accuracy: 0.9898\n",
      "Epoch 560: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.3127 - accuracy: 0.9898 - val_loss: 0.9256 - val_accuracy: 0.8000\n",
      "Epoch 561/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3300 - accuracy: 0.9792\n",
      "Epoch 561: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3315 - accuracy: 0.9796 - val_loss: 0.9791 - val_accuracy: 0.8000\n",
      "Epoch 562/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3511 - accuracy: 0.9792\n",
      "Epoch 562: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.3496 - accuracy: 0.9796 - val_loss: 0.9669 - val_accuracy: 0.8000\n",
      "Epoch 563/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3272 - accuracy: 0.9896\n",
      "Epoch 563: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3266 - accuracy: 0.9898 - val_loss: 0.9061 - val_accuracy: 0.8000\n",
      "Epoch 564/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3588 - accuracy: 0.9688\n",
      "Epoch 564: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3573 - accuracy: 0.9694 - val_loss: 0.9036 - val_accuracy: 0.8400\n",
      "Epoch 565/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3155 - accuracy: 0.9896\n",
      "Epoch 565: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.3147 - accuracy: 0.9898 - val_loss: 0.8561 - val_accuracy: 0.8400\n",
      "Epoch 566/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3579 - accuracy: 0.9583\n",
      "Epoch 566: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3585 - accuracy: 0.9592 - val_loss: 0.9129 - val_accuracy: 0.7600\n",
      "Epoch 567/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3611 - accuracy: 0.9694\n",
      "Epoch 567: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.3611 - accuracy: 0.9694 - val_loss: 0.8653 - val_accuracy: 0.8800\n",
      "Epoch 568/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3348 - accuracy: 0.9796\n",
      "Epoch 568: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.3348 - accuracy: 0.9796 - val_loss: 0.9164 - val_accuracy: 0.8000\n",
      "Epoch 569/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3316 - accuracy: 0.9896\n",
      "Epoch 569: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.3310 - accuracy: 0.9898 - val_loss: 0.9227 - val_accuracy: 0.8000\n",
      "Epoch 570/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2887 - accuracy: 1.0000\n",
      "Epoch 570: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2884 - accuracy: 1.0000 - val_loss: 0.9221 - val_accuracy: 0.8000\n",
      "Epoch 571/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3067 - accuracy: 1.0000\n",
      "Epoch 571: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3058 - accuracy: 1.0000 - val_loss: 0.9104 - val_accuracy: 0.8400\n",
      "Epoch 572/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3333 - accuracy: 0.9896\n",
      "Epoch 572: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3320 - accuracy: 0.9898 - val_loss: 1.0005 - val_accuracy: 0.7600\n",
      "Epoch 573/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3529 - accuracy: 0.9583\n",
      "Epoch 573: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3531 - accuracy: 0.9592 - val_loss: 0.9254 - val_accuracy: 0.7600\n",
      "Epoch 574/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3127 - accuracy: 0.9896\n",
      "Epoch 574: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.3117 - accuracy: 0.9898 - val_loss: 0.8896 - val_accuracy: 0.8000\n",
      "Epoch 575/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3736 - accuracy: 0.9583\n",
      "Epoch 575: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3715 - accuracy: 0.9592 - val_loss: 0.8663 - val_accuracy: 0.8000\n",
      "Epoch 576/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3007 - accuracy: 0.9898\n",
      "Epoch 576: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.3007 - accuracy: 0.9898 - val_loss: 0.8698 - val_accuracy: 0.7600\n",
      "Epoch 577/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3201 - accuracy: 0.9896\n",
      "Epoch 577: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3226 - accuracy: 0.9898 - val_loss: 0.9150 - val_accuracy: 0.8400\n",
      "Epoch 578/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3578 - accuracy: 0.9479\n",
      "Epoch 578: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3564 - accuracy: 0.9490 - val_loss: 0.9635 - val_accuracy: 0.7600\n",
      "Epoch 579/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3213 - accuracy: 0.9792\n",
      "Epoch 579: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3261 - accuracy: 0.9796 - val_loss: 0.9510 - val_accuracy: 0.7600\n",
      "Epoch 580/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.4064 - accuracy: 0.9688\n",
      "Epoch 580: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.4098 - accuracy: 0.9694 - val_loss: 0.8871 - val_accuracy: 0.7600\n",
      "Epoch 581/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3288 - accuracy: 0.9796\n",
      "Epoch 581: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.3288 - accuracy: 0.9796 - val_loss: 0.8761 - val_accuracy: 0.8000\n",
      "Epoch 582/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3439 - accuracy: 0.9792\n",
      "Epoch 582: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3421 - accuracy: 0.9796 - val_loss: 0.8464 - val_accuracy: 0.8400\n",
      "Epoch 583/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2757 - accuracy: 1.0000\n",
      "Epoch 583: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.2757 - accuracy: 1.0000 - val_loss: 0.8621 - val_accuracy: 0.8400\n",
      "Epoch 584/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3184 - accuracy: 0.9792\n",
      "Epoch 584: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3171 - accuracy: 0.9796 - val_loss: 0.8578 - val_accuracy: 0.8000\n",
      "Epoch 585/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3491 - accuracy: 0.9583\n",
      "Epoch 585: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3473 - accuracy: 0.9592 - val_loss: 0.9033 - val_accuracy: 0.8000\n",
      "Epoch 586/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3173 - accuracy: 0.9792\n",
      "Epoch 586: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3161 - accuracy: 0.9796 - val_loss: 0.9392 - val_accuracy: 0.8000\n",
      "Epoch 587/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3009 - accuracy: 0.9898\n",
      "Epoch 587: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.3009 - accuracy: 0.9898 - val_loss: 0.8882 - val_accuracy: 0.8400\n",
      "Epoch 588/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3493 - accuracy: 0.9694\n",
      "Epoch 588: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.3493 - accuracy: 0.9694 - val_loss: 0.9032 - val_accuracy: 0.8000\n",
      "Epoch 589/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3104 - accuracy: 0.9896\n",
      "Epoch 589: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3099 - accuracy: 0.9898 - val_loss: 0.8669 - val_accuracy: 0.8400\n",
      "Epoch 590/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3202 - accuracy: 0.9792\n",
      "Epoch 590: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3188 - accuracy: 0.9796 - val_loss: 0.8224 - val_accuracy: 0.8400\n",
      "Epoch 591/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2970 - accuracy: 0.9896\n",
      "Epoch 591: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2961 - accuracy: 0.9898 - val_loss: 0.8768 - val_accuracy: 0.8400\n",
      "Epoch 592/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3003 - accuracy: 0.9792\n",
      "Epoch 592: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3024 - accuracy: 0.9796 - val_loss: 0.8758 - val_accuracy: 0.8000\n",
      "Epoch 593/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2835 - accuracy: 0.9898\n",
      "Epoch 593: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.2835 - accuracy: 0.9898 - val_loss: 0.8437 - val_accuracy: 0.8400\n",
      "Epoch 594/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3566 - accuracy: 0.9583\n",
      "Epoch 594: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3557 - accuracy: 0.9592 - val_loss: 0.8163 - val_accuracy: 0.9200\n",
      "Epoch 595/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3031 - accuracy: 0.9898\n",
      "Epoch 595: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.3031 - accuracy: 0.9898 - val_loss: 0.7918 - val_accuracy: 0.8800\n",
      "Epoch 596/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2922 - accuracy: 0.9896\n",
      "Epoch 596: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2955 - accuracy: 0.9898 - val_loss: 0.7610 - val_accuracy: 0.9200\n",
      "Epoch 597/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3677 - accuracy: 0.9479\n",
      "Epoch 597: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.3652 - accuracy: 0.9490 - val_loss: 0.8023 - val_accuracy: 0.8400\n",
      "Epoch 598/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2908 - accuracy: 0.9896\n",
      "Epoch 598: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.2899 - accuracy: 0.9898 - val_loss: 0.8105 - val_accuracy: 0.8400\n",
      "Epoch 599/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3433 - accuracy: 0.9592\n",
      "Epoch 599: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.3433 - accuracy: 0.9592 - val_loss: 0.8414 - val_accuracy: 0.8400\n",
      "Epoch 600/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2887 - accuracy: 0.9792\n",
      "Epoch 600: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2912 - accuracy: 0.9796 - val_loss: 0.8307 - val_accuracy: 0.8400\n",
      "Epoch 601/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2888 - accuracy: 0.9896\n",
      "Epoch 601: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2879 - accuracy: 0.9898 - val_loss: 0.8602 - val_accuracy: 0.8000\n",
      "Epoch 602/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2728 - accuracy: 1.0000\n",
      "Epoch 602: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2727 - accuracy: 1.0000 - val_loss: 0.8940 - val_accuracy: 0.7600\n",
      "Epoch 603/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2800 - accuracy: 0.9898\n",
      "Epoch 603: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.2800 - accuracy: 0.9898 - val_loss: 0.9002 - val_accuracy: 0.7600\n",
      "Epoch 604/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2954 - accuracy: 0.9896\n",
      "Epoch 604: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2943 - accuracy: 0.9898 - val_loss: 0.7719 - val_accuracy: 0.9600\n",
      "Epoch 605/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3062 - accuracy: 0.9688\n",
      "Epoch 605: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3049 - accuracy: 0.9694 - val_loss: 0.8825 - val_accuracy: 0.7600\n",
      "Epoch 606/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3272 - accuracy: 0.9792\n",
      "Epoch 606: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3254 - accuracy: 0.9796 - val_loss: 0.8524 - val_accuracy: 0.8000\n",
      "Epoch 607/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2974 - accuracy: 0.9896\n",
      "Epoch 607: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2963 - accuracy: 0.9898 - val_loss: 0.8427 - val_accuracy: 0.8000\n",
      "Epoch 608/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2913 - accuracy: 0.9792\n",
      "Epoch 608: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2902 - accuracy: 0.9796 - val_loss: 0.8681 - val_accuracy: 0.8000\n",
      "Epoch 609/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2656 - accuracy: 1.0000\n",
      "Epoch 609: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2653 - accuracy: 1.0000 - val_loss: 0.8752 - val_accuracy: 0.8400\n",
      "Epoch 610/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2901 - accuracy: 0.9896\n",
      "Epoch 610: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2997 - accuracy: 0.9898 - val_loss: 0.9227 - val_accuracy: 0.7600\n",
      "Epoch 611/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2819 - accuracy: 0.9898\n",
      "Epoch 611: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2819 - accuracy: 0.9898 - val_loss: 0.9194 - val_accuracy: 0.7600\n",
      "Epoch 612/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2874 - accuracy: 0.9792\n",
      "Epoch 612: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.2866 - accuracy: 0.9796 - val_loss: 0.8453 - val_accuracy: 0.8000\n",
      "Epoch 613/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2725 - accuracy: 0.9896\n",
      "Epoch 613: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3036 - accuracy: 0.9796 - val_loss: 0.8211 - val_accuracy: 0.8400\n",
      "Epoch 614/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3033 - accuracy: 0.9792\n",
      "Epoch 614: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3041 - accuracy: 0.9796 - val_loss: 0.8367 - val_accuracy: 0.8000\n",
      "Epoch 615/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2492 - accuracy: 1.0000\n",
      "Epoch 615: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.2490 - accuracy: 1.0000 - val_loss: 0.8582 - val_accuracy: 0.8000\n",
      "Epoch 616/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3565 - accuracy: 0.9583\n",
      "Epoch 616: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3540 - accuracy: 0.9592 - val_loss: 0.8351 - val_accuracy: 0.8000\n",
      "Epoch 617/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2955 - accuracy: 0.9792\n",
      "Epoch 617: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2974 - accuracy: 0.9796 - val_loss: 0.8429 - val_accuracy: 0.8400\n",
      "Epoch 618/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3523 - accuracy: 0.9694\n",
      "Epoch 618: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.3523 - accuracy: 0.9694 - val_loss: 0.8227 - val_accuracy: 0.8400\n",
      "Epoch 619/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3159 - accuracy: 0.9688\n",
      "Epoch 619: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.3142 - accuracy: 0.9694 - val_loss: 0.8146 - val_accuracy: 0.8400\n",
      "Epoch 620/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2931 - accuracy: 0.9796\n",
      "Epoch 620: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.2931 - accuracy: 0.9796 - val_loss: 0.8810 - val_accuracy: 0.7600\n",
      "Epoch 621/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2974 - accuracy: 0.9792\n",
      "Epoch 621: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2971 - accuracy: 0.9796 - val_loss: 0.9030 - val_accuracy: 0.7600\n",
      "Epoch 622/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2568 - accuracy: 1.0000\n",
      "Epoch 622: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2568 - accuracy: 1.0000 - val_loss: 0.8745 - val_accuracy: 0.7600\n",
      "Epoch 623/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2676 - accuracy: 1.0000\n",
      "Epoch 623: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2671 - accuracy: 1.0000 - val_loss: 0.8624 - val_accuracy: 0.8000\n",
      "Epoch 624/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3171 - accuracy: 0.9694\n",
      "Epoch 624: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.3171 - accuracy: 0.9694 - val_loss: 0.8981 - val_accuracy: 0.7600\n",
      "Epoch 625/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3457 - accuracy: 0.9688\n",
      "Epoch 625: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3441 - accuracy: 0.9694 - val_loss: 0.9775 - val_accuracy: 0.7600\n",
      "Epoch 626/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2529 - accuracy: 1.0000\n",
      "Epoch 626: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.2524 - accuracy: 1.0000 - val_loss: 0.9150 - val_accuracy: 0.8400\n",
      "Epoch 627/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2474 - accuracy: 1.0000\n",
      "Epoch 627: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2470 - accuracy: 1.0000 - val_loss: 0.9087 - val_accuracy: 0.8400\n",
      "Epoch 628/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2702 - accuracy: 0.9896\n",
      "Epoch 628: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.2731 - accuracy: 0.9898 - val_loss: 0.8975 - val_accuracy: 0.8400\n",
      "Epoch 629/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2986 - accuracy: 0.9792\n",
      "Epoch 629: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2991 - accuracy: 0.9796 - val_loss: 0.9196 - val_accuracy: 0.7600\n",
      "Epoch 630/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2694 - accuracy: 0.9898\n",
      "Epoch 630: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.2694 - accuracy: 0.9898 - val_loss: 0.8156 - val_accuracy: 0.8400\n",
      "Epoch 631/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2559 - accuracy: 0.9896\n",
      "Epoch 631: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2554 - accuracy: 0.9898 - val_loss: 0.8604 - val_accuracy: 0.8000\n",
      "Epoch 632/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2568 - accuracy: 1.0000\n",
      "Epoch 632: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2568 - accuracy: 1.0000 - val_loss: 0.9086 - val_accuracy: 0.8000\n",
      "Epoch 633/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2605 - accuracy: 0.9896\n",
      "Epoch 633: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2612 - accuracy: 0.9898 - val_loss: 0.8962 - val_accuracy: 0.8000\n",
      "Epoch 634/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2436 - accuracy: 1.0000\n",
      "Epoch 634: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2436 - accuracy: 1.0000 - val_loss: 0.8903 - val_accuracy: 0.8000\n",
      "Epoch 635/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2525 - accuracy: 0.9896\n",
      "Epoch 635: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2519 - accuracy: 0.9898 - val_loss: 0.8829 - val_accuracy: 0.8000\n",
      "Epoch 636/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3011 - accuracy: 0.9694\n",
      "Epoch 636: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.3011 - accuracy: 0.9694 - val_loss: 0.9201 - val_accuracy: 0.8000\n",
      "Epoch 637/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2537 - accuracy: 0.9896\n",
      "Epoch 637: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2531 - accuracy: 0.9898 - val_loss: 0.8456 - val_accuracy: 0.8400\n",
      "Epoch 638/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2573 - accuracy: 1.0000\n",
      "Epoch 638: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.2573 - accuracy: 1.0000 - val_loss: 0.8374 - val_accuracy: 0.8400\n",
      "Epoch 639/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2497 - accuracy: 1.0000\n",
      "Epoch 639: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.2497 - accuracy: 1.0000 - val_loss: 0.8607 - val_accuracy: 0.8000\n",
      "Epoch 640/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2457 - accuracy: 1.0000\n",
      "Epoch 640: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2453 - accuracy: 1.0000 - val_loss: 0.8458 - val_accuracy: 0.8000\n",
      "Epoch 641/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3226 - accuracy: 0.9796\n",
      "Epoch 641: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.3226 - accuracy: 0.9796 - val_loss: 0.8670 - val_accuracy: 0.8000\n",
      "Epoch 642/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2641 - accuracy: 0.9896\n",
      "Epoch 642: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2635 - accuracy: 0.9898 - val_loss: 0.8611 - val_accuracy: 0.7600\n",
      "Epoch 643/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3393 - accuracy: 0.9583\n",
      "Epoch 643: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.3368 - accuracy: 0.9592 - val_loss: 0.9034 - val_accuracy: 0.7600\n",
      "Epoch 644/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2638 - accuracy: 0.9792\n",
      "Epoch 644: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.2865 - accuracy: 0.9694 - val_loss: 0.8978 - val_accuracy: 0.8000\n",
      "Epoch 645/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2755 - accuracy: 0.9688\n",
      "Epoch 645: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2745 - accuracy: 0.9694 - val_loss: 0.8326 - val_accuracy: 0.8400\n",
      "Epoch 646/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2614 - accuracy: 0.9898\n",
      "Epoch 646: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2614 - accuracy: 0.9898 - val_loss: 0.8964 - val_accuracy: 0.7600\n",
      "Epoch 647/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2706 - accuracy: 0.9896\n",
      "Epoch 647: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2695 - accuracy: 0.9898 - val_loss: 0.8450 - val_accuracy: 0.8000\n",
      "Epoch 648/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2456 - accuracy: 0.9898\n",
      "Epoch 648: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.2456 - accuracy: 0.9898 - val_loss: 0.8301 - val_accuracy: 0.8400\n",
      "Epoch 649/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2813 - accuracy: 0.9896\n",
      "Epoch 649: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2800 - accuracy: 0.9898 - val_loss: 0.8420 - val_accuracy: 0.8000\n",
      "Epoch 650/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2637 - accuracy: 0.9792\n",
      "Epoch 650: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2626 - accuracy: 0.9796 - val_loss: 0.8268 - val_accuracy: 0.8800\n",
      "Epoch 651/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2542 - accuracy: 0.9896\n",
      "Epoch 651: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2534 - accuracy: 0.9898 - val_loss: 0.8271 - val_accuracy: 0.8400\n",
      "Epoch 652/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.3006 - accuracy: 0.9796\n",
      "Epoch 652: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.3006 - accuracy: 0.9796 - val_loss: 0.9447 - val_accuracy: 0.7600\n",
      "Epoch 653/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2352 - accuracy: 1.0000\n",
      "Epoch 653: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2451 - accuracy: 0.9898 - val_loss: 0.9074 - val_accuracy: 0.7600\n",
      "Epoch 654/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2423 - accuracy: 0.9898\n",
      "Epoch 654: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.2423 - accuracy: 0.9898 - val_loss: 0.8248 - val_accuracy: 0.8000\n",
      "Epoch 655/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2596 - accuracy: 0.9792\n",
      "Epoch 655: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2620 - accuracy: 0.9796 - val_loss: 0.9430 - val_accuracy: 0.7600\n",
      "Epoch 656/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2939 - accuracy: 0.9583\n",
      "Epoch 656: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.2969 - accuracy: 0.9592 - val_loss: 1.0574 - val_accuracy: 0.7600\n",
      "Epoch 657/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2737 - accuracy: 0.9792\n",
      "Epoch 657: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2724 - accuracy: 0.9796 - val_loss: 0.9920 - val_accuracy: 0.7600\n",
      "Epoch 658/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2440 - accuracy: 0.9796\n",
      "Epoch 658: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2440 - accuracy: 0.9796 - val_loss: 0.9217 - val_accuracy: 0.8000\n",
      "Epoch 659/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2784 - accuracy: 0.9792\n",
      "Epoch 659: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2772 - accuracy: 0.9796 - val_loss: 0.9240 - val_accuracy: 0.7600\n",
      "Epoch 660/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2500 - accuracy: 0.9796\n",
      "Epoch 660: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.2500 - accuracy: 0.9796 - val_loss: 0.9100 - val_accuracy: 0.8000\n",
      "Epoch 661/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2329 - accuracy: 1.0000\n",
      "Epoch 661: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.2329 - accuracy: 1.0000 - val_loss: 0.8834 - val_accuracy: 0.8000\n",
      "Epoch 662/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2781 - accuracy: 0.9792\n",
      "Epoch 662: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.2767 - accuracy: 0.9796 - val_loss: 0.8382 - val_accuracy: 0.9200\n",
      "Epoch 663/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2682 - accuracy: 0.9792\n",
      "Epoch 663: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2671 - accuracy: 0.9796 - val_loss: 0.8813 - val_accuracy: 0.8000\n",
      "Epoch 664/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2505 - accuracy: 0.9896\n",
      "Epoch 664: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2498 - accuracy: 0.9898 - val_loss: 0.8440 - val_accuracy: 0.8000\n",
      "Epoch 665/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2891 - accuracy: 0.9792\n",
      "Epoch 665: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2874 - accuracy: 0.9796 - val_loss: 0.8809 - val_accuracy: 0.8000\n",
      "Epoch 666/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2372 - accuracy: 0.9796\n",
      "Epoch 666: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2372 - accuracy: 0.9796 - val_loss: 0.9321 - val_accuracy: 0.7600\n",
      "Epoch 667/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2363 - accuracy: 1.0000\n",
      "Epoch 667: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2365 - accuracy: 1.0000 - val_loss: 0.9073 - val_accuracy: 0.8000\n",
      "Epoch 668/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2472 - accuracy: 0.9898\n",
      "Epoch 668: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.2472 - accuracy: 0.9898 - val_loss: 0.8946 - val_accuracy: 0.8000\n",
      "Epoch 669/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3572 - accuracy: 0.9583\n",
      "Epoch 669: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.3541 - accuracy: 0.9592 - val_loss: 0.8907 - val_accuracy: 0.8000\n",
      "Epoch 670/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2811 - accuracy: 0.9688\n",
      "Epoch 670: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2798 - accuracy: 0.9694 - val_loss: 0.8429 - val_accuracy: 0.8000\n",
      "Epoch 671/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2270 - accuracy: 1.0000\n",
      "Epoch 671: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2282 - accuracy: 1.0000 - val_loss: 0.8926 - val_accuracy: 0.8000\n",
      "Epoch 672/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2646 - accuracy: 0.9896\n",
      "Epoch 672: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2649 - accuracy: 0.9898 - val_loss: 0.9110 - val_accuracy: 0.8400\n",
      "Epoch 673/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2674 - accuracy: 0.9688\n",
      "Epoch 673: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2660 - accuracy: 0.9694 - val_loss: 0.8511 - val_accuracy: 0.8800\n",
      "Epoch 674/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2534 - accuracy: 0.9583\n",
      "Epoch 674: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2529 - accuracy: 0.9592 - val_loss: 0.9115 - val_accuracy: 0.8000\n",
      "Epoch 675/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2321 - accuracy: 1.0000\n",
      "Epoch 675: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2315 - accuracy: 1.0000 - val_loss: 0.8452 - val_accuracy: 0.8400\n",
      "Epoch 676/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2502 - accuracy: 0.9688\n",
      "Epoch 676: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2492 - accuracy: 0.9694 - val_loss: 0.8456 - val_accuracy: 0.8000\n",
      "Epoch 677/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2428 - accuracy: 0.9792\n",
      "Epoch 677: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2420 - accuracy: 0.9796 - val_loss: 0.8588 - val_accuracy: 0.8000\n",
      "Epoch 678/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2324 - accuracy: 0.9896\n",
      "Epoch 678: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2318 - accuracy: 0.9898 - val_loss: 0.8789 - val_accuracy: 0.8000\n",
      "Epoch 679/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2181 - accuracy: 1.0000\n",
      "Epoch 679: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2179 - accuracy: 1.0000 - val_loss: 0.8464 - val_accuracy: 0.8000\n",
      "Epoch 680/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2270 - accuracy: 1.0000\n",
      "Epoch 680: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2297 - accuracy: 1.0000 - val_loss: 0.9141 - val_accuracy: 0.7600\n",
      "Epoch 681/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2573 - accuracy: 0.9792\n",
      "Epoch 681: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.2561 - accuracy: 0.9796 - val_loss: 0.8730 - val_accuracy: 0.8800\n",
      "Epoch 682/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2577 - accuracy: 0.9896\n",
      "Epoch 682: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2573 - accuracy: 0.9898 - val_loss: 0.8433 - val_accuracy: 0.8800\n",
      "Epoch 683/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2739 - accuracy: 0.9792\n",
      "Epoch 683: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2732 - accuracy: 0.9796 - val_loss: 0.9472 - val_accuracy: 0.7200\n",
      "Epoch 684/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2272 - accuracy: 0.9896\n",
      "Epoch 684: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2269 - accuracy: 0.9898 - val_loss: 0.8831 - val_accuracy: 0.8800\n",
      "Epoch 685/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2835 - accuracy: 0.9688\n",
      "Epoch 685: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2826 - accuracy: 0.9694 - val_loss: 0.8754 - val_accuracy: 0.8800\n",
      "Epoch 686/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2290 - accuracy: 0.9896\n",
      "Epoch 686: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2287 - accuracy: 0.9898 - val_loss: 0.9117 - val_accuracy: 0.8800\n",
      "Epoch 687/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2607 - accuracy: 0.9896\n",
      "Epoch 687: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2594 - accuracy: 0.9898 - val_loss: 0.8946 - val_accuracy: 0.8400\n",
      "Epoch 688/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2363 - accuracy: 0.9896\n",
      "Epoch 688: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.2355 - accuracy: 0.9898 - val_loss: 0.8875 - val_accuracy: 0.8800\n",
      "Epoch 689/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2650 - accuracy: 0.9896\n",
      "Epoch 689: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2635 - accuracy: 0.9898 - val_loss: 0.8806 - val_accuracy: 0.8400\n",
      "Epoch 690/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2159 - accuracy: 1.0000\n",
      "Epoch 690: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2170 - accuracy: 1.0000 - val_loss: 0.9308 - val_accuracy: 0.7600\n",
      "Epoch 691/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2362 - accuracy: 1.0000\n",
      "Epoch 691: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2362 - accuracy: 1.0000 - val_loss: 0.9205 - val_accuracy: 0.8800\n",
      "Epoch 692/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2252 - accuracy: 1.0000\n",
      "Epoch 692: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2487 - accuracy: 0.9898 - val_loss: 0.8704 - val_accuracy: 0.8800\n",
      "Epoch 693/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2034 - accuracy: 1.0000\n",
      "Epoch 693: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2035 - accuracy: 1.0000 - val_loss: 0.8983 - val_accuracy: 0.8800\n",
      "Epoch 694/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2273 - accuracy: 0.9898\n",
      "Epoch 694: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.2273 - accuracy: 0.9898 - val_loss: 0.8605 - val_accuracy: 0.8800\n",
      "Epoch 695/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2355 - accuracy: 0.9896\n",
      "Epoch 695: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2389 - accuracy: 0.9898 - val_loss: 0.8536 - val_accuracy: 0.8800\n",
      "Epoch 696/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2114 - accuracy: 1.0000\n",
      "Epoch 696: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2113 - accuracy: 1.0000 - val_loss: 0.8465 - val_accuracy: 0.8800\n",
      "Epoch 697/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2628 - accuracy: 0.9792\n",
      "Epoch 697: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2614 - accuracy: 0.9796 - val_loss: 0.8464 - val_accuracy: 0.8800\n",
      "Epoch 698/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2302 - accuracy: 0.9896\n",
      "Epoch 698: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2294 - accuracy: 0.9898 - val_loss: 0.8810 - val_accuracy: 0.8800\n",
      "Epoch 699/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2227 - accuracy: 0.9896\n",
      "Epoch 699: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2221 - accuracy: 0.9898 - val_loss: 0.9214 - val_accuracy: 0.8800\n",
      "Epoch 700/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2416 - accuracy: 0.9896\n",
      "Epoch 700: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2423 - accuracy: 0.9898 - val_loss: 0.9577 - val_accuracy: 0.8000\n",
      "Epoch 701/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2716 - accuracy: 0.9688\n",
      "Epoch 701: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2810 - accuracy: 0.9592 - val_loss: 0.9547 - val_accuracy: 0.8000\n",
      "Epoch 702/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2392 - accuracy: 0.9688\n",
      "Epoch 702: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2382 - accuracy: 0.9694 - val_loss: 0.9042 - val_accuracy: 0.8400\n",
      "Epoch 703/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2241 - accuracy: 0.9896\n",
      "Epoch 703: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.2236 - accuracy: 0.9898 - val_loss: 0.8891 - val_accuracy: 0.8800\n",
      "Epoch 704/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2438 - accuracy: 0.9688\n",
      "Epoch 704: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2432 - accuracy: 0.9694 - val_loss: 0.8974 - val_accuracy: 0.8400\n",
      "Epoch 705/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2021 - accuracy: 1.0000\n",
      "Epoch 705: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2021 - accuracy: 1.0000 - val_loss: 0.8761 - val_accuracy: 0.8800\n",
      "Epoch 706/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2695 - accuracy: 0.9688\n",
      "Epoch 706: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2704 - accuracy: 0.9694 - val_loss: 0.8570 - val_accuracy: 0.8800\n",
      "Epoch 707/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2268 - accuracy: 0.9792\n",
      "Epoch 707: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 0.2260 - accuracy: 0.9796 - val_loss: 0.8414 - val_accuracy: 0.8800\n",
      "Epoch 708/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2739 - accuracy: 0.9792\n",
      "Epoch 708: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2775 - accuracy: 0.9796 - val_loss: 0.8455 - val_accuracy: 0.8800\n",
      "Epoch 709/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2308 - accuracy: 0.9898\n",
      "Epoch 709: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.2308 - accuracy: 0.9898 - val_loss: 0.9090 - val_accuracy: 0.8400\n",
      "Epoch 710/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2616 - accuracy: 0.9688\n",
      "Epoch 710: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2600 - accuracy: 0.9694 - val_loss: 0.8681 - val_accuracy: 0.8800\n",
      "Epoch 711/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2263 - accuracy: 0.9792\n",
      "Epoch 711: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2255 - accuracy: 0.9796 - val_loss: 0.8778 - val_accuracy: 0.8400\n",
      "Epoch 712/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2490 - accuracy: 0.9796\n",
      "Epoch 712: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2490 - accuracy: 0.9796 - val_loss: 0.8402 - val_accuracy: 0.8800\n",
      "Epoch 713/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2091 - accuracy: 0.9896\n",
      "Epoch 713: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2086 - accuracy: 0.9898 - val_loss: 0.8809 - val_accuracy: 0.8400\n",
      "Epoch 714/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2465 - accuracy: 0.9792\n",
      "Epoch 714: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2573 - accuracy: 0.9694 - val_loss: 0.8495 - val_accuracy: 0.8800\n",
      "Epoch 715/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2246 - accuracy: 0.9796\n",
      "Epoch 715: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.2246 - accuracy: 0.9796 - val_loss: 0.8612 - val_accuracy: 0.8400\n",
      "Epoch 716/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2308 - accuracy: 0.9688\n",
      "Epoch 716: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2298 - accuracy: 0.9694 - val_loss: 0.8595 - val_accuracy: 0.8400\n",
      "Epoch 717/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2208 - accuracy: 0.9896\n",
      "Epoch 717: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2276 - accuracy: 0.9796 - val_loss: 0.8599 - val_accuracy: 0.9200\n",
      "Epoch 718/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2067 - accuracy: 1.0000\n",
      "Epoch 718: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2063 - accuracy: 1.0000 - val_loss: 0.8233 - val_accuracy: 0.8400\n",
      "Epoch 719/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1924 - accuracy: 1.0000\n",
      "Epoch 719: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1921 - accuracy: 1.0000 - val_loss: 0.8228 - val_accuracy: 0.8400\n",
      "Epoch 720/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2318 - accuracy: 0.9896\n",
      "Epoch 720: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2334 - accuracy: 0.9898 - val_loss: 0.9233 - val_accuracy: 0.7600\n",
      "Epoch 721/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2753 - accuracy: 0.9694\n",
      "Epoch 721: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.2753 - accuracy: 0.9694 - val_loss: 0.8231 - val_accuracy: 0.8800\n",
      "Epoch 722/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2450 - accuracy: 0.9896\n",
      "Epoch 722: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2471 - accuracy: 0.9898 - val_loss: 0.9292 - val_accuracy: 0.7600\n",
      "Epoch 723/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2043 - accuracy: 0.9896\n",
      "Epoch 723: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2038 - accuracy: 0.9898 - val_loss: 0.8667 - val_accuracy: 0.8000\n",
      "Epoch 724/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2156 - accuracy: 0.9792\n",
      "Epoch 724: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2150 - accuracy: 0.9796 - val_loss: 0.8587 - val_accuracy: 0.8000\n",
      "Epoch 725/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2049 - accuracy: 1.0000\n",
      "Epoch 725: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2044 - accuracy: 1.0000 - val_loss: 0.8413 - val_accuracy: 0.7600\n",
      "Epoch 726/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2115 - accuracy: 1.0000\n",
      "Epoch 726: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2170 - accuracy: 1.0000 - val_loss: 0.8679 - val_accuracy: 0.7600\n",
      "Epoch 727/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2045 - accuracy: 1.0000\n",
      "Epoch 727: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.2040 - accuracy: 1.0000 - val_loss: 0.8457 - val_accuracy: 0.7600\n",
      "Epoch 728/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2058 - accuracy: 1.0000\n",
      "Epoch 728: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2052 - accuracy: 1.0000 - val_loss: 0.8572 - val_accuracy: 0.7600\n",
      "Epoch 729/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2629 - accuracy: 0.9688\n",
      "Epoch 729: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2616 - accuracy: 0.9694 - val_loss: 0.8548 - val_accuracy: 0.7600\n",
      "Epoch 730/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2410 - accuracy: 0.9792\n",
      "Epoch 730: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2397 - accuracy: 0.9796 - val_loss: 0.8387 - val_accuracy: 0.7600\n",
      "Epoch 731/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2350 - accuracy: 0.9896\n",
      "Epoch 731: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2359 - accuracy: 0.9898 - val_loss: 0.8956 - val_accuracy: 0.8400\n",
      "Epoch 732/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2673 - accuracy: 0.9583\n",
      "Epoch 732: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2658 - accuracy: 0.9592 - val_loss: 0.8908 - val_accuracy: 0.8800\n",
      "Epoch 733/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2576 - accuracy: 0.9688\n",
      "Epoch 733: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2567 - accuracy: 0.9694 - val_loss: 0.8594 - val_accuracy: 0.8800\n",
      "Epoch 734/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2229 - accuracy: 0.9896\n",
      "Epoch 734: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2219 - accuracy: 0.9898 - val_loss: 0.8309 - val_accuracy: 0.8800\n",
      "Epoch 735/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2273 - accuracy: 0.9896\n",
      "Epoch 735: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2263 - accuracy: 0.9898 - val_loss: 0.8442 - val_accuracy: 0.8400\n",
      "Epoch 736/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2196 - accuracy: 0.9792\n",
      "Epoch 736: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2191 - accuracy: 0.9796 - val_loss: 0.8166 - val_accuracy: 0.8400\n",
      "Epoch 737/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2439 - accuracy: 0.9688\n",
      "Epoch 737: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2445 - accuracy: 0.9694 - val_loss: 0.8549 - val_accuracy: 0.8400\n",
      "Epoch 738/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2357 - accuracy: 0.9688\n",
      "Epoch 738: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2344 - accuracy: 0.9694 - val_loss: 0.8937 - val_accuracy: 0.8400\n",
      "Epoch 739/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2288 - accuracy: 0.9896\n",
      "Epoch 739: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.2278 - accuracy: 0.9898 - val_loss: 0.8355 - val_accuracy: 0.8800\n",
      "Epoch 740/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2109 - accuracy: 0.9896\n",
      "Epoch 740: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2110 - accuracy: 0.9898 - val_loss: 0.8449 - val_accuracy: 0.8800\n",
      "Epoch 741/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2433 - accuracy: 0.9896\n",
      "Epoch 741: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2420 - accuracy: 0.9898 - val_loss: 0.8416 - val_accuracy: 0.8400\n",
      "Epoch 742/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2262 - accuracy: 0.9792\n",
      "Epoch 742: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2252 - accuracy: 0.9796 - val_loss: 0.8208 - val_accuracy: 0.8800\n",
      "Epoch 743/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3154 - accuracy: 0.9479\n",
      "Epoch 743: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.3208 - accuracy: 0.9388 - val_loss: 0.8991 - val_accuracy: 0.8400\n",
      "Epoch 744/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2399 - accuracy: 0.9792\n",
      "Epoch 744: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2468 - accuracy: 0.9694 - val_loss: 0.8421 - val_accuracy: 0.8400\n",
      "Epoch 745/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2258 - accuracy: 0.9898\n",
      "Epoch 745: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2258 - accuracy: 0.9898 - val_loss: 0.7912 - val_accuracy: 0.8800\n",
      "Epoch 746/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2461 - accuracy: 0.9688\n",
      "Epoch 746: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2446 - accuracy: 0.9694 - val_loss: 0.7892 - val_accuracy: 0.9200\n",
      "Epoch 747/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2307 - accuracy: 0.9792\n",
      "Epoch 747: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2296 - accuracy: 0.9796 - val_loss: 0.8256 - val_accuracy: 0.8400\n",
      "Epoch 748/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2194 - accuracy: 1.0000\n",
      "Epoch 748: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2184 - accuracy: 1.0000 - val_loss: 0.8410 - val_accuracy: 0.8400\n",
      "Epoch 749/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2254 - accuracy: 0.9688\n",
      "Epoch 749: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2243 - accuracy: 0.9694 - val_loss: 0.8301 - val_accuracy: 0.8400\n",
      "Epoch 750/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2254 - accuracy: 0.9792\n",
      "Epoch 750: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2244 - accuracy: 0.9796 - val_loss: 0.8753 - val_accuracy: 0.8000\n",
      "Epoch 751/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2065 - accuracy: 0.9898\n",
      "Epoch 751: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2065 - accuracy: 0.9898 - val_loss: 0.8255 - val_accuracy: 0.8000\n",
      "Epoch 752/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2781 - accuracy: 0.9688\n",
      "Epoch 752: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2759 - accuracy: 0.9694 - val_loss: 0.7829 - val_accuracy: 0.8800\n",
      "Epoch 753/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2187 - accuracy: 0.9796\n",
      "Epoch 753: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2187 - accuracy: 0.9796 - val_loss: 0.8043 - val_accuracy: 0.8800\n",
      "Epoch 754/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2014 - accuracy: 0.9896\n",
      "Epoch 754: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2008 - accuracy: 0.9898 - val_loss: 0.7974 - val_accuracy: 0.8000\n",
      "Epoch 755/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2045 - accuracy: 0.9896\n",
      "Epoch 755: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2037 - accuracy: 0.9898 - val_loss: 0.8088 - val_accuracy: 0.8000\n",
      "Epoch 756/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2554 - accuracy: 0.9694\n",
      "Epoch 756: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2554 - accuracy: 0.9694 - val_loss: 0.8063 - val_accuracy: 0.8000\n",
      "Epoch 757/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2050 - accuracy: 0.9896\n",
      "Epoch 757: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2043 - accuracy: 0.9898 - val_loss: 0.8317 - val_accuracy: 0.8400\n",
      "Epoch 758/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1969 - accuracy: 1.0000\n",
      "Epoch 758: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1963 - accuracy: 1.0000 - val_loss: 0.8586 - val_accuracy: 0.7600\n",
      "Epoch 759/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2308 - accuracy: 0.9694\n",
      "Epoch 759: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2308 - accuracy: 0.9694 - val_loss: 0.8634 - val_accuracy: 0.7600\n",
      "Epoch 760/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1848 - accuracy: 1.0000\n",
      "Epoch 760: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1853 - accuracy: 1.0000 - val_loss: 0.8043 - val_accuracy: 0.7600\n",
      "Epoch 761/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1997 - accuracy: 1.0000\n",
      "Epoch 761: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1993 - accuracy: 1.0000 - val_loss: 0.7992 - val_accuracy: 0.8800\n",
      "Epoch 762/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1992 - accuracy: 0.9896\n",
      "Epoch 762: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1985 - accuracy: 0.9898 - val_loss: 0.8123 - val_accuracy: 0.7600\n",
      "Epoch 763/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2794 - accuracy: 0.9694\n",
      "Epoch 763: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.2794 - accuracy: 0.9694 - val_loss: 0.7824 - val_accuracy: 0.8400\n",
      "Epoch 764/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2496 - accuracy: 0.9792\n",
      "Epoch 764: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2495 - accuracy: 0.9796 - val_loss: 0.7960 - val_accuracy: 0.9200\n",
      "Epoch 765/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1865 - accuracy: 1.0000\n",
      "Epoch 765: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1887 - accuracy: 1.0000 - val_loss: 0.7666 - val_accuracy: 0.8400\n",
      "Epoch 766/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2105 - accuracy: 0.9792\n",
      "Epoch 766: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2096 - accuracy: 0.9796 - val_loss: 0.7510 - val_accuracy: 0.8800\n",
      "Epoch 767/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2373 - accuracy: 0.9796\n",
      "Epoch 767: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.2373 - accuracy: 0.9796 - val_loss: 0.7612 - val_accuracy: 0.9200\n",
      "Epoch 768/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1732 - accuracy: 1.0000\n",
      "Epoch 768: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1730 - accuracy: 1.0000 - val_loss: 0.7981 - val_accuracy: 0.8400\n",
      "Epoch 769/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2078 - accuracy: 0.9896\n",
      "Epoch 769: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2070 - accuracy: 0.9898 - val_loss: 0.7687 - val_accuracy: 0.9200\n",
      "Epoch 770/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1968 - accuracy: 0.9896\n",
      "Epoch 770: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1984 - accuracy: 0.9898 - val_loss: 0.8772 - val_accuracy: 0.7200\n",
      "Epoch 771/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1891 - accuracy: 1.0000\n",
      "Epoch 771: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1887 - accuracy: 1.0000 - val_loss: 0.8190 - val_accuracy: 0.8000\n",
      "Epoch 772/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1944 - accuracy: 1.0000\n",
      "Epoch 772: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1942 - accuracy: 1.0000 - val_loss: 0.8344 - val_accuracy: 0.8000\n",
      "Epoch 773/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2087 - accuracy: 0.9792\n",
      "Epoch 773: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2078 - accuracy: 0.9796 - val_loss: 0.8035 - val_accuracy: 0.8000\n",
      "Epoch 774/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2089 - accuracy: 0.9896\n",
      "Epoch 774: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2080 - accuracy: 0.9898 - val_loss: 0.8641 - val_accuracy: 0.7600\n",
      "Epoch 775/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1870 - accuracy: 1.0000\n",
      "Epoch 775: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1865 - accuracy: 1.0000 - val_loss: 0.8101 - val_accuracy: 0.8400\n",
      "Epoch 776/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2177 - accuracy: 0.9896\n",
      "Epoch 776: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2165 - accuracy: 0.9898 - val_loss: 0.8543 - val_accuracy: 0.8000\n",
      "Epoch 777/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2837 - accuracy: 0.9592\n",
      "Epoch 777: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.2837 - accuracy: 0.9592 - val_loss: 0.6974 - val_accuracy: 0.9200\n",
      "Epoch 778/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2073 - accuracy: 0.9792\n",
      "Epoch 778: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2064 - accuracy: 0.9796 - val_loss: 0.7101 - val_accuracy: 0.8800\n",
      "Epoch 779/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2080 - accuracy: 0.9688\n",
      "Epoch 779: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2070 - accuracy: 0.9694 - val_loss: 0.7062 - val_accuracy: 0.9600\n",
      "Epoch 780/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1893 - accuracy: 1.0000\n",
      "Epoch 780: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1887 - accuracy: 1.0000 - val_loss: 0.7149 - val_accuracy: 0.9600\n",
      "Epoch 781/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1718 - accuracy: 1.0000\n",
      "Epoch 781: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1731 - accuracy: 1.0000 - val_loss: 0.8214 - val_accuracy: 0.8400\n",
      "Epoch 782/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2734 - accuracy: 0.9479\n",
      "Epoch 782: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2713 - accuracy: 0.9490 - val_loss: 0.7487 - val_accuracy: 0.9200\n",
      "Epoch 783/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1999 - accuracy: 0.9898\n",
      "Epoch 783: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.1999 - accuracy: 0.9898 - val_loss: 0.6969 - val_accuracy: 0.9600\n",
      "Epoch 784/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2141 - accuracy: 0.9792\n",
      "Epoch 784: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.2221 - accuracy: 0.9796 - val_loss: 0.7808 - val_accuracy: 0.8000\n",
      "Epoch 785/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2368 - accuracy: 0.9792\n",
      "Epoch 785: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2481 - accuracy: 0.9694 - val_loss: 0.8447 - val_accuracy: 0.7200\n",
      "Epoch 786/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1916 - accuracy: 0.9898\n",
      "Epoch 786: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.1916 - accuracy: 0.9898 - val_loss: 0.7970 - val_accuracy: 0.8000\n",
      "Epoch 787/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.3035 - accuracy: 0.9479\n",
      "Epoch 787: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.3005 - accuracy: 0.9490 - val_loss: 0.8126 - val_accuracy: 0.8000\n",
      "Epoch 788/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2094 - accuracy: 0.9792\n",
      "Epoch 788: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2092 - accuracy: 0.9796 - val_loss: 0.8278 - val_accuracy: 0.7600\n",
      "Epoch 789/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1809 - accuracy: 0.9896\n",
      "Epoch 789: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.1804 - accuracy: 0.9898 - val_loss: 0.7989 - val_accuracy: 0.8800\n",
      "Epoch 790/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1687 - accuracy: 1.0000\n",
      "Epoch 790: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1685 - accuracy: 1.0000 - val_loss: 0.8123 - val_accuracy: 0.7600\n",
      "Epoch 791/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1986 - accuracy: 0.9792\n",
      "Epoch 791: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1979 - accuracy: 0.9796 - val_loss: 0.7865 - val_accuracy: 0.8800\n",
      "Epoch 792/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1930 - accuracy: 0.9896\n",
      "Epoch 792: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1922 - accuracy: 0.9898 - val_loss: 0.7944 - val_accuracy: 0.8400\n",
      "Epoch 793/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1901 - accuracy: 1.0000\n",
      "Epoch 793: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1894 - accuracy: 1.0000 - val_loss: 0.8107 - val_accuracy: 0.7600\n",
      "Epoch 794/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1759 - accuracy: 0.9896\n",
      "Epoch 794: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1755 - accuracy: 0.9898 - val_loss: 0.7956 - val_accuracy: 0.8000\n",
      "Epoch 795/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1908 - accuracy: 0.9896\n",
      "Epoch 795: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1909 - accuracy: 0.9898 - val_loss: 0.8008 - val_accuracy: 0.8400\n",
      "Epoch 796/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1927 - accuracy: 0.9792\n",
      "Epoch 796: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1970 - accuracy: 0.9796 - val_loss: 0.8324 - val_accuracy: 0.8400\n",
      "Epoch 797/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2184 - accuracy: 0.9792\n",
      "Epoch 797: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2180 - accuracy: 0.9796 - val_loss: 0.8859 - val_accuracy: 0.8000\n",
      "Epoch 798/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2213 - accuracy: 0.9688\n",
      "Epoch 798: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2209 - accuracy: 0.9694 - val_loss: 0.8523 - val_accuracy: 0.7600\n",
      "Epoch 799/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1888 - accuracy: 0.9896\n",
      "Epoch 799: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1881 - accuracy: 0.9898 - val_loss: 0.7977 - val_accuracy: 0.8000\n",
      "Epoch 800/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2652 - accuracy: 0.9688\n",
      "Epoch 800: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.2634 - accuracy: 0.9694 - val_loss: 0.8385 - val_accuracy: 0.8000\n",
      "Epoch 801/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2554 - accuracy: 0.9688\n",
      "Epoch 801: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2535 - accuracy: 0.9694 - val_loss: 0.8018 - val_accuracy: 0.9200\n",
      "Epoch 802/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1941 - accuracy: 0.9792\n",
      "Epoch 802: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1933 - accuracy: 0.9796 - val_loss: 0.8455 - val_accuracy: 0.8000\n",
      "Epoch 803/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1650 - accuracy: 1.0000\n",
      "Epoch 803: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1661 - accuracy: 1.0000 - val_loss: 0.8204 - val_accuracy: 0.8000\n",
      "Epoch 804/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1833 - accuracy: 0.9792\n",
      "Epoch 804: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1846 - accuracy: 0.9796 - val_loss: 0.8627 - val_accuracy: 0.8000\n",
      "Epoch 805/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2045 - accuracy: 0.9896\n",
      "Epoch 805: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.2034 - accuracy: 0.9898 - val_loss: 0.8264 - val_accuracy: 0.7600\n",
      "Epoch 806/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2763 - accuracy: 0.9792\n",
      "Epoch 806: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2738 - accuracy: 0.9796 - val_loss: 0.8708 - val_accuracy: 0.7600\n",
      "Epoch 807/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1799 - accuracy: 1.0000\n",
      "Epoch 807: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1804 - accuracy: 1.0000 - val_loss: 0.8440 - val_accuracy: 0.8000\n",
      "Epoch 808/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2420 - accuracy: 0.9694\n",
      "Epoch 808: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2420 - accuracy: 0.9694 - val_loss: 0.8592 - val_accuracy: 0.8000\n",
      "Epoch 809/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2208 - accuracy: 0.9688\n",
      "Epoch 809: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.2206 - accuracy: 0.9694 - val_loss: 0.8419 - val_accuracy: 0.8400\n",
      "Epoch 810/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1669 - accuracy: 1.0000\n",
      "Epoch 810: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1668 - accuracy: 1.0000 - val_loss: 0.8573 - val_accuracy: 0.8000\n",
      "Epoch 811/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2049 - accuracy: 0.9796\n",
      "Epoch 811: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.2049 - accuracy: 0.9796 - val_loss: 0.8625 - val_accuracy: 0.7600\n",
      "Epoch 812/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2254 - accuracy: 0.9688\n",
      "Epoch 812: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2245 - accuracy: 0.9694 - val_loss: 0.8504 - val_accuracy: 0.8400\n",
      "Epoch 813/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1932 - accuracy: 0.9896\n",
      "Epoch 813: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1923 - accuracy: 0.9898 - val_loss: 0.9122 - val_accuracy: 0.7200\n",
      "Epoch 814/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1683 - accuracy: 1.0000\n",
      "Epoch 814: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 0.1681 - accuracy: 1.0000 - val_loss: 0.8378 - val_accuracy: 0.8000\n",
      "Epoch 815/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1810 - accuracy: 1.0000\n",
      "Epoch 815: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1810 - accuracy: 1.0000 - val_loss: 0.7952 - val_accuracy: 0.8000\n",
      "Epoch 816/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1777 - accuracy: 0.9896\n",
      "Epoch 816: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1771 - accuracy: 0.9898 - val_loss: 0.7605 - val_accuracy: 0.8800\n",
      "Epoch 817/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1915 - accuracy: 0.9896\n",
      "Epoch 817: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1976 - accuracy: 0.9898 - val_loss: 0.8663 - val_accuracy: 0.8000\n",
      "Epoch 818/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1641 - accuracy: 1.0000\n",
      "Epoch 818: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1643 - accuracy: 1.0000 - val_loss: 0.8520 - val_accuracy: 0.8800\n",
      "Epoch 819/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1801 - accuracy: 1.0000\n",
      "Epoch 819: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.1794 - accuracy: 1.0000 - val_loss: 0.8365 - val_accuracy: 0.7600\n",
      "Epoch 820/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1925 - accuracy: 0.9796\n",
      "Epoch 820: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.1925 - accuracy: 0.9796 - val_loss: 0.8188 - val_accuracy: 0.8400\n",
      "Epoch 821/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2065 - accuracy: 0.9896\n",
      "Epoch 821: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2054 - accuracy: 0.9898 - val_loss: 0.8466 - val_accuracy: 0.7600\n",
      "Epoch 822/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1682 - accuracy: 1.0000\n",
      "Epoch 822: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1678 - accuracy: 1.0000 - val_loss: 0.8235 - val_accuracy: 0.8400\n",
      "Epoch 823/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2364 - accuracy: 0.9792\n",
      "Epoch 823: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2351 - accuracy: 0.9796 - val_loss: 0.8490 - val_accuracy: 0.7600\n",
      "Epoch 824/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1821 - accuracy: 0.9792\n",
      "Epoch 824: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1814 - accuracy: 0.9796 - val_loss: 0.9351 - val_accuracy: 0.7600\n",
      "Epoch 825/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1779 - accuracy: 0.9896\n",
      "Epoch 825: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 70ms/step - loss: 0.1773 - accuracy: 0.9898 - val_loss: 0.9533 - val_accuracy: 0.7600\n",
      "Epoch 826/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1963 - accuracy: 1.0000\n",
      "Epoch 826: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2007 - accuracy: 1.0000 - val_loss: 0.9024 - val_accuracy: 0.7600\n",
      "Epoch 827/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1940 - accuracy: 0.9898\n",
      "Epoch 827: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1940 - accuracy: 0.9898 - val_loss: 0.8588 - val_accuracy: 0.7600\n",
      "Epoch 828/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1741 - accuracy: 1.0000\n",
      "Epoch 828: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1735 - accuracy: 1.0000 - val_loss: 0.8260 - val_accuracy: 0.8400\n",
      "Epoch 829/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1998 - accuracy: 0.9796\n",
      "Epoch 829: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1998 - accuracy: 0.9796 - val_loss: 0.9068 - val_accuracy: 0.8000\n",
      "Epoch 830/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2137 - accuracy: 0.9792\n",
      "Epoch 830: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2124 - accuracy: 0.9796 - val_loss: 0.8572 - val_accuracy: 0.8800\n",
      "Epoch 831/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1709 - accuracy: 1.0000\n",
      "Epoch 831: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1705 - accuracy: 1.0000 - val_loss: 0.8731 - val_accuracy: 0.8800\n",
      "Epoch 832/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2115 - accuracy: 0.9694\n",
      "Epoch 832: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.2115 - accuracy: 0.9694 - val_loss: 0.9106 - val_accuracy: 0.7600\n",
      "Epoch 833/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1912 - accuracy: 0.9796\n",
      "Epoch 833: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1912 - accuracy: 0.9796 - val_loss: 0.8813 - val_accuracy: 0.8000\n",
      "Epoch 834/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1526 - accuracy: 1.0000\n",
      "Epoch 834: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1524 - accuracy: 1.0000 - val_loss: 0.8630 - val_accuracy: 0.7600\n",
      "Epoch 835/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2383 - accuracy: 0.9688\n",
      "Epoch 835: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 49ms/step - loss: 0.2364 - accuracy: 0.9694 - val_loss: 0.8561 - val_accuracy: 0.8800\n",
      "Epoch 836/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1800 - accuracy: 0.9898\n",
      "Epoch 836: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1800 - accuracy: 0.9898 - val_loss: 0.8598 - val_accuracy: 0.8800\n",
      "Epoch 837/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1664 - accuracy: 1.0000\n",
      "Epoch 837: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1660 - accuracy: 1.0000 - val_loss: 0.8773 - val_accuracy: 0.8000\n",
      "Epoch 838/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1723 - accuracy: 0.9896\n",
      "Epoch 838: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1716 - accuracy: 0.9898 - val_loss: 0.9167 - val_accuracy: 0.8000\n",
      "Epoch 839/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1765 - accuracy: 1.0000\n",
      "Epoch 839: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1996 - accuracy: 0.9898 - val_loss: 0.9135 - val_accuracy: 0.7200\n",
      "Epoch 840/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2576 - accuracy: 0.9796\n",
      "Epoch 840: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.2576 - accuracy: 0.9796 - val_loss: 0.8993 - val_accuracy: 0.7200\n",
      "Epoch 841/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1761 - accuracy: 0.9896\n",
      "Epoch 841: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.1758 - accuracy: 0.9898 - val_loss: 0.9184 - val_accuracy: 0.7600\n",
      "Epoch 842/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1577 - accuracy: 1.0000\n",
      "Epoch 842: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1577 - accuracy: 1.0000 - val_loss: 0.8802 - val_accuracy: 0.8400\n",
      "Epoch 843/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1685 - accuracy: 0.9896\n",
      "Epoch 843: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1680 - accuracy: 0.9898 - val_loss: 0.8767 - val_accuracy: 0.8000\n",
      "Epoch 844/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1969 - accuracy: 0.9792\n",
      "Epoch 844: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1957 - accuracy: 0.9796 - val_loss: 0.8551 - val_accuracy: 0.8000\n",
      "Epoch 845/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2028 - accuracy: 0.9896\n",
      "Epoch 845: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2054 - accuracy: 0.9898 - val_loss: 0.8816 - val_accuracy: 0.7200\n",
      "Epoch 846/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1714 - accuracy: 0.9896\n",
      "Epoch 846: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1707 - accuracy: 0.9898 - val_loss: 0.8896 - val_accuracy: 0.7200\n",
      "Epoch 847/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1779 - accuracy: 1.0000\n",
      "Epoch 847: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.1775 - accuracy: 1.0000 - val_loss: 0.8891 - val_accuracy: 0.7600\n",
      "Epoch 848/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1785 - accuracy: 1.0000\n",
      "Epoch 848: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1777 - accuracy: 1.0000 - val_loss: 0.9250 - val_accuracy: 0.7600\n",
      "Epoch 849/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1688 - accuracy: 1.0000\n",
      "Epoch 849: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1700 - accuracy: 1.0000 - val_loss: 0.8997 - val_accuracy: 0.8000\n",
      "Epoch 850/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.2041 - accuracy: 0.9694\n",
      "Epoch 850: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.2041 - accuracy: 0.9694 - val_loss: 0.7623 - val_accuracy: 0.8400\n",
      "Epoch 851/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1626 - accuracy: 1.0000\n",
      "Epoch 851: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1621 - accuracy: 1.0000 - val_loss: 0.8078 - val_accuracy: 0.8400\n",
      "Epoch 852/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1593 - accuracy: 1.0000\n",
      "Epoch 852: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1588 - accuracy: 1.0000 - val_loss: 0.8102 - val_accuracy: 0.8000\n",
      "Epoch 853/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1495 - accuracy: 1.0000\n",
      "Epoch 853: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.1495 - accuracy: 1.0000 - val_loss: 0.8218 - val_accuracy: 0.8000\n",
      "Epoch 854/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2064 - accuracy: 0.9688\n",
      "Epoch 854: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2061 - accuracy: 0.9694 - val_loss: 0.8341 - val_accuracy: 0.8000\n",
      "Epoch 855/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1592 - accuracy: 0.9896\n",
      "Epoch 855: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1587 - accuracy: 0.9898 - val_loss: 0.8751 - val_accuracy: 0.7600\n",
      "Epoch 856/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2062 - accuracy: 0.9688\n",
      "Epoch 856: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2054 - accuracy: 0.9694 - val_loss: 0.8099 - val_accuracy: 0.8800\n",
      "Epoch 857/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1972 - accuracy: 0.9792\n",
      "Epoch 857: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.1960 - accuracy: 0.9796 - val_loss: 0.8118 - val_accuracy: 0.8800\n",
      "Epoch 858/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1527 - accuracy: 1.0000\n",
      "Epoch 858: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1523 - accuracy: 1.0000 - val_loss: 0.8636 - val_accuracy: 0.7600\n",
      "Epoch 859/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1842 - accuracy: 0.9896\n",
      "Epoch 859: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1832 - accuracy: 0.9898 - val_loss: 0.8278 - val_accuracy: 0.8000\n",
      "Epoch 860/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1510 - accuracy: 1.0000\n",
      "Epoch 860: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1507 - accuracy: 1.0000 - val_loss: 0.8179 - val_accuracy: 0.8000\n",
      "Epoch 861/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1690 - accuracy: 0.9896\n",
      "Epoch 861: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1685 - accuracy: 0.9898 - val_loss: 0.8466 - val_accuracy: 0.8000\n",
      "Epoch 862/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1500 - accuracy: 1.0000\n",
      "Epoch 862: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1500 - accuracy: 1.0000 - val_loss: 0.8210 - val_accuracy: 0.8000\n",
      "Epoch 863/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1829 - accuracy: 0.9898\n",
      "Epoch 863: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 59ms/step - loss: 0.1829 - accuracy: 0.9898 - val_loss: 0.8005 - val_accuracy: 0.8000\n",
      "Epoch 864/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1518 - accuracy: 1.0000\n",
      "Epoch 864: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1514 - accuracy: 1.0000 - val_loss: 0.7985 - val_accuracy: 0.8800\n",
      "Epoch 865/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1562 - accuracy: 0.9896\n",
      "Epoch 865: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1558 - accuracy: 0.9898 - val_loss: 0.8172 - val_accuracy: 0.8000\n",
      "Epoch 866/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1590 - accuracy: 1.0000\n",
      "Epoch 866: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.1585 - accuracy: 1.0000 - val_loss: 0.8805 - val_accuracy: 0.7600\n",
      "Epoch 867/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1716 - accuracy: 0.9896\n",
      "Epoch 867: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.1708 - accuracy: 0.9898 - val_loss: 0.8501 - val_accuracy: 0.7600\n",
      "Epoch 868/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1473 - accuracy: 1.0000\n",
      "Epoch 868: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1476 - accuracy: 1.0000 - val_loss: 0.8184 - val_accuracy: 0.8000\n",
      "Epoch 869/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1681 - accuracy: 0.9896\n",
      "Epoch 869: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1679 - accuracy: 0.9898 - val_loss: 0.7815 - val_accuracy: 0.8800\n",
      "Epoch 870/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1680 - accuracy: 0.9896\n",
      "Epoch 870: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.1676 - accuracy: 0.9898 - val_loss: 0.8205 - val_accuracy: 0.8000\n",
      "Epoch 871/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2159 - accuracy: 0.9688\n",
      "Epoch 871: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2142 - accuracy: 0.9694 - val_loss: 0.9146 - val_accuracy: 0.7600\n",
      "Epoch 872/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1593 - accuracy: 0.9898\n",
      "Epoch 872: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.1593 - accuracy: 0.9898 - val_loss: 0.8188 - val_accuracy: 0.7600\n",
      "Epoch 873/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1450 - accuracy: 1.0000\n",
      "Epoch 873: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1525 - accuracy: 0.9898 - val_loss: 0.8787 - val_accuracy: 0.8400\n",
      "Epoch 874/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1517 - accuracy: 1.0000\n",
      "Epoch 874: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1513 - accuracy: 1.0000 - val_loss: 0.8880 - val_accuracy: 0.8000\n",
      "Epoch 875/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2345 - accuracy: 0.9792\n",
      "Epoch 875: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.2336 - accuracy: 0.9796 - val_loss: 0.8114 - val_accuracy: 0.8400\n",
      "Epoch 876/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1693 - accuracy: 0.9688\n",
      "Epoch 876: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1685 - accuracy: 0.9694 - val_loss: 0.8641 - val_accuracy: 0.7200\n",
      "Epoch 877/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1507 - accuracy: 1.0000\n",
      "Epoch 877: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.1507 - accuracy: 1.0000 - val_loss: 0.8418 - val_accuracy: 0.8400\n",
      "Epoch 878/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1654 - accuracy: 1.0000\n",
      "Epoch 878: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1647 - accuracy: 1.0000 - val_loss: 0.9369 - val_accuracy: 0.7200\n",
      "Epoch 879/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1717 - accuracy: 0.9792\n",
      "Epoch 879: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1788 - accuracy: 0.9694 - val_loss: 0.9287 - val_accuracy: 0.6800\n",
      "Epoch 880/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1778 - accuracy: 0.9896\n",
      "Epoch 880: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1770 - accuracy: 0.9898 - val_loss: 0.9140 - val_accuracy: 0.7200\n",
      "Epoch 881/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1774 - accuracy: 0.9792\n",
      "Epoch 881: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1765 - accuracy: 0.9796 - val_loss: 0.8066 - val_accuracy: 0.8000\n",
      "Epoch 882/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1513 - accuracy: 1.0000\n",
      "Epoch 882: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1509 - accuracy: 1.0000 - val_loss: 0.8149 - val_accuracy: 0.8000\n",
      "Epoch 883/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1520 - accuracy: 0.9896\n",
      "Epoch 883: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.1576 - accuracy: 0.9898 - val_loss: 0.8773 - val_accuracy: 0.8400\n",
      "Epoch 884/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1711 - accuracy: 0.9792\n",
      "Epoch 884: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.1703 - accuracy: 0.9796 - val_loss: 0.8440 - val_accuracy: 0.8800\n",
      "Epoch 885/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1597 - accuracy: 0.9896\n",
      "Epoch 885: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1674 - accuracy: 0.9796 - val_loss: 0.8846 - val_accuracy: 0.8400\n",
      "Epoch 886/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1523 - accuracy: 0.9896\n",
      "Epoch 886: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1528 - accuracy: 0.9898 - val_loss: 0.8849 - val_accuracy: 0.8400\n",
      "Epoch 887/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1543 - accuracy: 0.9896\n",
      "Epoch 887: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1538 - accuracy: 0.9898 - val_loss: 0.8882 - val_accuracy: 0.7200\n",
      "Epoch 888/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2274 - accuracy: 0.9792\n",
      "Epoch 888: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.2253 - accuracy: 0.9796 - val_loss: 0.8967 - val_accuracy: 0.7600\n",
      "Epoch 889/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1437 - accuracy: 1.0000\n",
      "Epoch 889: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1434 - accuracy: 1.0000 - val_loss: 0.8939 - val_accuracy: 0.7200\n",
      "Epoch 890/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1593 - accuracy: 0.9896\n",
      "Epoch 890: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1588 - accuracy: 0.9898 - val_loss: 0.8647 - val_accuracy: 0.7200\n",
      "Epoch 891/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1659 - accuracy: 0.9896\n",
      "Epoch 891: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1651 - accuracy: 0.9898 - val_loss: 0.9308 - val_accuracy: 0.7600\n",
      "Epoch 892/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1996 - accuracy: 0.9896\n",
      "Epoch 892: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.1981 - accuracy: 0.9898 - val_loss: 0.8224 - val_accuracy: 0.8800\n",
      "Epoch 893/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1549 - accuracy: 1.0000\n",
      "Epoch 893: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1544 - accuracy: 1.0000 - val_loss: 0.8245 - val_accuracy: 0.8000\n",
      "Epoch 894/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1775 - accuracy: 0.9688\n",
      "Epoch 894: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1765 - accuracy: 0.9694 - val_loss: 0.8198 - val_accuracy: 0.7200\n",
      "Epoch 895/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1471 - accuracy: 1.0000\n",
      "Epoch 895: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.1467 - accuracy: 1.0000 - val_loss: 0.8599 - val_accuracy: 0.7200\n",
      "Epoch 896/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1490 - accuracy: 0.9898\n",
      "Epoch 896: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1490 - accuracy: 0.9898 - val_loss: 0.8605 - val_accuracy: 0.7200\n",
      "Epoch 897/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1550 - accuracy: 1.0000\n",
      "Epoch 897: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.1544 - accuracy: 1.0000 - val_loss: 0.8434 - val_accuracy: 0.7600\n",
      "Epoch 898/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1440 - accuracy: 1.0000\n",
      "Epoch 898: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.1440 - accuracy: 1.0000 - val_loss: 0.8765 - val_accuracy: 0.7600\n",
      "Epoch 899/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1504 - accuracy: 0.9896\n",
      "Epoch 899: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1499 - accuracy: 0.9898 - val_loss: 0.8511 - val_accuracy: 0.8000\n",
      "Epoch 900/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1566 - accuracy: 0.9896\n",
      "Epoch 900: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1562 - accuracy: 0.9898 - val_loss: 0.8787 - val_accuracy: 0.8000\n",
      "Epoch 901/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1674 - accuracy: 0.9896\n",
      "Epoch 901: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1665 - accuracy: 0.9898 - val_loss: 0.7842 - val_accuracy: 0.8000\n",
      "Epoch 902/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1439 - accuracy: 1.0000\n",
      "Epoch 902: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1434 - accuracy: 1.0000 - val_loss: 0.7765 - val_accuracy: 0.8400\n",
      "Epoch 903/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1585 - accuracy: 0.9896\n",
      "Epoch 903: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1587 - accuracy: 0.9898 - val_loss: 0.8118 - val_accuracy: 0.8000\n",
      "Epoch 904/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1450 - accuracy: 1.0000\n",
      "Epoch 904: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.1446 - accuracy: 1.0000 - val_loss: 0.8200 - val_accuracy: 0.8000\n",
      "Epoch 905/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1608 - accuracy: 0.9896\n",
      "Epoch 905: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.1611 - accuracy: 0.9898 - val_loss: 0.8371 - val_accuracy: 0.7600\n",
      "Epoch 906/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1430 - accuracy: 0.9896\n",
      "Epoch 906: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1428 - accuracy: 0.9898 - val_loss: 0.7820 - val_accuracy: 0.8000\n",
      "Epoch 907/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1516 - accuracy: 1.0000\n",
      "Epoch 907: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.1695 - accuracy: 0.9898 - val_loss: 0.7566 - val_accuracy: 0.8000\n",
      "Epoch 908/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1438 - accuracy: 1.0000\n",
      "Epoch 908: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1435 - accuracy: 1.0000 - val_loss: 0.7510 - val_accuracy: 0.8000\n",
      "Epoch 909/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1625 - accuracy: 0.9792\n",
      "Epoch 909: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.1701 - accuracy: 0.9694 - val_loss: 0.7765 - val_accuracy: 0.8000\n",
      "Epoch 910/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1808 - accuracy: 0.9792\n",
      "Epoch 910: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1796 - accuracy: 0.9796 - val_loss: 0.8009 - val_accuracy: 0.8000\n",
      "Epoch 911/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1539 - accuracy: 0.9896\n",
      "Epoch 911: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1535 - accuracy: 0.9898 - val_loss: 0.8148 - val_accuracy: 0.8000\n",
      "Epoch 912/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1678 - accuracy: 0.9898\n",
      "Epoch 912: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 50ms/step - loss: 0.1678 - accuracy: 0.9898 - val_loss: 0.8470 - val_accuracy: 0.8400\n",
      "Epoch 913/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1743 - accuracy: 0.9896\n",
      "Epoch 913: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1733 - accuracy: 0.9898 - val_loss: 0.8189 - val_accuracy: 0.8400\n",
      "Epoch 914/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1400 - accuracy: 1.0000\n",
      "Epoch 914: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1435 - accuracy: 1.0000 - val_loss: 0.8217 - val_accuracy: 0.8000\n",
      "Epoch 915/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1425 - accuracy: 0.9896\n",
      "Epoch 915: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1600 - accuracy: 0.9796 - val_loss: 0.7971 - val_accuracy: 0.7600\n",
      "Epoch 916/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1482 - accuracy: 0.9896\n",
      "Epoch 916: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1477 - accuracy: 0.9898 - val_loss: 0.7728 - val_accuracy: 0.8000\n",
      "Epoch 917/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1406 - accuracy: 1.0000\n",
      "Epoch 917: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1406 - accuracy: 1.0000 - val_loss: 0.7599 - val_accuracy: 0.8400\n",
      "Epoch 918/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1700 - accuracy: 0.9688\n",
      "Epoch 918: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 0.1690 - accuracy: 0.9694 - val_loss: 0.8155 - val_accuracy: 0.8000\n",
      "Epoch 919/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1744 - accuracy: 0.9792\n",
      "Epoch 919: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1752 - accuracy: 0.9796 - val_loss: 0.8204 - val_accuracy: 0.7600\n",
      "Epoch 920/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1393 - accuracy: 1.0000\n",
      "Epoch 920: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1389 - accuracy: 1.0000 - val_loss: 0.8087 - val_accuracy: 0.7600\n",
      "Epoch 921/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1508 - accuracy: 0.9792\n",
      "Epoch 921: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1517 - accuracy: 0.9796 - val_loss: 0.8408 - val_accuracy: 0.8000\n",
      "Epoch 922/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1454 - accuracy: 1.0000\n",
      "Epoch 922: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.1449 - accuracy: 1.0000 - val_loss: 0.9149 - val_accuracy: 0.8000\n",
      "Epoch 923/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1642 - accuracy: 0.9896\n",
      "Epoch 923: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1634 - accuracy: 0.9898 - val_loss: 0.8612 - val_accuracy: 0.7600\n",
      "Epoch 924/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1436 - accuracy: 1.0000\n",
      "Epoch 924: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1456 - accuracy: 1.0000 - val_loss: 0.9402 - val_accuracy: 0.7200\n",
      "Epoch 925/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1563 - accuracy: 0.9896\n",
      "Epoch 925: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.1607 - accuracy: 0.9898 - val_loss: 0.8607 - val_accuracy: 0.7600\n",
      "Epoch 926/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1993 - accuracy: 0.9583\n",
      "Epoch 926: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1977 - accuracy: 0.9592 - val_loss: 0.8834 - val_accuracy: 0.7600\n",
      "Epoch 927/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1552 - accuracy: 0.9896\n",
      "Epoch 927: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1545 - accuracy: 0.9898 - val_loss: 0.8711 - val_accuracy: 0.8000\n",
      "Epoch 928/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1524 - accuracy: 0.9896\n",
      "Epoch 928: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1520 - accuracy: 0.9898 - val_loss: 0.8203 - val_accuracy: 0.8000\n",
      "Epoch 929/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1624 - accuracy: 0.9896\n",
      "Epoch 929: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1619 - accuracy: 0.9898 - val_loss: 0.8263 - val_accuracy: 0.8000\n",
      "Epoch 930/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1416 - accuracy: 1.0000\n",
      "Epoch 930: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1413 - accuracy: 1.0000 - val_loss: 0.8463 - val_accuracy: 0.8000\n",
      "Epoch 931/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1680 - accuracy: 0.9896\n",
      "Epoch 931: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1672 - accuracy: 0.9898 - val_loss: 0.8639 - val_accuracy: 0.7600\n",
      "Epoch 932/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1570 - accuracy: 1.0000\n",
      "Epoch 932: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1566 - accuracy: 1.0000 - val_loss: 0.8669 - val_accuracy: 0.7600\n",
      "Epoch 933/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1478 - accuracy: 0.9896\n",
      "Epoch 933: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.1473 - accuracy: 0.9898 - val_loss: 0.8526 - val_accuracy: 0.7200\n",
      "Epoch 934/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1681 - accuracy: 0.9896\n",
      "Epoch 934: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1671 - accuracy: 0.9898 - val_loss: 0.8076 - val_accuracy: 0.7600\n",
      "Epoch 935/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1287 - accuracy: 1.0000\n",
      "Epoch 935: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1286 - accuracy: 1.0000 - val_loss: 0.7896 - val_accuracy: 0.7600\n",
      "Epoch 936/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1400 - accuracy: 1.0000\n",
      "Epoch 936: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1648 - accuracy: 0.9898 - val_loss: 0.8340 - val_accuracy: 0.8400\n",
      "Epoch 937/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1534 - accuracy: 0.9896\n",
      "Epoch 937: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1527 - accuracy: 0.9898 - val_loss: 0.8336 - val_accuracy: 0.8400\n",
      "Epoch 938/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1548 - accuracy: 0.9792\n",
      "Epoch 938: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1603 - accuracy: 0.9796 - val_loss: 0.8147 - val_accuracy: 0.8400\n",
      "Epoch 939/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1421 - accuracy: 1.0000\n",
      "Epoch 939: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1421 - accuracy: 1.0000 - val_loss: 0.8206 - val_accuracy: 0.8400\n",
      "Epoch 940/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1393 - accuracy: 1.0000\n",
      "Epoch 940: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.1388 - accuracy: 1.0000 - val_loss: 0.8028 - val_accuracy: 0.8400\n",
      "Epoch 941/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1354 - accuracy: 0.9896\n",
      "Epoch 941: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1351 - accuracy: 0.9898 - val_loss: 0.7960 - val_accuracy: 0.8400\n",
      "Epoch 942/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1506 - accuracy: 0.9896\n",
      "Epoch 942: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1502 - accuracy: 0.9898 - val_loss: 0.8411 - val_accuracy: 0.8000\n",
      "Epoch 943/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1774 - accuracy: 0.9688\n",
      "Epoch 943: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1763 - accuracy: 0.9694 - val_loss: 0.8696 - val_accuracy: 0.8400\n",
      "Epoch 944/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1381 - accuracy: 0.9896\n",
      "Epoch 944: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1377 - accuracy: 0.9898 - val_loss: 0.8695 - val_accuracy: 0.8400\n",
      "Epoch 945/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1559 - accuracy: 0.9792\n",
      "Epoch 945: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1564 - accuracy: 0.9796 - val_loss: 0.9048 - val_accuracy: 0.7600\n",
      "Epoch 946/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1515 - accuracy: 0.9896\n",
      "Epoch 946: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1591 - accuracy: 0.9898 - val_loss: 0.9689 - val_accuracy: 0.7600\n",
      "Epoch 947/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1789 - accuracy: 0.9792\n",
      "Epoch 947: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1776 - accuracy: 0.9796 - val_loss: 0.8733 - val_accuracy: 0.8000\n",
      "Epoch 948/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1692 - accuracy: 0.9896\n",
      "Epoch 948: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.1680 - accuracy: 0.9898 - val_loss: 0.8950 - val_accuracy: 0.8000\n",
      "Epoch 949/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1497 - accuracy: 0.9896\n",
      "Epoch 949: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1490 - accuracy: 0.9898 - val_loss: 0.8062 - val_accuracy: 0.8000\n",
      "Epoch 950/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1507 - accuracy: 0.9896\n",
      "Epoch 950: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1499 - accuracy: 0.9898 - val_loss: 0.8470 - val_accuracy: 0.8400\n",
      "Epoch 951/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1691 - accuracy: 0.9792\n",
      "Epoch 951: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1680 - accuracy: 0.9796 - val_loss: 0.8015 - val_accuracy: 0.8000\n",
      "Epoch 952/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1386 - accuracy: 0.9896\n",
      "Epoch 952: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1381 - accuracy: 0.9898 - val_loss: 0.8813 - val_accuracy: 0.8000\n",
      "Epoch 953/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1887 - accuracy: 0.9792\n",
      "Epoch 953: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.1984 - accuracy: 0.9796 - val_loss: 0.8096 - val_accuracy: 0.8000\n",
      "Epoch 954/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1489 - accuracy: 1.0000\n",
      "Epoch 954: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1516 - accuracy: 1.0000 - val_loss: 0.8555 - val_accuracy: 0.7600\n",
      "Epoch 955/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2202 - accuracy: 0.9688\n",
      "Epoch 955: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.2181 - accuracy: 0.9694 - val_loss: 0.8383 - val_accuracy: 0.8000\n",
      "Epoch 956/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1832 - accuracy: 0.9688\n",
      "Epoch 956: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.1818 - accuracy: 0.9694 - val_loss: 0.8573 - val_accuracy: 0.8000\n",
      "Epoch 957/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1567 - accuracy: 0.9792\n",
      "Epoch 957: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1558 - accuracy: 0.9796 - val_loss: 0.8977 - val_accuracy: 0.7600\n",
      "Epoch 958/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1867 - accuracy: 0.9792\n",
      "Epoch 958: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1859 - accuracy: 0.9796 - val_loss: 0.8799 - val_accuracy: 0.7200\n",
      "Epoch 959/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1305 - accuracy: 0.9896\n",
      "Epoch 959: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1310 - accuracy: 0.9898 - val_loss: 0.8630 - val_accuracy: 0.7200\n",
      "Epoch 960/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1758 - accuracy: 0.9896\n",
      "Epoch 960: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 47ms/step - loss: 0.1750 - accuracy: 0.9898 - val_loss: 0.8716 - val_accuracy: 0.8000\n",
      "Epoch 961/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1439 - accuracy: 0.9896\n",
      "Epoch 961: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1433 - accuracy: 0.9898 - val_loss: 0.8565 - val_accuracy: 0.8000\n",
      "Epoch 962/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1485 - accuracy: 0.9896\n",
      "Epoch 962: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1503 - accuracy: 0.9898 - val_loss: 0.8202 - val_accuracy: 0.8800\n",
      "Epoch 963/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2149 - accuracy: 0.9688\n",
      "Epoch 963: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.2130 - accuracy: 0.9694 - val_loss: 0.8478 - val_accuracy: 0.8400\n",
      "Epoch 964/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1428 - accuracy: 1.0000\n",
      "Epoch 964: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.1428 - accuracy: 1.0000 - val_loss: 0.8148 - val_accuracy: 0.8400\n",
      "Epoch 965/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1280 - accuracy: 1.0000\n",
      "Epoch 965: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1280 - accuracy: 1.0000 - val_loss: 0.8483 - val_accuracy: 0.8400\n",
      "Epoch 966/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1795 - accuracy: 0.9688\n",
      "Epoch 966: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.1782 - accuracy: 0.9694 - val_loss: 0.8643 - val_accuracy: 0.8000\n",
      "Epoch 967/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1564 - accuracy: 0.9896\n",
      "Epoch 967: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1555 - accuracy: 0.9898 - val_loss: 0.7981 - val_accuracy: 0.8800\n",
      "Epoch 968/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1423 - accuracy: 0.9896\n",
      "Epoch 968: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.1418 - accuracy: 0.9898 - val_loss: 0.8006 - val_accuracy: 0.8000\n",
      "Epoch 969/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1273 - accuracy: 1.0000\n",
      "Epoch 969: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1298 - accuracy: 1.0000 - val_loss: 0.8732 - val_accuracy: 0.8000\n",
      "Epoch 970/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1353 - accuracy: 1.0000\n",
      "Epoch 970: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1382 - accuracy: 1.0000 - val_loss: 0.8684 - val_accuracy: 0.8000\n",
      "Epoch 971/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1663 - accuracy: 0.9792\n",
      "Epoch 971: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1652 - accuracy: 0.9796 - val_loss: 0.8402 - val_accuracy: 0.8000\n",
      "Epoch 972/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1271 - accuracy: 1.0000\n",
      "Epoch 972: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 0.1268 - accuracy: 1.0000 - val_loss: 0.8386 - val_accuracy: 0.8000\n",
      "Epoch 973/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1342 - accuracy: 1.0000\n",
      "Epoch 973: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1338 - accuracy: 1.0000 - val_loss: 0.8525 - val_accuracy: 0.7600\n",
      "Epoch 974/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1227 - accuracy: 1.0000\n",
      "Epoch 974: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1225 - accuracy: 1.0000 - val_loss: 0.8572 - val_accuracy: 0.7600\n",
      "Epoch 975/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1488 - accuracy: 0.9896\n",
      "Epoch 975: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.1481 - accuracy: 0.9898 - val_loss: 0.8745 - val_accuracy: 0.8000\n",
      "Epoch 976/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1617 - accuracy: 0.9688\n",
      "Epoch 976: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1607 - accuracy: 0.9694 - val_loss: 0.8068 - val_accuracy: 0.8000\n",
      "Epoch 977/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1581 - accuracy: 0.9898\n",
      "Epoch 977: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.1581 - accuracy: 0.9898 - val_loss: 0.8409 - val_accuracy: 0.8400\n",
      "Epoch 978/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1312 - accuracy: 1.0000\n",
      "Epoch 978: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1312 - accuracy: 1.0000 - val_loss: 0.8338 - val_accuracy: 0.8000\n",
      "Epoch 979/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1640 - accuracy: 0.9792\n",
      "Epoch 979: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1630 - accuracy: 0.9796 - val_loss: 0.8380 - val_accuracy: 0.8000\n",
      "Epoch 980/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1224 - accuracy: 1.0000\n",
      "Epoch 980: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1242 - accuracy: 1.0000 - val_loss: 0.8831 - val_accuracy: 0.8000\n",
      "Epoch 981/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1690 - accuracy: 0.9792\n",
      "Epoch 981: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 57ms/step - loss: 0.1678 - accuracy: 0.9796 - val_loss: 0.8922 - val_accuracy: 0.7600\n",
      "Epoch 982/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1322 - accuracy: 1.0000\n",
      "Epoch 982: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1324 - accuracy: 1.0000 - val_loss: 0.8890 - val_accuracy: 0.7200\n",
      "Epoch 983/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1620 - accuracy: 0.9796\n",
      "Epoch 983: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.1620 - accuracy: 0.9796 - val_loss: 0.8218 - val_accuracy: 0.7600\n",
      "Epoch 984/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1627 - accuracy: 0.9796\n",
      "Epoch 984: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 53ms/step - loss: 0.1627 - accuracy: 0.9796 - val_loss: 0.7966 - val_accuracy: 0.8400\n",
      "Epoch 985/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1431 - accuracy: 1.0000\n",
      "Epoch 985: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1426 - accuracy: 1.0000 - val_loss: 0.8053 - val_accuracy: 0.8400\n",
      "Epoch 986/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1409 - accuracy: 0.9896\n",
      "Epoch 986: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1403 - accuracy: 0.9898 - val_loss: 0.8513 - val_accuracy: 0.8000\n",
      "Epoch 987/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1540 - accuracy: 0.9896\n",
      "Epoch 987: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1531 - accuracy: 0.9898 - val_loss: 0.8443 - val_accuracy: 0.8000\n",
      "Epoch 988/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1560 - accuracy: 0.9792\n",
      "Epoch 988: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1551 - accuracy: 0.9796 - val_loss: 0.8343 - val_accuracy: 0.8400\n",
      "Epoch 989/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1492 - accuracy: 0.9896\n",
      "Epoch 989: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 40ms/step - loss: 0.1523 - accuracy: 0.9898 - val_loss: 0.7835 - val_accuracy: 0.8400\n",
      "Epoch 990/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.2002 - accuracy: 0.9688\n",
      "Epoch 990: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 55ms/step - loss: 0.1987 - accuracy: 0.9694 - val_loss: 0.8202 - val_accuracy: 0.8000\n",
      "Epoch 991/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1266 - accuracy: 1.0000\n",
      "Epoch 991: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1266 - accuracy: 1.0000 - val_loss: 0.8474 - val_accuracy: 0.8000\n",
      "Epoch 992/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1358 - accuracy: 1.0000\n",
      "Epoch 992: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 42ms/step - loss: 0.1359 - accuracy: 1.0000 - val_loss: 0.7992 - val_accuracy: 0.8000\n",
      "Epoch 993/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1473 - accuracy: 0.9792\n",
      "Epoch 993: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 46ms/step - loss: 0.1465 - accuracy: 0.9796 - val_loss: 0.8144 - val_accuracy: 0.7600\n",
      "Epoch 994/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1419 - accuracy: 0.9792\n",
      "Epoch 994: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.1413 - accuracy: 0.9796 - val_loss: 0.8037 - val_accuracy: 0.8000\n",
      "Epoch 995/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1178 - accuracy: 1.0000\n",
      "Epoch 995: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 48ms/step - loss: 0.1178 - accuracy: 1.0000 - val_loss: 0.8684 - val_accuracy: 0.7200\n",
      "Epoch 996/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1281 - accuracy: 1.0000\n",
      "Epoch 996: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 44ms/step - loss: 0.1281 - accuracy: 1.0000 - val_loss: 0.8138 - val_accuracy: 0.7600\n",
      "Epoch 997/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1384 - accuracy: 1.0000\n",
      "Epoch 997: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 45ms/step - loss: 0.1396 - accuracy: 1.0000 - val_loss: 0.8156 - val_accuracy: 0.8000\n",
      "Epoch 998/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1441 - accuracy: 0.9896\n",
      "Epoch 998: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1440 - accuracy: 0.9898 - val_loss: 0.8389 - val_accuracy: 0.7600\n",
      "Epoch 999/1000\n",
      "3/4 [=====================>........] - ETA: 0s - loss: 0.1232 - accuracy: 1.0000\n",
      "Epoch 999: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1235 - accuracy: 1.0000 - val_loss: 0.8671 - val_accuracy: 0.7600\n",
      "Epoch 1000/1000\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.1509 - accuracy: 0.9898\n",
      "Epoch 1000: val_accuracy did not improve from 0.96000\n",
      "4/4 [==============================] - 0s 52ms/step - loss: 0.1509 - accuracy: 0.9898 - val_loss: 0.8772 - val_accuracy: 0.7200\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.8772 - accuracy: 0.7200\n",
      "Test accuracy: 0.7200000286102295\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "num_epochs = 1000\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"calc_and_exp_2-12.hdf5\", monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "seqModel = model.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[checkpoint])\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15eb59df0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(seqModel.history.keys())\n",
    "xc         = range(num_epochs)\n",
    "\n",
    "plt.plot(xc, seqModel.history['loss'], label='train loss')\n",
    "plt.plot(xc, seqModel.history['val_loss'], label='validation loss')\n",
    "plt.plot(xc, seqModel.history['accuracy'], label='accuracy')\n",
    "plt.plot(xc, seqModel.history['val_accuracy'], label='val_accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with custom_object_scope({'SeqSelfAttention': SeqSelfAttention}):\n",
    "    load_model = keras.models.load_model('/Users/dimitrygrebenyuk/Yandex.Disk.localized/Working/PDF/Refinements/PDF-Cluster-Prediction/all_data/calc_and_exp_2-12.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 114ms/step - loss: 2.2140 - accuracy: 0.9600\n",
      "1/1 [==============================] - 0s 247ms/step\n"
     ]
    }
   ],
   "source": [
    "load_model.evaluate(X_test, y_test)\n",
    "y_pred_prob = load_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "confusion = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix, without normalization\n",
      "[[1 0 0 0 0 0]\n",
      " [0 5 0 0 0 0]\n",
      " [0 0 8 0 0 0]\n",
      " [0 0 1 2 0 0]\n",
      " [0 0 0 0 6 0]\n",
      " [0 0 0 0 0 2]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(confusion, classes = np.unique(y_test), title='Confusion matrix', normalize=False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:48:25) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3adb7d5fef717c587deb8377a86ec7783da6fdece6d2a9408ba836e669f2be8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
